<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="es"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Interaccion con modelos de IA usando OpenRouter — acep_openrouter • ACEP</title><!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png"><link rel="icon" type="”image/svg+xml”" href="../favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" sizes="any" href="../favicon.ico"><link rel="manifest" href="../site.webmanifest"><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Interaccion con modelos de IA usando OpenRouter — acep_openrouter"><meta name="description" content="Funcion para interactuar con multiples proveedores de IA (OpenAI, Anthropic, Google,
Meta, etc.) a traves de la API unificada de OpenRouter. Soporta Structured Outputs
para modelos compatibles (OpenAI GPT-4o+, Fireworks, y otros). OpenRouter normaliza
las diferencias entre proveedores, permitiendo acceder a 400+ modelos con una sola API.
Ideal para comparar modelos o usar fallbacks automaticos."><meta property="og:description" content="Funcion para interactuar con multiples proveedores de IA (OpenAI, Anthropic, Google,
Meta, etc.) a traves de la API unificada de OpenRouter. Soporta Structured Outputs
para modelos compatibles (OpenAI GPT-4o+, Fireworks, y otros). OpenRouter normaliza
las diferencias entre proveedores, permitiendo acceder a 400+ modelos con una sola API.
Ideal para comparar modelos o usar fallbacks automaticos."><meta property="og:image" content="https://agusnieto77.github.io/ACEP/logo.svg"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">ACEP</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/conflictividad_soip.html">Conflictividad laboral en la pesca</a></li>
    <li><a class="dropdown-item" href="../articles/extraccion_de_svo_con_acep.html">Extraer S-V-O con ACEP</a></li>
    <li><a class="dropdown-item" href="../articles/extraccion_palabras_clave.html">Extracción de palabas clave</a></li>
    <li><a class="dropdown-item" href="../articles/limpieza_de_texto_con_acep.html">Limpieza de texto con ACEP</a></li>
    <li><a class="dropdown-item" href="../articles/tokenizar_con_acep.html">Tokenizar con ACEP</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/agusnieto77/ACEP/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>Interaccion con modelos de IA usando OpenRouter</h1>
      <small class="dont-index">Source: <a href="https://github.com/agusnieto77/ACEP/blob/master/R/acep_openrouter.R" class="external-link"><code>R/acep_openrouter.R</code></a></small>
      <div class="d-none name"><code>acep_openrouter.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Funcion para interactuar con multiples proveedores de IA (OpenAI, Anthropic, Google,
Meta, etc.) a traves de la API unificada de OpenRouter. Soporta Structured Outputs
para modelos compatibles (OpenAI GPT-4o+, Fireworks, y otros). OpenRouter normaliza
las diferencias entre proveedores, permitiendo acceder a 400+ modelos con una sola API.
Ideal para comparar modelos o usar fallbacks automaticos.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">acep_openrouter</span><span class="op">(</span></span>
<span>  <span class="va">texto</span>,</span>
<span>  <span class="va">instrucciones</span>,</span>
<span>  modelo <span class="op">=</span> <span class="st">"openai/gpt-4o-mini"</span>,</span>
<span>  api_key <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.getenv.html" class="external-link">Sys.getenv</a></span><span class="op">(</span><span class="st">"OPENROUTER_API_KEY"</span><span class="op">)</span>,</span>
<span>  schema <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  parse_json <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  temperature <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  max_tokens <span class="op">=</span> <span class="fl">2000</span>,</span>
<span>  top_p <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span>  app_name <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  site_url <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  use_fallback <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  fallback_provider_order <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  fallback_models <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-texto">texto<a class="anchor" aria-label="anchor" href="#arg-texto"></a></dt>
<dd><p>Texto a analizar. Puede ser una noticia, tweet, documento, etc.</p></dd>


<dt id="arg-instrucciones">instrucciones<a class="anchor" aria-label="anchor" href="#arg-instrucciones"></a></dt>
<dd><p>Instrucciones en lenguaje natural que indican al modelo que hacer
con el texto. Ejemplo: "Extrae todas las entidades nombradas", "Clasifica el sentimiento".</p></dd>


<dt id="arg-modelo">modelo<a class="anchor" aria-label="anchor" href="#arg-modelo"></a></dt>
<dd><p>Modelo a utilizar con formato "proveedor/modelo". Ejemplos populares:
- OpenAI: `"openai/gpt-4o-mini"` (rapido y economico), `"openai/gpt-4o"` (potente)
- Anthropic: `"anthropic/claude-sonnet-4.5"`, `"anthropic/claude-3.5-haiku"`
- Google: `"google/gemini-2.5-flash"`, `"google/gemini-2.0-flash-001"`
- Meta: `"meta-llama/llama-3.3-70b-instruct"`, `"meta-llama/llama-4-maverick:free"`
- Qwen: `"qwen/qwen3-next-80b-a3b-instruct-2509"`
- DeepSeek: `"deepseek/deepseek-chat-v3-0324:free"`, `"deepseek/deepseek-r1:free"`
Por defecto: `"openai/gpt-4o-mini"`. Ver lista completa: https://openrouter.ai/models</p></dd>


<dt id="arg-api-key">api_key<a class="anchor" aria-label="anchor" href="#arg-api-key"></a></dt>
<dd><p>Clave de API de OpenRouter. Si no se proporciona, busca la variable de
entorno `OPENROUTER_API_KEY`. Para obtener una clave: https://openrouter.ai/settings/keys</p></dd>


<dt id="arg-schema">schema<a class="anchor" aria-label="anchor" href="#arg-schema"></a></dt>
<dd><p>Esquema JSON que define la estructura de la respuesta. Puede usar
`acep_gpt_schema()` para obtener esquemas predefinidos o crear uno personalizado.
Si es `NULL`, usa un esquema simple con campo "respuesta".
NOTA: Structured Outputs solo funciona con modelos compatibles (OpenAI GPT-4o+, Fireworks).
Para otros modelos, se usara JSON mode basico.</p></dd>


<dt id="arg-parse-json">parse_json<a class="anchor" aria-label="anchor" href="#arg-parse-json"></a></dt>
<dd><p>Logico. Si `TRUE` (por defecto), parsea automaticamente el JSON
a un objeto R (lista o data frame). Si `FALSE`, devuelve el JSON como string.</p></dd>


<dt id="arg-temperature">temperature<a class="anchor" aria-label="anchor" href="#arg-temperature"></a></dt>
<dd><p>Parametro de temperatura (0-2). Valores bajos (0-0.3) generan
respuestas mas deterministas. Valores altos (0.7-1) mas creativas. Por defecto: 0.</p></dd>


<dt id="arg-max-tokens">max_tokens<a class="anchor" aria-label="anchor" href="#arg-max-tokens"></a></dt>
<dd><p>Numero maximo de tokens en la respuesta. Por defecto: 2000.</p></dd>


<dt id="arg-top-p">top_p<a class="anchor" aria-label="anchor" href="#arg-top-p"></a></dt>
<dd><p>Parametro top-p para nucleus sampling (0-1). Por defecto: 0.2.</p></dd>


<dt id="arg-app-name">app_name<a class="anchor" aria-label="anchor" href="#arg-app-name"></a></dt>
<dd><p>Nombre de tu aplicacion (opcional). Se muestra en openrouter.ai/activity.</p></dd>


<dt id="arg-site-url">site_url<a class="anchor" aria-label="anchor" href="#arg-site-url"></a></dt>
<dd><p>URL de tu aplicacion (opcional). Para estadisticas en OpenRouter.</p></dd>


<dt id="arg-use-fallback">use_fallback<a class="anchor" aria-label="anchor" href="#arg-use-fallback"></a></dt>
<dd><p>Logico. Si `TRUE`, OpenRouter usara modelos alternativos si el
proveedor primario falla. Por defecto: FALSE (sin fallbacks).</p></dd>


<dt id="arg-fallback-provider-order">fallback_provider_order<a class="anchor" aria-label="anchor" href="#arg-fallback-provider-order"></a></dt>
<dd><p>Vector opcional de slugs de proveedores para forzar
un orden especifico de enrutamiento (ej.: `c("openai", "anthropic")`). Requiere
`use_fallback = TRUE` para habilitar intentos sucesivos.</p></dd>


<dt id="arg-fallback-models">fallback_models<a class="anchor" aria-label="anchor" href="#arg-fallback-models"></a></dt>
<dd><p>Vector opcional de modelos alternativos (en formato
`"proveedor/modelo"`) que se probaran en orden si el modelo principal devuelve un
error recuperable (429, 5xx, timeouts). Ideal para definir variantes pagas cuando
la version `:free` alcance su limite.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>Si `parse_json=TRUE`, devuelve una lista o data frame con la respuesta
  estructurada segun el esquema. Si `parse_json=FALSE`, devuelve un string JSON.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>OpenRouter abstrae las diferencias entre proveedores, mapeando automaticamente los
parametros a la interfaz nativa de cada modelo. Los parametros no soportados por un
modelo son ignorados silenciosamente. Esto permite usar la misma funcion para
cualquier modelo sin preocuparse por las especificidades de cada API.</p>
<p>Cuando `use_fallback = TRUE`, la funcion configura el objeto `provider` de OpenRouter
para conservar la resiliencia ante errores transitorios y, si se define
`fallback_models`, intenta llamar secuencialmente a cada modelo alternativo ante
codigos recuperables (429, 5xx, timeouts). Esto evita depender del campo `route`,
ya deprecado en la API.</p>
<p>Para Structured Outputs estrictos, recomendamos usar modelos OpenAI (gpt-4o+) o
Fireworks. Otros modelos intentaran seguir el esquema pero sin garantias estrictas.</p>
    </div>
    <div class="section level2">
    <h2 id="modelos-compatibles-y-probados-actualizado-">MODELOS COMPATIBLES Y PROBADOS (ACTUALIZADO)<a class="anchor" aria-label="anchor" href="#modelos-compatibles-y-probados-actualizado-"></a></h2>


<div class="section">
<h3 id="openai-familia-gpt-ultima-generacion-">OpenAI - Familia GPT-5 (Ultima Generacion)<a class="anchor" aria-label="anchor" href="#openai-familia-gpt-ultima-generacion-"></a></h3>

<ul><li><p><code>openai/gpt-5</code> - Modelo principal GPT-5</p></li>
<li><p><code>openai/gpt-5-pro</code> - Version Pro, maxima precision</p></li>
<li><p><code>openai/gpt-5-mini</code> - Version mini, economica</p></li>
<li><p><code>openai/gpt-5-nano</code> - Version nano, ultrarrapida</p></li>
<li><p><code>openai/gpt-5-chat</code> - Optimizado para chat</p></li>
</ul></div>
<div class="section">
<h3 id="openai-familia-gpt-">OpenAI - Familia GPT-4.1<a class="anchor" aria-label="anchor" href="#openai-familia-gpt-"></a></h3>

<ul><li><p><code>openai/gpt-4.1</code> - Modelo principal GPT-4.1</p></li>
<li><p><code>openai/gpt-4.1-mini</code> - Version mini</p></li>
<li><p><code>openai/gpt-4.1-nano</code> - Version nano</p></li>
</ul></div>
<div class="section">
<h3 id="openai-familia-gpt--1">OpenAI - Familia GPT-4<a class="anchor" aria-label="anchor" href="#openai-familia-gpt--1"></a></h3>

<ul><li><p><code>openai/gpt-4o</code> - GPT-4 optimizado</p></li>
<li><p><code>openai/gpt-4o-mini</code> - Economico, rapido, ideal para produccion</p></li>
<li><p><code>openai/gpt-4-turbo</code> - Version turbo</p></li>
<li><p><code>openai/gpt-4</code> - Modelo base GPT-4</p></li>
</ul></div>
<div class="section">
<h3 id="openai-familia-gpt--2">OpenAI - Familia GPT-3.5<a class="anchor" aria-label="anchor" href="#openai-familia-gpt--2"></a></h3>

<ul><li><p><code>openai/gpt-3.5-turbo</code> - Version turbo, economica</p></li>
</ul></div>
<div class="section">
<h3 id="openai-modelos-oss-open-source-style-">OpenAI - Modelos OSS (Open Source Style)<a class="anchor" aria-label="anchor" href="#openai-modelos-oss-open-source-style-"></a></h3>

<ul><li><p><code>openai/gpt-oss-120b</code> - Modelo grande (120B parametros)</p></li>
<li><p><code>openai/gpt-oss-120b:exacto</code> - Version exacta</p></li>
<li><p><code>openai/gpt-oss-20b</code> - Modelo pequeno (20B parametros)</p></li>
<li><p><code>openai/gpt-oss-20b:free</code> - Version gratuita</p></li>
</ul></div>
<div class="section">
<h3 id="xai-familia-grok-ultima-generacion-">xAI - Familia Grok 4 (Ultima Generacion)<a class="anchor" aria-label="anchor" href="#xai-familia-grok-ultima-generacion-"></a></h3>

<ul><li><p><code>x-ai/grok-4</code> - Modelo principal Grok 4</p></li>
<li><p><code>x-ai/grok-4-fast</code> - Version rapida, optimizada</p></li>
</ul></div>
<div class="section">
<h3 id="xai-familia-grok-">xAI - Familia Grok 3<a class="anchor" aria-label="anchor" href="#xai-familia-grok-"></a></h3>

<ul><li><p><code>x-ai/grok-3</code> - Modelo principal Grok 3</p></li>
<li><p><code>x-ai/grok-3-mini</code> - Version mini, economica</p></li>
<li><p><code>x-ai/grok-3-beta</code> - Version beta</p></li>
<li><p><code>x-ai/grok-3-mini-beta</code> - Version mini beta</p></li>
</ul></div>
<div class="section">
<h3 id="deepseek-familia-v-ultima-generacion-">DeepSeek - Familia V3 (Ultima Generacion)<a class="anchor" aria-label="anchor" href="#deepseek-familia-v-ultima-generacion-"></a></h3>

<ul><li><p><code>deepseek/deepseek-v3.2-exp</code> - Version experimental 3.2</p></li>
<li><p><code>deepseek/deepseek-v3.1-terminus</code> - Version terminus 3.1</p></li>
<li><p><code>deepseek/deepseek-v3.1-terminus:exacto</code> - Version terminus exacta</p></li>
</ul></div>
<div class="section">
<h3 id="deepseek-familia-r-razonamiento-">DeepSeek - Familia R1 (Razonamiento)<a class="anchor" aria-label="anchor" href="#deepseek-familia-r-razonamiento-"></a></h3>

<ul><li><p><code>deepseek/deepseek-r1-0528</code> - Version R1 de mayo 2028</p></li>
<li><p><code>deepseek/deepseek-r1</code> - Modelo principal R1</p></li>
<li><p><code>deepseek/deepseek-r1:free</code> - Version R1 gratuita</p></li>
</ul></div>
<div class="section">
<h3 id="deepseek-r-distilled-basado-en-llama-">DeepSeek - R1 Distilled (Basado en Llama)<a class="anchor" aria-label="anchor" href="#deepseek-r-distilled-basado-en-llama-"></a></h3>

<ul><li><p><code>deepseek/deepseek-r1-distill-llama-70b</code> - R1 destilado en Llama 70B</p></li>
<li><p><code>deepseek/deepseek-r1-distill-llama-70b:free</code> - Version gratuita</p></li>
</ul></div>
<div class="section">
<h3 id="deepseek-chat-y-otros">DeepSeek - Chat y Otros<a class="anchor" aria-label="anchor" href="#deepseek-chat-y-otros"></a></h3>

<ul><li><p><code>deepseek/deepseek-chat</code> - Optimizado para chat</p></li>
</ul></div>
<div class="section">
<h3 id="deepcogito-modelos-especializados">DeepCogito - Modelos Especializados<a class="anchor" aria-label="anchor" href="#deepcogito-modelos-especializados"></a></h3>

<ul><li><p><code>deepcogito/cogito-v2-preview-deepseek-671b</code> - Modelo cogito 671B basado en DeepSeek</p></li>
</ul></div>
<div class="section">
<h3 id="meta-llama-familia-">Meta Llama - Familia 4<a class="anchor" aria-label="anchor" href="#meta-llama-familia-"></a></h3>

<ul><li><p><code>meta-llama/llama-4-maverick</code> - Llama 4 Maverick</p></li>
</ul></div>
<div class="section">
<h3 id="meta-llama-familia--1">Meta Llama - Familia 3.3<a class="anchor" aria-label="anchor" href="#meta-llama-familia--1"></a></h3>

<ul><li><p><code>meta-llama/llama-3.3-70b-instruct</code> - Version de pago</p></li>
<li><p><code>meta-llama/llama-3.3-70b-instruct:free</code> - Version gratuita</p></li>
</ul></div>
<div class="section">
<h3 id="meta-llama-familia--2">Meta Llama - Familia 3.2<a class="anchor" aria-label="anchor" href="#meta-llama-familia--2"></a></h3>

<ul><li><p><code>meta-llama/llama-3.2-90b-vision-instruct</code> - Con capacidades de vision</p></li>
</ul></div>
<div class="section">
<h3 id="meta-llama-familia--3">Meta Llama - Familia 3.1<a class="anchor" aria-label="anchor" href="#meta-llama-familia--3"></a></h3>

<ul><li><p><code>meta-llama/llama-3.1-405b-instruct</code> - Modelo grande 405B</p></li>
<li><p><code>meta-llama/llama-3.1-70b-instruct</code> - Modelo mediano 70B</p></li>
</ul></div>
<div class="section">
<h3 id="nousresearch-modelos-hermes">NousResearch - Modelos Hermes<a class="anchor" aria-label="anchor" href="#nousresearch-modelos-hermes"></a></h3>

<ul><li><p><code>nousresearch/hermes-3-llama-3.1-405b</code> - Hermes 3 basado en Llama 405B</p></li>
</ul></div>
<div class="section">
<h3 id="mistral-ai-familia-magistral">Mistral AI - Familia Magistral<a class="anchor" aria-label="anchor" href="#mistral-ai-familia-magistral"></a></h3>

<ul><li><p><code>mistralai/magistral-medium-2506</code> - Magistral medium</p></li>
<li><p><code>mistralai/magistral-medium-2506:thinking</code> - Con razonamiento extendido</p></li>
</ul></div>
<div class="section">
<h3 id="mistral-ai-otros-modelos">Mistral AI - Otros Modelos<a class="anchor" aria-label="anchor" href="#mistral-ai-otros-modelos"></a></h3>

<ul><li><p><code>mistralai/mistral-large-2407</code> - Mistral large</p></li>
<li><p><code>mistralai/mixtral-8x22b-instruct</code> - Mixtral 8x22B (MoE)</p></li>
</ul></div>
<div class="section">
<h3 id="moonshotai-familia-kimi-k-">MoonshotAI - Familia Kimi K2<a class="anchor" aria-label="anchor" href="#moonshotai-familia-kimi-k-"></a></h3>

<ul><li><p><code>moonshotai/kimi-k2</code> - Modelo principal Kimi K2</p></li>
<li><p><code>moonshotai/kimi-k2-0905</code> - Version 09/05</p></li>
<li><p><code>moonshotai/kimi-k2-0905:exacto</code> - Version exacta</p></li>
<li><p><code>moonshotai/kimi-k2-thinking</code> - Con razonamiento extendido</p></li>
</ul></div>
<div class="section">
<h3 id="qwen-familia-qwen-b-modelos-grandes-">Qwen - Familia Qwen3 (235B - Modelos Grandes)<a class="anchor" aria-label="anchor" href="#qwen-familia-qwen-b-modelos-grandes-"></a></h3>

<ul><li><p><code>qwen/qwen3-235b-a22b-2507</code> - Modelo grande 235B (version 2507)</p></li>
<li><p><code>qwen/qwen3-235b-a22b</code> - Modelo grande 235B</p></li>
<li><p><code>qwen/qwen3-235b-a22b-thinking-2507</code> - Con razonamiento extendido</p></li>
<li><p><code>qwen/qwen3-max</code> - Version maxima</p></li>
</ul></div>
<div class="section">
<h3 id="qwen-familia-qwen-b-b-modelos-medianos-">Qwen - Familia Qwen3 (30B-80B - Modelos Medianos)<a class="anchor" aria-label="anchor" href="#qwen-familia-qwen-b-b-modelos-medianos-"></a></h3>

<ul><li><p><code>qwen/qwen3-next-80b-a3b-instruct</code> - Modelo next 80B</p></li>
<li><p><code>qwen/qwen3-32b</code> - Modelo 32B</p></li>
<li><p><code>qwen/qwen3-30b-a3b</code> - Modelo 30B</p></li>
<li><p><code>qwen/qwen3-30b-a3b-instruct-2507</code> - Version instruct 2507</p></li>
<li><p><code>qwen/qwen3-30b-a3b:free</code> - Version 30B gratuita</p></li>
</ul></div>
<div class="section">
<h3 id="qwen-familia-qwen-modelos-pequenos-">Qwen - Familia Qwen3 (Modelos Pequenos)<a class="anchor" aria-label="anchor" href="#qwen-familia-qwen-modelos-pequenos-"></a></h3>

<ul><li><p><code>qwen/qwen3-14b:free</code> - Modelo 14B gratuito</p></li>
<li><p><code>qwen/qwen3-4b:free</code> - Modelo 4B gratuito, ultrarrapido</p></li>
</ul></div>
<div class="section">
<h3 id="qwen-familia-qwen-">Qwen - Familia Qwen 2.5<a class="anchor" aria-label="anchor" href="#qwen-familia-qwen-"></a></h3>

<ul><li><p><code>qwen/qwen-2.5-72b-instruct</code> - Modelo 2.5 generacion anterior</p></li>
<li><p><code>qwen/qwen-plus</code> - Version plus</p></li>
</ul></div>
<div class="section">
<h3 id="google-gemini-familia-ultima-generacion-">Google Gemini - Familia 2.5 (Ultima Generacion)<a class="anchor" aria-label="anchor" href="#google-gemini-familia-ultima-generacion-"></a></h3>

<ul><li><p><code>google/gemini-2.5-flash</code> - Rapido, ultima generacion</p></li>
<li><p><code>google/gemini-2.5-pro</code> - Mayor precision, ultima generacion</p></li>
<li><p><code>google/gemini-2.5-flash-lite</code> - Ultrarrapido, ligero</p></li>
<li><p><code>google/gemini-2.5-flash-preview-09-2025</code> - Preview version septiembre</p></li>
<li><p><code>google/gemini-2.5-flash-lite-preview-09-2025</code> - Preview lite septiembre</p></li>
</ul></div>
<div class="section">
<h3 id="google-gemini-familia-">Google Gemini - Familia 2.0<a class="anchor" aria-label="anchor" href="#google-gemini-familia-"></a></h3>

<ul><li><p><code>google/gemini-2.0-flash-001</code> - Version estable 2.0</p></li>
<li><p><code>google/gemini-2.0-flash-lite-001</code> - Version ligera 2.0</p></li>
</ul></div>
<div class="section">
<h3 id="google-gemini-familia--1">Google Gemini - Familia 1.5<a class="anchor" aria-label="anchor" href="#google-gemini-familia--1"></a></h3>

<ul><li><p><code>google/gemini-pro-1.5</code> - Version anterior, estable</p></li>
</ul></div>
<div class="section">
<h3 id="anthropic-claude-familia-haiku-rapidos-y-economicos-">Anthropic Claude - Familia Haiku (Rapidos y Economicos)<a class="anchor" aria-label="anchor" href="#anthropic-claude-familia-haiku-rapidos-y-economicos-"></a></h3>

<ul><li><p><code>anthropic/claude-3.5-haiku</code> - Version 3.5, muy rapido</p></li>
<li><p><code>anthropic/claude-3-haiku</code> - Version 3, economico</p></li>
<li><p><code>anthropic/claude-haiku-4.5</code> - Ultima version, mas preciso</p></li>
</ul></div>
<div class="section">
<h3 id="anthropic-claude-familia-sonnet-equilibrados-">Anthropic Claude - Familia Sonnet (Equilibrados)<a class="anchor" aria-label="anchor" href="#anthropic-claude-familia-sonnet-equilibrados-"></a></h3>

<ul><li><p><code>anthropic/claude-3.5-sonnet</code> - Popular, buen balance</p></li>
<li><p><code>anthropic/claude-3.7-sonnet</code> - Version mejorada</p></li>
<li><p><code>anthropic/claude-3.7-sonnet:thinking</code> - Con razonamiento extendido</p></li>
<li><p><code>anthropic/claude-sonnet-4</code> - Generacion 4</p></li>
<li><p><code>anthropic/claude-sonnet-4.5</code> - Ultima version, mas preciso</p></li>
</ul></div>
<div class="section">
<h3 id="anthropic-claude-familia-opus-maxima-precision-">Anthropic Claude - Familia Opus (Maxima Precision)<a class="anchor" aria-label="anchor" href="#anthropic-claude-familia-opus-maxima-precision-"></a></h3>

<ul><li><p><code>anthropic/claude-3-opus</code> - Version 3, muy preciso</p></li>
<li><p><code>anthropic/claude-opus-4</code> - Generacion 4</p></li>
<li><p><code>anthropic/claude-opus-4.1</code> - Ultima version disponible</p></li>
</ul></div><p>**Importante:** los modelos etiquetados como `:free` operan con cuotas comunitarias
y suelen estar sometidos a limites de tasa estrictos por parte de OpenRouter. Es
frecuente recibir respuestas HTTP 429 (Too Many Requests) cuando la demanda supera
la cuota disponible; este codigo indica que el proveedor rechazo la peticion para
proteger la infraestructura compartida. Si ocurre, espera unos segundos y reintenta,
o selecciona la variante de pago equivalente (sin sufijo `:free`) o activa `use_fallback`
para que OpenRouter cambie automaticamente a un modelo disponible.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span><span class="co"># Configurar API key</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Sys.setenv.html" class="external-link">Sys.setenv</a></span><span class="op">(</span>OPENROUTER_API_KEY <span class="op">=</span> <span class="st">"tu-api-key"</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Usar GPT-4o mini (rapido y economico)</span></span></span>
<span class="r-in"><span><span class="va">texto</span> <span class="op">&lt;-</span> <span class="st">"El SUTEBA convoco a un paro en Buenos Aires el 15 de marzo."</span></span></span>
<span class="r-in"><span><span class="va">resultado</span> <span class="op">&lt;-</span> <span class="fu">acep_openrouter</span><span class="op">(</span><span class="va">texto</span>, <span class="st">"Extrae las entidades nombradas"</span>,</span></span>
<span class="r-in"><span>                              modelo <span class="op">=</span> <span class="st">"openai/gpt-4o-mini"</span>,</span></span>
<span class="r-in"><span>                              schema <span class="op">=</span> <span class="fu"><a href="acep_gpt_schema.html">acep_gpt_schema</a></span><span class="op">(</span><span class="st">"extraccion_entidades"</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Comparar con Claude</span></span></span>
<span class="r-in"><span><span class="va">resultado_claude</span> <span class="op">&lt;-</span> <span class="fu">acep_openrouter</span><span class="op">(</span><span class="va">texto</span>, <span class="st">"Extrae las entidades nombradas"</span>,</span></span>
<span class="r-in"><span>                                     modelo <span class="op">=</span> <span class="st">"anthropic/claude-sonnet-4.5"</span>,</span></span>
<span class="r-in"><span>                                     schema <span class="op">=</span> <span class="fu"><a href="acep_gpt_schema.html">acep_gpt_schema</a></span><span class="op">(</span><span class="st">"extraccion_entidades"</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Usar modelo gratuito</span></span></span>
<span class="r-in"><span><span class="va">resultado_free</span> <span class="op">&lt;-</span> <span class="fu">acep_openrouter</span><span class="op">(</span><span class="va">texto</span>, <span class="st">"Clasifica el sentimiento"</span>,</span></span>
<span class="r-in"><span>                                   modelo <span class="op">=</span> <span class="st">"meta-llama/llama-4-maverick:free"</span>,</span></span>
<span class="r-in"><span>                                   schema <span class="op">=</span> <span class="fu"><a href="acep_gpt_schema.html">acep_gpt_schema</a></span><span class="op">(</span><span class="st">"sentimiento"</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Definir fallback hacia variantes pagas o proveedores alternativos</span></span></span>
<span class="r-in"><span><span class="va">resultado_resiliente</span> <span class="op">&lt;-</span> <span class="fu">acep_openrouter</span><span class="op">(</span></span></span>
<span class="r-in"><span>  <span class="va">texto</span>,</span></span>
<span class="r-in"><span>  <span class="st">"Extrae las entidades nombradas"</span>,</span></span>
<span class="r-in"><span>  modelo <span class="op">=</span> <span class="st">"meta-llama/llama-4-maverick:free"</span>,</span></span>
<span class="r-in"><span>  schema <span class="op">=</span> <span class="fu"><a href="acep_gpt_schema.html">acep_gpt_schema</a></span><span class="op">(</span><span class="st">"extraccion_entidades"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>  use_fallback <span class="op">=</span> <span class="cn">TRUE</span>,</span></span>
<span class="r-in"><span>  fallback_models <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"meta-llama/llama-4-maverick"</span>, <span class="st">"openai/gpt-4o-mini"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Agustín Nieto.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer></div>





  </body></html>

