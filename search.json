[{"path":"https://agusnieto77.github.io/ACEP/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 ACEP authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://agusnieto77.github.io/ACEP/articles/conflictividad_soip.html","id":"introducción","dir":"Articles","previous_headings":"","what":"Introducción","title":"Conflictividad laboral en la pesca","text":"En este artículo desarrollaremos una introducción al análisis de la conflictividad laboral en la industria pesquera argentina con un enfoque de diccionario en base las funciones del paquete ACEP. En esta oportunidad pondremos el foco en la conflictividad laboral protagonizada por el Sindicato Obrero de la Industria del Pescado (SOIP) en la ciudad de Mar del Plata entre los años 2009 y 2020.","code":""},{"path":"https://agusnieto77.github.io/ACEP/articles/conflictividad_soip.html","id":"el-corpus-de-notas","dir":"Articles","previous_headings":"","what":"El corpus de notas","title":"Conflictividad laboral en la pesca","text":"Las notas que componen el corpus utilizado en este ejercicio fueron raspadas del sitio revistapuerto.com.ar con las funciones del paquete rvest. Se compone de 7816 notas y 6 variables: fecha, titulo, bajada, nota, imagen, link. El corpus de notas cubre desde el 2 de marzo de 2009 hasta el 29 de diciembre de 2020. Para cargar todas las notas haremos uso de la función acep_load_base().","code":"# Cargamos la librería ACEP library(ACEP)  # Definimos la url url <- acep_bases$rp_mdp  # Descargamos el corpus de notas de la Revista Puerto rev_puerto <- acep_load_base(url)  # Imprimimos la base en consola rev_puerto #> # A tibble: 7,816 × 6 #>    fecha      titulo                                   bajada nota  imagen link  #>  * <date>     <chr>                                    <chr>  <chr> <chr>  <chr> #>  1 2020-12-29 ¡Feliz Año 2021 para todos nuestros ami… Con m… \"Con… https… http… #>  2 2020-12-28 Mapa del trabajo esclavo en aguas inter… Un re… \"El … https… http… #>  3 2020-12-24 Plantas piden tener garantizada la prov… En Ch… \"El … https… http… #>  4 2020-12-24 Los obreros navales despiden el año ana… En Ma… \"El … https… http… #>  5 2020-12-23 El incumplimiento del régimen de cuotif… Se ll… \"Las… https… http… #>  6 2020-12-23 Otro fallo ratifica cautelar contra el … La Cá… \"La … https… http… #>  7 2020-12-22 Recomendaciones de SENASA para las expo… Desde… \"En … https… http… #>  8 2020-12-22 Trelew consolida su inserción en la ind… En 20… \"Ins… https… http… #>  9 2020-12-21 El CFP presentó el estado y la captura … En la… \"Ant… https… http… #> 10 2020-12-21 La flota amarilla cierra el año con sos… Puert… \"El … https… http… #> # ℹ 7,806 more rows"},{"path":"https://agusnieto77.github.io/ACEP/articles/conflictividad_soip.html","id":"los-diccionarios","dir":"Articles","previous_headings":"","what":"Los diccionarios","title":"Conflictividad laboral en la pesca","text":"Una vez descargada la base de notas vamos crear variables numéricas que contenga las frecuencias de palabras totales y de cada diccionario usado para cada una de las notas. En esta parte del código haremos uso de tres funciones y un diccionario del paquete ACEP: acep_frec(), acep_count(), acep_load_base() y acep_diccionarios. También crearemos dos diccionarios breves para usarlos en la función acep_count() con un doble objetivo: 1) identificar las notas que refieran huelgas; 2) identificar las notas que refieran lxs trabajadorxs del procesamiento de pescado en tierra en la ciudad de Mar del Plata.","code":"# Creamos la variable con la frecuencia de palabras por nota rev_puerto$frec_palabras <- acep_frec(rev_puerto$nota)  # Cargamos el diccionario de palabras que refieren a conflictividad dicc_conflictos <- acep_load_base(acep_diccionarios$dicc_confl_sismos)  # Creamos la variable con la frecuencia de palabras que refieren a conflictividad rev_puerto$frec_conflictos <- acep_count(rev_puerto$nota, dicc_conflictos)  # Creamos el diccionario de palabras que refieren a huelgas dicc_huelgas <- c(\"en paro\", \"al paro\", \"huelga\", \"huelguistas\", \"paro y movil\",                   \"paro de actividades\", \"conciliación obligatoria\", \"un paro\",                    \"paro total\", \"paro parcial\", \"trabajo a reglamento\",                    \"el paro\", \"de brazos caídos\")  # Creamos la variable con la frecuencia de palabras que refieren a huelgas rev_puerto$frec_huelgas <- acep_count(rev_puerto$nota, dicc_huelgas)  # Creamos el diccionario de palabras que refieren a lxs obrerxs del pescado dicc_soip <- c(\"soip\", \"sindicato obrero de la industria del pescado\",                 \"sindicato de la industria del pescado\", \"huelguistas\",                 \"obreras de la industria del pescado\", \"obreras del pescado\",                \"obreros de la industria del pescado\", \"obreros del pescado\",                \"fileteros\", \"fileteras\", \"obreros del filet\", \"obreras del filet\")  # Creamos la variable con la frecuencia de palabras que  # refieren a lxs obrerxs del pescado rev_puerto$frec_soip <- acep_count(rev_puerto$nota, dicc_soip)  # Imprimimos la base en consola rev_puerto #> # A tibble: 7,816 × 10 #>    fecha      titulo     bajada nota  imagen link  frec_palabras frec_conflictos #>    <date>     <chr>      <chr>  <chr> <chr>  <chr>         <int>           <int> #>  1 2020-12-29 ¡Feliz Añ… Con m… \"Con… https… http…            28               0 #>  2 2020-12-28 Mapa del … Un re… \"El … https… http…          1142               3 #>  3 2020-12-24 Plantas p… En Ch… \"El … https… http…           536               3 #>  4 2020-12-24 Los obrer… En Ma… \"El … https… http…           489               7 #>  5 2020-12-23 El incump… Se ll… \"Las… https… http…           529               4 #>  6 2020-12-23 Otro fall… La Cá… \"La … https… http…           467               6 #>  7 2020-12-22 Recomenda… Desde… \"En … https… http…           661               0 #>  8 2020-12-22 Trelew co… En 20… \"Ins… https… http…           844               4 #>  9 2020-12-21 El CFP pr… En la… \"Ant… https… http…          1454               4 #> 10 2020-12-21 La flota … Puert… \"El … https… http…          1073               5 #> # ℹ 7,806 more rows #> # ℹ 2 more variables: frec_huelgas <int>, frec_soip <int>"},{"path":"https://agusnieto77.github.io/ACEP/articles/conflictividad_soip.html","id":"los-índices","dir":"Articles","previous_headings":"","what":"Los índices","title":"Conflictividad laboral en la pesca","text":"Ya construidas las variables de frecuencia de palabras y menciones nos ocuparemos de elaborar nuevas variables con índices de intensidad en base al ratio entre las frecuencias de palabras totales y las menciones de los diccionarios sobre trabajadorxs del pescado, conflictos y huelgas. Para la elaboración de estos índices haremos uso de la función acep_int() del paquete ACEP. Al realizar los filtros la base se redujo 387 notas que presentan al menos una mención de una palabra que refiere conflicto y al menos un término que refiere lxs trabajadorxs del pescado.","code":"# Creamos la variable con el índice de conflictividad general rev_puerto$i_conf_gral <- acep_int(rev_puerto$frec_conflictos,                                     rev_puerto$frec_palabras)  # Creamos la variable con el índice de incidencia  # de lxs trabajadorxs del pescado rev_puerto$i_soip <- acep_int(rev_puerto$frec_soip,                                rev_puerto$frec_palabras)  # Creamos la variable con el índice de huelgas rev_puerto$i_huelgas <- acep_int(rev_puerto$frec_huelgas,                                   rev_puerto$frec_conflictos)  # Filtramos para quedarnos con los índices mayores a 0  # en la variable del índice de conflictividad general rev_puerto <- rev_puerto[rev_puerto$i_conf_gral > 0, ]  # Filtramos para quedarnos con los índices mayores a 0 # en el índice de incidencia de lxs trabajadorxs del pescado rev_puerto <- rev_puerto[rev_puerto$i_soip > 0, ]  # Imprimimos la base en consola rev_puerto #> # A tibble: 387 × 13 #>    fecha      titulo     bajada nota  imagen link  frec_palabras frec_conflictos #>    <date>     <chr>      <chr>  <chr> <chr>  <chr>         <int>           <int> #>  1 2020-11-24 Mardi, la… \"Con … \"Tra… https… http…          1140               1 #>  2 2020-11-16 Cierran l… \"El v… \"Des… https… http…           384               3 #>  3 2020-11-13 CaIPA-SOI… \"Las … \"Lo … https… http…           380               3 #>  4 2020-10-30 Conflicto… \"El S… \"La … https… http…           689               4 #>  5 2020-10-12 Obreros r… \"Pert… \"Un … https… http…           425               6 #>  6 2020-10-07 Langostin… \"El m… \"El … https… http…          1120               4 #>  7 2020-09-15 Corvina: … \"Áfri… \"La … https… http…           669               4 #>  8 2020-08-31 Peón de u… \"Es u… \"Víc… https… http…           759               5 #>  9 2020-08-26 “La salid… \"Lo d… \"Due… https… http…          1624               4 #> 10 2020-08-11 Los comed… \"Aume… \"Es … https… http…          1272               3 #> # ℹ 377 more rows #> # ℹ 5 more variables: frec_huelgas <int>, frec_soip <int>, i_conf_gral <dbl>, #> #   i_soip <dbl>, i_huelgas <dbl>"},{"path":"https://agusnieto77.github.io/ACEP/articles/conflictividad_soip.html","id":"serie-temporal-de-índices","dir":"Articles","previous_headings":"","what":"Serie temporal de índices","title":"Conflictividad laboral en la pesca","text":"En esta parte del código usaremos la función acep_sst() para calcular los índices agrupados por año y mes. Primero construimos la serie de tiempo para la conflictividad general. En la siguiente parte del código construimos la serie de tiempo para la conflictividad huelguística.","code":"# Calculamos el índice anual de conflictividad general en el # ámbito de la industrial del procesado de pescado en tierra # Pero primero preparamos el marcos de datos para ser procesado  # por la función acep_sst() # Estos pasos previos se deben realizar porque en este ejemplo no hicimos uso  # de la función acep_db() que calcula frecuencia, menciones e intensidad y # deja el marco de datos resultante en un formato adecuado para ser usado # con la función acep_sst() datos <- data.frame(   fecha = rev_puerto$fecha,   n_palabras = rev_puerto$frec_palabras,   conflictos = rev_puerto$frec_conflictos,   intensidad = rev_puerto$i_conf_gral )  # Luego construimos los vectores fecha <- datos$fecha n_palabras <- datos$n_palabras conflictos <- datos$conflictos  # Ahora agrupamos por mes la conflictividad general del sector conf_gral_anio <- acep_sst(datos, st = \"anio\")  # Imprimimos la base en consola conf_gral_anio |> head() #>     st frecn csn frecp frecm  intac intensidad int_notas_confl #> 1 2009    33  24 26169   161 0.2256     0.0062          0.7273 #> 2 2010    30  21 27950   219 0.2873     0.0078          0.7000 #> 3 2011    44  32 31273   277 0.4344     0.0089          0.7273 #> 4 2012    77  70 67922   713 0.8519     0.0105          0.9091 #> 5 2013    27  16 19783   168 0.2273     0.0085          0.5926 #> 6 2014    17  11 12944    88 0.1173     0.0068          0.6471 # Calculamos el índice mensual de conflictividad general en el # ámbito de la industrial del procesado de pescado en tierra # Pero primero preparamos el marcos de datos para ser procesado  # por la función acep_sst() datos <- data.frame(   fecha = rev_puerto$fecha,   n_palabras = rev_puerto$frec_palabras,   conflictos = rev_puerto$frec_conflictos,   intensidad = rev_puerto$i_conf_gral )  # Nos quedamos con los datos del año 2012  datos <-  datos[datos$fecha < \"2013-01-01\", ] datos <-  datos[datos$fecha > \"2011-12-31\", ]  # Luego construimos los vectores fecha <- datos$fecha n_palabras <- datos$n_palabras conflictos <- datos$conflictos  # Ahora agrupamos por mes la conflictividad general del sector conf_gral <- acep_sst(datos)  # Imprimimos la base en consola conf_gral |> head() #>        st frecn csn frecp frecm  intac intensidad int_notas_confl #> 1 2012-01     4   2  3407    17 0.0233     0.0050          0.5000 #> 2 2012-02     3   2  1991    11 0.0175     0.0055          0.6667 #> 3 2012-03     5   4  4994    16 0.0183     0.0032          0.8000 #> 4 2012-04     6   6  5426    52 0.0661     0.0096          1.0000 #> 5 2012-05     7   7  5982    83 0.0991     0.0139          1.0000 #> 6 2012-06    12  12 11100   158 0.1692     0.0142          1.0000 # Calculamos el índice mensual de conflictividad huelguística en el # ámbito de la industrial del procesado de pescado en tierra # Pero primero preparamos el marcos de datos para ser procesado  # por la función acep_sst() datosh <- data.frame(   fecha = rev_puerto$fecha,   n_palabras = rev_puerto$frec_palabras,   conflictos = rev_puerto$frec_huelgas,   intensidad = rev_puerto$i_huelgas )  # Nos quedamos con los datos del año 2012   datosh <-  datosh[datosh$fecha < \"2013-01-01\", ] datosh <-  datosh[datosh$fecha > \"2011-12-31\", ]  # Luego construimos los vectores fechah <- datosh$fecha n_palabrash <- datosh$n_palabras conflictosh <- datosh$conflictos  # Ahora agrupamos por mes la conflictividad huelguística del sector huelgas <- acep_sst(datosh)  # Imprimimos la base en consola huelgas |> head() #>        st frecn csn frecp frecm  intac intensidad int_notas_confl #> 1 2012-01     4   0  3407     0 0.0000     0.0000          0.0000 #> 2 2012-02     3   0  1991     0 0.0000     0.0000          0.0000 #> 3 2012-03     5   0  4994     0 0.0000     0.0000          0.0000 #> 4 2012-04     6   0  5426     5 0.5219     0.0009          0.0000 #> 5 2012-05     7   1  5982     9 0.5396     0.0015          0.1429 #> 6 2012-06    12   2 11100    17 0.9302     0.0015          0.1667"},{"path":"https://agusnieto77.github.io/ACEP/articles/conflictividad_soip.html","id":"las-visualizaciones","dir":"Articles","previous_headings":"","what":"Las visualizaciones","title":"Conflictividad laboral en la pesca","text":"En este último apartado haremos uso de las funciones acep_plot_st() y acep_plot_rst() para visualizar la variación anual de la conflictividad general protagonizada por lxs trabajadorxs del pescado entre marzo de 2009 y diciembre de 2020. También visualizaremos la variación mensual durante el año 2012, el más conflictivo de período bajo análisis.     Las distintas métricas nos ayudan identificar al año 2012 como el más conflictivo del período en el ámbito de la industria pesquera de procesado en tierra en la ciudad de Mar del Plata, con epicentro en los meses de junio, julio y agosto para la conflictividad general y con epicentro en los meses de mayo, junio y julio para los movimientos huelguísticos.","code":"# Visualizaremos el índice de conflictividad general  # agrupado por año para el período 2009-2020 acep_plot_st(  conf_gral_anio$st,  conf_gral_anio$frecm,  t = \"Indice anual de conflictividad en la industria pesquera (MdP)\",  ejey = \"Menciones del diccionario\",  etiquetax = \"vertical\"              ) # Visualizaremos el índice de conflictividad general  # agrupado por año para el período 2009-2020 acep_plot_rst(conf_gral_anio, tagx = \"vertical\") # Visualizaremos el índice de conflictividad general  # agrupado por mes para el 2012 acep_plot_st(  conf_gral$st,  conf_gral$frecm,  t = \"Indice mensual de conflictos en la industria pesquera (MdP)\",  ejey = \"Menciones del diccionario\",  etiquetax = \"vertical\"              ) # Visualizaremos el índice de conflictividad huelguística  # agrupado por mes para el 2012 acep_plot_st(  huelgas$st,  huelgas$frecm,  t = \"Indice mensual de huelgas en la industria pesquera (MdP)\",  ejey = \"Menciones del diccionario\",  etiquetax = \"vertical\"              )"},{"path":"https://agusnieto77.github.io/ACEP/articles/conflictividad_soip.html","id":"comentarios-finales","dir":"Articles","previous_headings":"","what":"Comentarios finales","title":"Conflictividad laboral en la pesca","text":"lo largo de este breve tutorial sobre algunas de las funciones del paquete ACEP buscamos ejemplificar de qué modo se puede adoptar un enfoque de diccionario para realizar un primer análisis exploratorio de un corpus de notas periodísticas. Los resultados son alentadores. Con la combinación de distintos diccionarios se pudo identificar la temporalidad de la conflictividad protagonizada por lxs obrerxs del pescado en la ciudad de Mar del Plata. En próximos artículos avanzaremos con otras funciones del paquete ACEP para el análisis computacional de la conflictividad en la industria pesquera argentina.","code":""},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"función-a-presentar","dir":"Articles","previous_headings":"","what":"Función a presentar:","title":"Extraer S-V-O con ACEP","text":"En este artículo se explicarán los procesos que realizan las funciones: acep_postag() acep_upos() acep_svo()","code":""},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"función-acep_postag","dir":"Articles","previous_headings":"","what":"Función acep_postag()","title":"Extraer S-V-O con ACEP","text":"Esta función realiza etiquetado POS, lematización, tokenización, extracción de entidades y georreferenciación. Para llevar cabo estas tareas acep_postag envuelve y articula funciones de tres librerías: spacyr, rsyntax y tidygeocoder. En primer lugar, cargamos la librería ACEP. Luego, cargamos un vector de titulares de portales noticiosos sobre notas referidas conflictos. Con esta selección de titulares haremos la prueba. También agregamos una última oración unimembre como ejemplo extremo de oración procesable con la función acep_svo(). Ejecutamos la función acep_postag() para los titulares contenidos en el vector. ¿Cuál es el resultado? La función acep_postag toma el vector de textos y realiza diferentes acciones: Verifica que el objeto entregado sea un vector de tipo caracter (de lo contrario imprime un mensaje de advertencia) Verifica que el parámetro ‘core’ sean un modelo válido (de lo contrario devuelve un mensaje de advertencia) Verifica que los parámetros ‘bajar_core’, ‘inst_spacy’, ‘inst_miniconda’, ‘inst_reticulate’ ingresados sean valores booleanos (de lo contrario envía un mensaje de advertencia) Crea una lista de seis objetos de tipo data frame: texto_tag: es un objeto de clases ‘tokenIndex’ que sirve como input para la función acep_svo(). Contiene 20 variables que reúnen información de los procesos de tokenización, lematización, etiquetado pos, etiquetado de relaciones de dependencia, etiquetado NER y morfológico. texto_tag_entity: es un objeto de clase ‘spacyr_parsed’ con una columna que identifica los distintos tipos de entidades. texto_only_entity: es un ‘data.frame’ con 4 variables que contiene solo las entidades identificadas. texto_only_entity_loc: es un ‘data.frame’ de 7 variables que permite la georreferenciación de las entidades identificadas como tipo ‘LOC’. texto_nounphrase: es un objeto de clase ‘spacyr_parsed’ con una columna que identifica las distintas frases compuestas por sustantivos (nounphrase). texto_only_nounphrase: es un ‘data.frame’ con tres variables que identifica y filtra los sustantivos que forman frases: ‘las_principales_ciudades’. Cabe mencionar que los textos ingresados son tokenizados, es decir, cada palabra es un token. En este resultado podemos ver cómo la función crea los seis marcos de datos con información relevante sobre el contenido y la forma de los textos ingresados. En nuestro caso, textos referidos conflictos. Veamos con un poco más de detalle cada uno de los marcos de datos creados con la función acep_postag():","code":"library(ACEP)  titulares <- c(acep_bases$titulares, \"Hola mundo.\")  titulares #> [1] \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política económica del Gobierno.\\n          Los gremios convocan a un paro docente contra 'la presencialidad de Larreta' en Ciudad de Buenos Aires.\" #> [2] \"Los gremios docentes rechazan volver a las aulas sin garantías sanitarias.\"                                                                                                                                                                              #> [3] \"Los estatales rechazaron la oferta salarial que les hizo el gobierno en Chubut.\"                                                                                                                                                                         #> [4] \"La CGT presiona para que los 1700 empleados cobren la doble indemnización.\"                                                                                                                                                                              #> [5] \"Las dos CTA y la Izquierda rechazaron el acuerdo de la CGT para rebajar salarios.\"                                                                                                                                                                       #> [6] \"Un gremio aéreo levantó el paro en Tucumán. Los judiciales ratificaron un paro.\\n          La CGT marchó con críticas por la economía y evalúa si llama a un paro.\"                                                                                      #> [7] \"Ctera convocó a un paro de 72 horas en todo el país.\"                                                                                                                                                                                                    #> [8] \"Conciliación obligatoria en el conflicto del neumático.\"                                                                                                                                                                                                 #> [9] \"Hola mundo.\" titulares_tags <- acep_postag(   texto = titulares,   core = \"es_core_news_lg\", # valor por defecto   bajar_core = FALSE,       # el valor por defecto es TRUE   inst_spacy = FALSE,       # valor por defecto   inst_miniconda = FALSE,   # valor por defecto   inst_reticulate = FALSE   # valor por defecto )  str(titulares_tags) #> List of 6 #>  $ texto_tag            :Classes 'tokenIndex', 'data.table' and 'data.frame':    153 obs. of  20 variables: #>   ..$ doc_id        : int [1:153] 1 1 1 1 1 1 1 1 1 1 ... #>   ..$ sentence      : int [1:153] 1 1 1 1 1 1 1 1 1 1 ... #>   ..$ token_id      : num [1:153] 1 2 3 4 5 6 7 8 9 10 ... #>   ..$ token         : chr [1:153] \"Sindicatos\" \"y\" \"estudiantes\" \"marchan\" ... #>   ..$ lemma         : chr [1:153] \"Sindicatos\" \"y\" \"estudiante\" \"marchar\" ... #>   ..$ pos           : chr [1:153] \"PROPN\" \"CCONJ\" \"NOUN\" \"VERB\" ... #>   ..$ parent        : num [1:153] 4 3 1 NA 8 8 8 4 10 8 ... #>   ..$ relation      : chr [1:153] \"nsubj\" \"cc\" \"conj\" \"ROOT\" ... #>   .. ..- attr(*, \"levels\")= chr \"ROOT\" #>   ..$ entity        : chr [1:153] \"\" \"\" \"\" \"\" ... #>   ..$ nounphrase    : chr [1:153] \"beg_root\" \"\" \"beg_root\" \"\" ... #>   ..$ whitespace    : logi [1:153] TRUE TRUE TRUE TRUE TRUE TRUE ... #>   ..$ is_upper      : logi [1:153] FALSE FALSE FALSE FALSE FALSE FALSE ... #>   ..$ is_title      : logi [1:153] TRUE FALSE FALSE FALSE FALSE FALSE ... #>   ..$ is_quote      : logi [1:153] FALSE FALSE FALSE FALSE FALSE FALSE ... #>   ..$ ent_iob_      : chr [1:153] \"O\" \"O\" \"O\" \"O\" ... #>   ..$ ent_iob       : int [1:153] 2 2 2 2 2 2 2 2 2 3 ... #>   ..$ is_left_punct : logi [1:153] FALSE FALSE FALSE FALSE FALSE FALSE ... #>   ..$ is_right_punct: logi [1:153] FALSE FALSE FALSE FALSE FALSE FALSE ... #>   ..$ morph         : chr [1:153] \"\" \"\" \"Number=Plur\" \"Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\" ... #>   ..$ sent          : chr [1:153] \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ ... #>   ..- attr(*, \".internal.selfref\")=<externalptr>  #>   ..- attr(*, \"sorted\")= chr [1:3] \"doc_id\" \"sentence\" \"token_id\" #>   ..- attr(*, \"index\")= int(0)  #>   .. ..- attr(*, \"__doc_id__sentence__parent\")= int [1:153] 4 3 2 1 8 12 21 5 6 7 ... #>   .. ..- attr(*, \"__relation\")= int [1:153] 4 25 46 57 71 88 101 109 116 131 ... #>  $ texto_tag_entity     :Classes 'spacyr_parsed' and 'data.frame':   149 obs. of  7 variables: #>   ..$ doc_id     : int [1:149] 1 1 1 1 1 1 1 1 1 1 ... #>   ..$ sentence_id: int [1:149] 1 1 1 1 1 1 1 1 1 1 ... #>   ..$ token_id   : num [1:149] 1 2 3 4 5 6 7 8 9 10 ... #>   ..$ token      : chr [1:149] \"Sindicatos\" \"y\" \"estudiantes\" \"marchan\" ... #>   ..$ lemma      : chr [1:149] \"Sindicatos\" \"y\" \"estudiante\" \"marchar\" ... #>   ..$ pos        : chr [1:149] \"PROPN\" \"CCONJ\" \"NOUN\" \"VERB\" ... #>   ..$ entity_type: chr [1:149] \"\" \"\" \"\" \"\" ... #>  $ texto_only_entity    :'data.frame':   13 obs. of  4 variables: #>   ..$ doc_id     : int [1:13] 1 1 1 1 3 4 5 5 5 6 ... #>   ..$ sentence_id: int [1:13] 1 1 2 2 1 1 1 1 1 1 ... #>   ..$ entity     : chr [1:13] \"México\" \"Gobierno\" \"Larreta\" \"Ciudad_de_Buenos_Aires\" ... #>   ..$ entity_type: chr [1:13] \"LOC\" \"ORG\" \"PER\" \"LOC\" ... #>  $ texto_only_entity_loc:'data.frame':   4 obs. of  7 variables: #>   ..$ doc_id     : int [1:4] 1 1 3 6 #>   ..$ sentence   : int [1:4] 1 2 1 1 #>   ..$ entity_    : chr [1:4] \"México\" \"Ciudad de Buenos Aires\" \"Chubut\" \"Tucumán\" #>   ..$ entity     : chr [1:4] \"México\" \"Ciudad_de_Buenos_Aires\" \"Chubut\" \"Tucumán\" #>   ..$ entity_type: chr [1:4] \"LOC\" \"LOC\" \"LOC\" \"LOC\" #>   ..$ lat        : num [1:4] 23.7 -34.6 -43.7 -26.6 #>   ..$ long       : num [1:4] -102 -58.4 -68.7 -64.9 #>  $ texto_nounphrase     :Classes 'spacyr_parsed' and 'data.frame':   120 obs. of  6 variables: #>   ..$ doc_id     : int [1:120] 1 1 1 1 1 1 1 1 1 1 ... #>   ..$ sentence_id: int [1:120] 1 1 1 1 1 1 1 1 1 1 ... #>   ..$ token_id   : num [1:120] 1 2 3 4 5 6 7 8 9 10 ... #>   ..$ token      : chr [1:120] \"Sindicatos\" \"y\" \"estudiantes\" \"marchan\" ... #>   ..$ lemma      : chr [1:120] \"Sindicatos\" \"y\" \"estudiante\" \"marchar\" ... #>   ..$ pos        : chr [1:120] \"nounphrase\" \"CCONJ\" \"nounphrase\" \"VERB\" ... #>  $ texto_only_nounphrase:'data.frame':   45 obs. of  3 variables: #>   ..$ doc_id     : int [1:45] 1 1 1 1 1 1 1 1 1 1 ... #>   ..$ sentence_id: int [1:45] 1 1 1 1 1 1 1 2 2 2 ... #>   ..$ nounphrase : chr [1:45] \"Sindicatos\" \"estudiantes\" \"las_principales_ciudades\" \"México\" ..."},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"texto_tag","dir":"Articles","previous_headings":"Función acep_postag()","what":"texto_tag","title":"Extraer S-V-O con ACEP","text":"Como adelantamos, el primer objeto de la lista es un marco de datos estructurado para servir de input de la función acep_svo().","code":"head(titulares_tags$texto_tag[43:54, ], n = 12) #> Key: <doc_id, sentence, token_id> #>     doc_id sentence token_id      token     lemma    pos parent relation entity #>      <int>    <int>    <num>     <char>    <char> <char>  <num>   <char> <char> #>  1:      2        1        1        Los        el    DET      2      det        #>  2:      2        1        2    gremios    gremio   NOUN      4    nsubj        #>  3:      2        1        3   docentes   docente    ADJ      2     amod        #>  4:      2        1        4   rechazan  rechazar   VERB     NA     ROOT        #>  5:      2        1        5     volver    volver   VERB      4    xcomp        #>  6:      2        1        6          a         a    ADP      8     case        #>  7:      2        1        7        las        el    DET      8      det        #>  8:      2        1        8      aulas      aula   NOUN      5      obl        #>  9:      2        1        9        sin       sin    ADP     10     case        #> 10:      2        1       10  garantías  garantía   NOUN      5      obl        #> 11:      2        1       11 sanitarias sanitario    ADJ     10     amod        #> 12:      2        1       12          .         .  PUNCT      4    punct        #>     nounphrase whitespace is_upper is_title is_quote ent_iob_ ent_iob #>         <char>     <lgcl>   <lgcl>   <lgcl>   <lgcl>   <char>   <int> #>  1:        beg       TRUE    FALSE     TRUE    FALSE        O       2 #>  2:   end_root       TRUE    FALSE    FALSE    FALSE        O       2 #>  3:                  TRUE    FALSE    FALSE    FALSE        O       2 #>  4:                  TRUE    FALSE    FALSE    FALSE        O       2 #>  5:                  TRUE    FALSE    FALSE    FALSE        O       2 #>  6:                  TRUE    FALSE    FALSE    FALSE        O       2 #>  7:        beg       TRUE    FALSE    FALSE    FALSE        O       2 #>  8:   end_root       TRUE    FALSE    FALSE    FALSE        O       2 #>  9:                  TRUE    FALSE    FALSE    FALSE        O       2 #> 10:   beg_root       TRUE    FALSE    FALSE    FALSE        O       2 #> 11:                 FALSE    FALSE    FALSE    FALSE        O       2 #> 12:                 FALSE    FALSE    FALSE    FALSE        O       2 #>     is_left_punct is_right_punct #>            <lgcl>         <lgcl> #>  1:         FALSE          FALSE #>  2:         FALSE          FALSE #>  3:         FALSE          FALSE #>  4:         FALSE          FALSE #>  5:         FALSE          FALSE #>  6:         FALSE          FALSE #>  7:         FALSE          FALSE #>  8:         FALSE          FALSE #>  9:         FALSE          FALSE #> 10:         FALSE          FALSE #> 11:         FALSE          FALSE #> 12:         FALSE          FALSE #>                                                     morph #>                                                    <char> #>  1:     Definite=Def|Gender=Masc|Number=Plur|PronType=Art #>  2:                               Gender=Masc|Number=Plur #>  3:                                           Number=Plur #>  4: Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin #>  5:                                          VerbForm=Inf #>  6:                                          AdpType=Prep #>  7:      Definite=Def|Gender=Fem|Number=Plur|PronType=Art #>  8:                                Gender=Fem|Number=Plur #>  9:                                          AdpType=Prep #> 10:                                Gender=Fem|Number=Plur #> 11:                                Gender=Fem|Number=Plur #> 12:                                        PunctType=Peri #>                                                                           sent #>                                                                         <char> #>  1: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias. #>  2: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias. #>  3: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias. #>  4: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias. #>  5: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias. #>  6: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias. #>  7: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias. #>  8: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias. #>  9: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias. #> 10: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias. #> 11: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias. #> 12: Los gremios docentes rechazan volver a las aulas sin garantías sanitarias."},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"texto_tag_entity","dir":"Articles","previous_headings":"Función acep_postag()","what":"texto_tag_entity","title":"Extraer S-V-O con ACEP","text":"El segundo objeto de la lista es un marco de datos que reescribe la columna ‘pos’ con la etiqueta ‘ENTITY’ e identifica el tipo de entidad en la columna ‘entity_type’. Si la entidad detectada está compuesta por más de un token, la función colapsa todos los tokens referidos esa entidad en una sola celda de la columna token. Ejemplo: ‘Ciudad_de_Buenos_Aires’.","code":"head(titulares_tags$texto_tag_entity[52:65, ], n = 14) #>    doc_id sentence_id token_id      token    lemma    pos entity_type #> 52      3           1        1        Los       el    DET             #> 53      3           1        2  estatales  estatal   NOUN             #> 54      3           1        3 rechazaron rechazar   VERB             #> 55      3           1        4         la       el    DET             #> 56      3           1        5     oferta   oferta   NOUN             #> 57      3           1        6   salarial salarial    ADJ             #> 58      3           1        7        que      que   PRON             #> 59      3           1        8        les       él   PRON             #> 60      3           1        9       hizo    hacer   VERB             #> 61      3           1       10         el       el    DET             #> 62      3           1       11   gobierno gobierno   NOUN             #> 63      3           1       12         en       en    ADP             #> 64      3           1       13     Chubut   Chubut ENTITY         LOC #> 65      3           1       14          .        .  PUNCT"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"texto_only_entity","dir":"Articles","previous_headings":"Función acep_postag()","what":"texto_only_entity","title":"Extraer S-V-O con ACEP","text":"El tercer objeto de la lista es el marco de datos ‘texto_tag_entity’ filtrado por el valor ‘ENTITY’ de la columna ‘pos’.","code":"head(titulares_tags$texto_only_entity, n = 10) #>    doc_id sentence_id                 entity entity_type #> 1       1           1                 México         LOC #> 2       1           1               Gobierno         ORG #> 3       1           2                Larreta         PER #> 4       1           2 Ciudad_de_Buenos_Aires         LOC #> 5       3           1                 Chubut         LOC #> 6       4           1                    CGT         ORG #> 7       5           1                    CTA         ORG #> 8       5           1              Izquierda         ORG #> 9       5           1                    CGT         ORG #> 10      6           1                Tucumán         LOC"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"texto_only_entity_loc","dir":"Articles","previous_headings":"Función acep_postag()","what":"texto_only_entity_loc","title":"Extraer S-V-O con ACEP","text":"El cuarto objeto de la lista es el marco de datos ‘texto_only_entity’ filtrado por el valor ‘LOC’ de la columna ‘entity_type’ y procesado con la función ‘geo()’ del paquete tidygeocoder.","code":"head(titulares_tags$texto_only_entity_loc[ , c(1:3, 6:7)], n = 4) #>    doc_id sentence                entity_       lat       long #> 1       1        1                 México  23.65851 -102.00771 #> 22      1        2 Ciudad de Buenos Aires -34.60757  -58.43709 #> 43      3        1                 Chubut -43.71284  -68.74618 #> 57      6        1                Tucumán -26.56436  -64.88240"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"texto_nounphrase","dir":"Articles","previous_headings":"Función acep_postag()","what":"texto_nounphrase","title":"Extraer S-V-O con ACEP","text":"El quinto objeto de la lista es un marco de datos que reescribe la columna ‘pos’ con la etiqueta ‘nounphrase’. Si el sustantivo detectado está compuesto por más de un token, la función colapsa todos los tokens referidos ese sustantivo en una sola celda de la columna token. Ejemplo: ‘las_principales_ciudades’.","code":"head(titulares_tags$texto_nounphrase[ , c(1:2, 4, 6)], n = 10) #>    doc_id sentence_id                    token        pos #> 1       1           1               Sindicatos nounphrase #> 2       1           1                        y      CCONJ #> 3       1           1              estudiantes nounphrase #> 4       1           1                  marchan       VERB #> 5       1           1                      por        ADP #> 6       1           1 las_principales_ciudades nounphrase #> 7       1           1                       de        ADP #> 8       1           1                   México nounphrase #> 9       1           1                     para        ADP #> 10      1           1                   exigir       VERB"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"texto_only_nounphrase","dir":"Articles","previous_headings":"Función acep_postag()","what":"texto_only_nounphrase","title":"Extraer S-V-O con ACEP","text":"El sexto objeto de la lista es el marco de datos ‘texto_nounphrase’ filtrado por el valor ‘nounphrase’ de la columna ‘pos’.","code":"head(titulares_tags$texto_only_nounphrase, n = 10) #>    doc_id sentence_id               nounphrase #> 1       1           1               Sindicatos #> 2       1           1              estudiantes #> 3       1           1 las_principales_ciudades #> 4       1           1                   México #> 5       1           1                un_cambio #> 6       1           1              la_política #> 7       1           1                 Gobierno #> 8       1           2              Los_gremios #> 9       1           2                  un_paro #> 10      1           2        la_presencialidad"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"función-acep_upos","dir":"Articles","previous_headings":"","what":"Función acep_upos()","title":"Extraer S-V-O con ACEP","text":"Esta función realiza etiquetado POS, lematización, tokenización, pero realiza extracción de entidades y, por ende, puede hacer georreferenciación. Para llevar cabo estas tareas acep_upos envuelve la función udpipe() de la librería homonimia. Advertencia: ponemos esta alternativa acep_postag porque la instalación de reticulate, anaconda y las librerías de Python necesarias para el funcionamiento de spacyr pueden traer más de un problema. Repetimos el proceso realizado con la función acep_postag: activamos la librería ACEP, luego, cargamos un vector de titulares de portales noticiosos sobre notas referidas conflictos para su prueba, y agregamos una última oración unimembre como ejemplo extremo de oración procesable con la función acep_svo(). Ejecutamos la función acep_upos() para los titulares contenidos en el vector. ¿Cuál es el resultado? La función acep_upos toma el vector de textos y realiza diferentes acciones: Verifica que el objeto entregado sea un vector de tipo caracter (de lo contrario imprime un mensaje de advertencia) Verifica que el parámetro ‘modelo’ sean un modelo válido (de lo contrario devuelve un mensaje de advertencia) Crea un objeto de clases ‘tokenIndex’ que sirve como input para la función acep_svo(). Contiene 17 variables que reúnen información de los procesos de tokenización, lematización, etiquetado pos, etiquetado de relaciones de dependencia y morfológico. Cabe mencionar que, al igual que acep_postag, los textos ingresados son tokenizados, es decir, cada palabra es un token. En este resultado podemos ver cómo la función crea el input para usar con acep_svo(). Hay que tener en cuenta que udpipe y spacyr usan modelos distintos para el etiquetado pos y las relaciones de dependencia, así como para parsear el texto en oraciones. Por ende, el resultado obtenido de la función acep_svo puede ser ligeramente diferente si usamos uno u otro modelo de etiquetado. En el ejemplo que sigue usaremos el output de la función acep_upos.","code":"library(ACEP)  titulares <- c(acep_bases$titulares, \"Hola mundo.\")  titulares #> [1] \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política económica del Gobierno.\\n          Los gremios convocan a un paro docente contra 'la presencialidad de Larreta' en Ciudad de Buenos Aires.\" #> [2] \"Los gremios docentes rechazan volver a las aulas sin garantías sanitarias.\"                                                                                                                                                                              #> [3] \"Los estatales rechazaron la oferta salarial que les hizo el gobierno en Chubut.\"                                                                                                                                                                         #> [4] \"La CGT presiona para que los 1700 empleados cobren la doble indemnización.\"                                                                                                                                                                              #> [5] \"Las dos CTA y la Izquierda rechazaron el acuerdo de la CGT para rebajar salarios.\"                                                                                                                                                                       #> [6] \"Un gremio aéreo levantó el paro en Tucumán. Los judiciales ratificaron un paro.\\n          La CGT marchó con críticas por la economía y evalúa si llama a un paro.\"                                                                                      #> [7] \"Ctera convocó a un paro de 72 horas en todo el país.\"                                                                                                                                                                                                    #> [8] \"Conciliación obligatoria en el conflicto del neumático.\"                                                                                                                                                                                                 #> [9] \"Hola mundo.\" titulares_utags <- acep_upos(   texto = titulares,   modelo = \"spanish\" # valor por defecto )  str(titulares_utags) #> Classes 'tokenIndex', 'data.table' and 'data.frame': 153 obs. of  17 variables: #>  $ doc_id      : int  1 1 1 1 1 1 1 1 1 1 ... #>  $ paragraph_id: int  1 1 1 1 1 1 1 1 1 1 ... #>  $ sentence    : int  1 1 1 1 1 1 1 1 1 1 ... #>  $ sent        : chr  \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ ... #>  $ start       : int  1 12 14 26 34 38 42 54 63 66 ... #>  $ end         : int  10 12 24 32 36 40 52 61 64 71 ... #>  $ term_id     : int  1 2 3 4 5 6 7 8 9 10 ... #>  $ token_id    : num  1 2 3 4 5 6 7 8 9 10 ... #>  $ token       : chr  \"Sindicatos\" \"y\" \"estudiantes\" \"marchan\" ... #>  $ lemma       : chr  \"sindicatos\" \"y\" \"estudiante\" \"marchar\" ... #>  $ pos         : chr  \"NOUN\" \"CCONJ\" \"NOUN\" \"VERB\" ... #>  $ xpos        : chr  NA NA NA NA ... #>  $ morph       : chr  \"Gender=Masc|Number=Plur\" NA \"Number=Plur\" \"Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\" ... #>  $ parent      : num  4 3 1 NA 8 8 8 4 10 8 ... #>  $ relation    : chr  \"nsubj\" \"cc\" \"conj\" \"ROOT\" ... #>   ..- attr(*, \"levels\")= chr \"ROOT\" #>  $ deps        : chr  NA NA NA NA ... #>  $ misc        : chr  NA NA NA NA ... #>  - attr(*, \".internal.selfref\")=<externalptr>  #>  - attr(*, \"sorted\")= chr [1:3] \"doc_id\" \"sentence\" \"token_id\" #>  - attr(*, \"index\")= int(0)  #>   ..- attr(*, \"__doc_id__sentence__parent\")= int [1:153] 4 3 2 1 8 12 22 5 6 7 ... #>   ..- attr(*, \"__relation\")= int [1:153] 4 25 46 57 71 88 101 109 115 130 ..."},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"función-acep_svo","dir":"Articles","previous_headings":"","what":"Función acep_svo()","title":"Extraer S-V-O con ACEP","text":"Una vez que tenemos la lista, con 6 marcos de datos, creada partir de la función acep_upos(), podemos utilizar la función acep_svo() para obtener un listado nuevo, con otros 6 marcos de datos, que nos proveerá la siguiente información: acep_annotate_svo: es un marco de datos con 22 variables. Mantiene la estructura del objeto ingresado la función (titulares_utags) y agrega 5 nuevas variables (‘s_v_o’, ‘s_v_o_id’, ‘s_v_o_fill’, ‘s_p’, ‘conjugaciones’). acep_pro_svo: es un marco de datos con 13 variables (‘doc_id’, ‘oracion_id’, ‘eventos’, ‘sujeto_svo’, ‘root’, ‘objeto’, ‘sujeto’, ‘predicado’, ‘verbo’, ‘lemma_verb’, ‘aux_verbos’, ‘entidades’, ‘sust_pred’) que reúne los tripletes SVO e información de contexto. Ejemplo de extracción SVO: “gremios -> convocan -> paro presencialidad”. acep_list_svo: es un marco de datos con 6 variables (‘doc_id’, ‘oracion_id’, ‘eventos’, ‘sujeto’, ‘verbo’ ‘objeto’) que procesa los tripletes SVO y los devuelve separados en sujeto, verbo, objeto. Ejemplo de extracción SVO: “gremios” “convocan” “paro presencialidad”. acep_sp: es un marco de datos con 9 variables (‘doc_id’, ‘oracion_id’, ‘sujeto’, ‘predicado’, ‘verbo’, ‘lemma_verb’, ‘aux_verbos’, ‘entidades’, ‘sust_pred’) que ofrece más información de contexto como entidades, sustantivos dentro de la oración analizada, etc. acep_lista_lemmas: es un marco de datos con dos variables (‘lemma’, ‘n’) que ofrece la frecuencia absoluta de las palabras lemmatizadas presentes en el corpus analizado. acep_no_procesadas: es un marco de datos con tres variables (‘doc_id’, ‘oracion_id’, ‘oracion’) que ofrece la frecuencia absoluta de las palabras lemmatizadas presentes en el corpus analizado. Veamos con un poco más de detalle cada uno de los marcos de datos creados con la función acep_svo().","code":"titulares_svo <- acep_svo(titulares_utags)  str(titulares_svo) #> List of 6 #>  $ acep_annotate_svo :Classes 'tokenIndex', 'data.table' and 'data.frame':   153 obs. of  22 variables: #>   ..$ doc_id       : int [1:153] 1 1 1 1 1 1 1 1 1 1 ... #>   ..$ paragraph_id : int [1:153] 1 1 1 1 1 1 1 1 1 1 ... #>   ..$ sentence     : int [1:153] 1 1 1 1 1 1 1 1 1 1 ... #>   ..$ sent         : chr [1:153] \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ \"Sindicatos y estudiantes marchan por las principales ciudades de México para exigir un cambio en la política ec\"| __truncated__ ... #>   ..$ start        : int [1:153] 1 12 14 26 34 38 42 54 63 66 ... #>   ..$ end          : int [1:153] 10 12 24 32 36 40 52 61 64 71 ... #>   ..$ term_id      : int [1:153] 1 2 3 4 5 6 7 8 9 10 ... #>   ..$ token_id     : num [1:153] 1 2 3 4 5 6 7 8 9 10 ... #>   ..$ token        : chr [1:153] \"Sindicatos\" \"y\" \"estudiantes\" \"marchan\" ... #>   ..$ lemma        : chr [1:153] \"sindicatos\" \"y\" \"estudiante\" \"marchar\" ... #>   ..$ pos          : chr [1:153] \"NOUN\" \"CCONJ\" \"NOUN\" \"VERB\" ... #>   ..$ xpos         : chr [1:153] NA NA NA NA ... #>   ..$ morph        : chr [1:153] \"Gender=Masc|Number=Plur\" NA \"Number=Plur\" \"Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\" ... #>   ..$ parent       : num [1:153] 4 3 1 NA 8 8 8 4 10 8 ... #>   ..$ relation     : chr [1:153] \"nsubj\" \"cc\" \"conj\" \"ROOT\" ... #>   .. ..- attr(*, \"levels\")= chr \"ROOT\" #>   ..$ deps         : chr [1:153] NA NA NA NA ... #>   ..$ misc         : chr [1:153] NA NA NA NA ... #>   ..$ s_v_o        : Factor w/ 3 levels \"objeto\",\"sujeto\",..: 2 NA 1 3 NA NA 1 1 NA 1 ... #>   ..$ s_v_o_id     : Factor w/ 10 levels \"1.1.4\",\"1.2.3\",..: 1 NA 1 1 NA NA 1 1 NA 1 ... #>   ..$ s_v_o_fill   : num [1:153] 0 NA 0 0 NA NA 1 0 NA 1 ... #>   ..$ s_p          : chr [1:153] \"sujeto\" \"sujeto\" \"sujeto\" \"predicado\" ... #>   ..$ conjugaciones: chr [1:153] NA NA NA \"presente\" ... #>   ..- attr(*, \".internal.selfref\")=<externalptr>  #>   ..- attr(*, \"sorted\")= chr [1:3] \"doc_id\" \"sentence\" \"token_id\" #>  $ acep_pro_svo      :'data.frame':  10 obs. of  13 variables: #>   ..$ doc_id    : int [1:10] 1 1 2 3 4 5 6 6 6 7 #>   ..$ oracion_id: int [1:10] 1 2 1 1 1 1 1 2 3 1 #>   ..$ eventos   : chr [1:10] \"Sindicatos -> marchan -> ciudades cambio\" \"gremios -> convocan -> paro\" \"gremios -> rechazan -> aulas garantías\" \"estatales -> rechazaron -> oferta gobierno Chubut\" ... #>   ..$ sujeto_svo: chr [1:10] \"Sindicatos\" \"gremios\" \"gremios\" \"estatales\" ... #>   ..$ root      : chr [1:10] \"marchan\" \"convocan\" \"rechazan\" \"rechazaron\" ... #>   ..$ objeto    : chr [1:10] \"ciudades cambio\" \"paro\" \"aulas garantías\" \"oferta gobierno Chubut\" ... #>   ..$ sujeto    : chr [1:10] \"Sindicatos estudiantes\" \"gremios\" \"gremios docentes\" \"estatales\" ... #>   ..$ predicado : chr [1:10] \"marchan principales ciudades México exigir cambio política económica Gobierno\" \"convocan paro docente presencialidad Larreta Ciudad Buenos Aires\" \"rechazan volver aulas garantías sanitarias\" \"rechazaron oferta salarial gobierno Chubut\" ... #>   ..$ verbo     : chr [1:10] \"marchan\" \"convocan\" \"rechazan\" \"rechazaron\" ... #>   ..$ lemma_verb: chr [1:10] \"marchan\" \"convocan\" \"rechazan\" \"rechazaron\" ... #>   ..$ aux_verbos: chr [1:10] \"| exigir |\" \"| NA |\" \"| volver |\" \"| NA |\" ... #>   ..$ entidades : chr [1:10] \"| México |\" \"| Larreta | Ciudad | Buenos | Aires |\" \"| NA |\" \"| Chubut |\" ... #>   ..$ sust_pred : chr [1:10] \"ciudades | México | cambio | política | Gobierno\" \"paro | presencialidad | Larreta | Ciudad | Buenos | Aires\" \"aulas | garantías\" \"oferta | gobierno | Chubut\" ... #>  $ acep_list_svo     :'data.frame':  10 obs. of  6 variables: #>   ..$ doc_id    : int [1:10] 1 1 2 3 4 5 6 6 6 7 #>   ..$ oracion_id: int [1:10] 1 2 1 1 1 1 1 2 3 1 #>   ..$ eventos   : chr [1:10] \"Sindicatos -> marchan -> ciudades cambio\" \"gremios -> convocan -> paro\" \"gremios -> rechazan -> aulas garantías\" \"estatales -> rechazaron -> oferta gobierno Chubut\" ... #>   ..$ sujeto    : chr [1:10] \"Sindicatos\" \"gremios\" \"gremios\" \"estatales\" ... #>   ..$ verbo     : chr [1:10] \"marchan\" \"convocan\" \"rechazan\" \"rechazaron\" ... #>   ..$ objeto    : chr [1:10] \"ciudades cambio\" \"paro\" \"aulas garantías\" \"oferta gobierno Chubut\" ... #>  $ acep_sp           :'data.frame':  10 obs. of  9 variables: #>   ..$ doc_id    : int [1:10] 1 1 2 3 4 5 6 6 6 7 #>   ..$ oracion_id: int [1:10] 1 2 1 1 1 1 1 2 3 1 #>   ..$ sujeto    : chr [1:10] \"Sindicatos estudiantes\" \"gremios\" \"gremios docentes\" \"estatales\" ... #>   ..$ predicado : chr [1:10] \"marchan principales ciudades México exigir cambio política económica Gobierno\" \"convocan paro docente presencialidad Larreta Ciudad Buenos Aires\" \"rechazan volver aulas garantías sanitarias\" \"rechazaron oferta salarial gobierno Chubut\" ... #>   ..$ verbo     : chr [1:10] \"marchan\" \"convocan\" \"rechazan\" \"rechazaron\" ... #>   ..$ lemma_verb: chr [1:10] \"marchan\" \"convocan\" \"rechazan\" \"rechazaron\" ... #>   ..$ aux_verbos: chr [1:10] \"| exigir |\" \"| NA |\" \"| volver |\" \"| NA |\" ... #>   ..$ entidades : chr [1:10] \"| México |\" \"| Larreta | Ciudad | Buenos | Aires |\" \"| NA |\" \"| Chubut |\" ... #>   ..$ sust_pred : chr [1:10] \"ciudades | México | cambio | política | Gobierno\" \"paro | presencialidad | Larreta | Ciudad | Buenos | Aires\" \"aulas | garantías\" \"oferta | gobierno | Chubut\" ... #>  $ acep_lista_lemmas :'data.frame':  58 obs. of  2 variables: #>   ..$ lemma: Factor w/ 58 levels \"acuerdo\",\"aéreo\",..: 45 7 28 52 9 13 18 27 38 1 ... #>   ..$ n    : int [1:58] 5 3 3 3 2 2 2 2 2 1 ... #>  $ acep_no_procesadas:Classes 'tokenIndex', 'data.table' and 'data.frame':   2 obs. of  3 variables: #>   ..$ doc_id    : int [1:2] 8 9 #>   ..$ oracion_id: int [1:2] 1 1 #>   ..$ oracion   : chr [1:2] \"Conciliación obligatoria en el conflicto del neumático.\" \"Hola mundo.\" #>   ..- attr(*, \".internal.selfref\")=<externalptr>  #>   ..- attr(*, \"sorted\")= chr [1:2] \"doc_id\" \"oracion_id\""},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"acep_annotate_svo","dir":"Articles","previous_headings":"Función acep_svo()","what":"acep_annotate_svo","title":"Extraer S-V-O con ACEP","text":"Es el marco de datos inicial procesado con las funciones del paquete rsyntax.","code":"head(titulares_svo$acep_annotate_svo[98:106, ], n=20) #> Key: <doc_id, sentence, token_id> #>    doc_id paragraph_id sentence                                        sent #>     <int>        <int>    <int>                                      <char> #> 1:      6            1        1 Un gremio aéreo levantó el paro en Tucumán. #> 2:      6            1        1 Un gremio aéreo levantó el paro en Tucumán. #> 3:      6            1        1 Un gremio aéreo levantó el paro en Tucumán. #> 4:      6            1        1 Un gremio aéreo levantó el paro en Tucumán. #> 5:      6            1        1 Un gremio aéreo levantó el paro en Tucumán. #> 6:      6            1        1 Un gremio aéreo levantó el paro en Tucumán. #> 7:      6            1        1 Un gremio aéreo levantó el paro en Tucumán. #> 8:      6            1        1 Un gremio aéreo levantó el paro en Tucumán. #> 9:      6            1        1 Un gremio aéreo levantó el paro en Tucumán. #>    start   end term_id token_id   token    lemma    pos   xpos #>    <int> <int>   <int>    <num>  <char>   <char> <char> <char> #> 1:     1     2       1        1      Un      uno    DET   <NA> #> 2:     4     9       2        2  gremio   gremio   NOUN   <NA> #> 3:    11    15       3        3   aéreo    aéreo    ADJ   <NA> #> 4:    17    23       4        4 levantó levantar   VERB   <NA> #> 5:    25    26       5        5      el       el    DET   <NA> #> 6:    28    31       6        6    paro     paro   NOUN   <NA> #> 7:    33    34       7        7      en       en    ADP   <NA> #> 8:    36    42       8        8 Tucumán  tucumán  PROPN   <NA> #> 9:    43    43       9        9       .        .  PUNCT   <NA> #>                                                    morph parent relation   deps #>                                                   <char>  <num>   <char> <char> #> 1:     Definite=Ind|Gender=Masc|Number=Sing|PronType=Art      2      det   <NA> #> 2:                               Gender=Masc|Number=Sing      4    nsubj   <NA> #> 3:                               Gender=Masc|Number=Sing      2     amod   <NA> #> 4: Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin     NA     ROOT   <NA> #> 5:     Definite=Def|Gender=Masc|Number=Sing|PronType=Art      6      det   <NA> #> 6:                               Gender=Masc|Number=Sing      4      obj   <NA> #> 7:                                                  <NA>      8     case   <NA> #> 8:                                                  <NA>      6     nmod   <NA> #> 9:                                                  <NA>      4    punct   <NA> #>             misc  s_v_o s_v_o_id s_v_o_fill       s_p conjugaciones #>           <char> <fctr>   <fctr>      <num>    <char>        <char> #> 1:          <NA>   <NA>     <NA>         NA    sujeto          <NA> #> 2:          <NA> sujeto    6.1.4          0    sujeto          <NA> #> 3:          <NA> sujeto    6.1.4          1    sujeto          <NA> #> 4:          <NA>  verbo    6.1.4          0 predicado        pasado #> 5:          <NA>   <NA>     <NA>         NA predicado          <NA> #> 6:          <NA> objeto    6.1.4          0 predicado          <NA> #> 7:          <NA>   <NA>     <NA>         NA predicado          <NA> #> 8: SpaceAfter=No objeto    6.1.4          1 predicado          <NA> #> 9:          <NA>   <NA>     <NA>         NA predicado          <NA>"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"acep_annotate_svo-1","dir":"Articles","previous_headings":"Función acep_svo()","what":"acep_annotate_svo","title":"Extraer S-V-O con ACEP","text":"Este marco de datos contiene las oraciones procesables con la identificación y extracción de sujeto-verbo-objeto y contexto.","code":"head(titulares_svo$acep_pro_svo, n=10) #>    doc_id oracion_id                                           eventos #> 1       1          1          Sindicatos -> marchan -> ciudades cambio #> 2       1          2                       gremios -> convocan -> paro #> 3       2          1            gremios -> rechazan -> aulas garantías #> 4       3          1 estatales -> rechazaron -> oferta gobierno Chubut #> 5       4          1                  CGT -> presiona -> indemnización #> 6       5          1             CTA -> rechazaron -> acuerdo salarios #> 7       6          1                         gremio -> levantó -> paro #> 8       6          2                 judiciales -> ratificaron -> paro #> 9       6          3                    CGT -> marchó -> críticas paro #> 10      7          1                     Ctera -> convocó -> paro país #>    sujeto_svo        root                 objeto                 sujeto #> 1  Sindicatos     marchan        ciudades cambio Sindicatos estudiantes #> 2     gremios    convocan                   paro                gremios #> 3     gremios    rechazan        aulas garantías       gremios docentes #> 4   estatales  rechazaron oferta gobierno Chubut              estatales #> 5         CGT    presiona          indemnización                    CGT #> 6         CTA  rechazaron       acuerdo salarios          CTA Izquierda #> 7      gremio     levantó                   paro           gremio aéreo #> 8  judiciales ratificaron                   paro             judiciales #> 9         CGT      marchó          críticas paro                    CGT #> 10      Ctera     convocó              paro país                  Ctera #>                                                                        predicado #> 1  marchan principales ciudades México exigir cambio política económica Gobierno #> 2               convocan paro docente presencialidad Larreta Ciudad Buenos Aires #> 3                                     rechazan volver aulas garantías sanitarias #> 4                                     rechazaron oferta salarial gobierno Chubut #> 5                              presiona que empleados cobren doble indemnización #> 6                                        rechazaron acuerdo CGT rebajar salarios #> 7                                                           levantó paro Tucumán #> 8                                                               ratificaron paro #> 9                                     marchó críticas economía evalúa llama paro #> 10                                                       convocó paro horas país #>          verbo  lemma_verb         aux_verbos #> 1      marchan     marchan         | exigir | #> 2     convocan    convocan             | NA | #> 3     rechazan    rechazan         | volver | #> 4   rechazaron  rechazaron             | NA | #> 5     presiona    presiona         | cobren | #> 6   rechazaron  rechazaron        | rebajar | #> 7      levantó     levantó             | NA | #> 8  ratificaron ratificaron             | NA | #> 9       marchó      marchó | evalúa | llama | #> 10     convocó     convocó             | NA | #>                                entidades #> 1                             | México | #> 2  | Larreta | Ciudad | Buenos | Aires | #> 3                                 | NA | #> 4                             | Chubut | #> 5                                | CGT | #> 6                          | CTA | CGT | #> 7                            | Tucumán | #> 8                                 | NA | #> 9                                | CGT | #> 10                             | Ctera | #>                                                    sust_pred #> 1           ciudades | México | cambio | política | Gobierno #> 2  paro | presencialidad | Larreta | Ciudad | Buenos | Aires #> 3                                          aulas | garantías #> 4                                 oferta | gobierno | Chubut #> 5                                  empleados | indemnización #> 6                                   acuerdo | CGT | salarios #> 7                                             paro | Tucumán #> 8                                                       paro #> 9                                 críticas | economía | paro #> 10                                       paro | horas | país"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"acep_list_svo","dir":"Articles","previous_headings":"Función acep_svo()","what":"acep_list_svo","title":"Extraer S-V-O con ACEP","text":"Este marco de datos es una versión reducida del data.frame ‘acep_pro_svo’. Solo contiene los tripletes sujeto-verbo-objeto en versión colapsada (‘gremios -> convocan -> paro’) y en versión separada (una columna para ‘sujeto’, otra para ‘verbo’ y otra para ‘objeto’).","code":"head(titulares_svo$acep_list_svo, n=10) #>    doc_id oracion_id                                           eventos #> 1       1          1          Sindicatos -> marchan -> ciudades cambio #> 2       1          2                       gremios -> convocan -> paro #> 3       2          1            gremios -> rechazan -> aulas garantías #> 4       3          1 estatales -> rechazaron -> oferta gobierno Chubut #> 5       4          1                  CGT -> presiona -> indemnización #> 6       5          1             CTA -> rechazaron -> acuerdo salarios #> 7       6          1                         gremio -> levantó -> paro #> 8       6          2                 judiciales -> ratificaron -> paro #> 9       6          3                    CGT -> marchó -> críticas paro #> 10      7          1                     Ctera -> convocó -> paro país #>        sujeto       verbo                 objeto #> 1  Sindicatos     marchan        ciudades cambio #> 2     gremios    convocan                   paro #> 3     gremios    rechazan        aulas garantías #> 4   estatales  rechazaron oferta gobierno Chubut #> 5         CGT    presiona          indemnización #> 6         CTA  rechazaron       acuerdo salarios #> 7      gremio     levantó                   paro #> 8  judiciales ratificaron                   paro #> 9         CGT      marchó          críticas paro #> 10      Ctera     convocó              paro país"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"acep_sp","dir":"Articles","previous_headings":"Función acep_svo()","what":"acep_sp","title":"Extraer S-V-O con ACEP","text":"Este marco de datos contiene los ‘sujetos’ y los ‘predicados’ identificados en cada oración y una aproximación ‘entidades’, ‘sustantivos’ y ‘verbos auxiliares’ como contexto que ayuda mejorar la extracción de sujetos y objetos de la acción.","code":"head(titulares_svo$acep_sp, n=10) #>    doc_id oracion_id                 sujeto #> 1       1          1 Sindicatos estudiantes #> 2       1          2                gremios #> 3       2          1       gremios docentes #> 4       3          1              estatales #> 5       4          1                    CGT #> 6       5          1          CTA Izquierda #> 7       6          1           gremio aéreo #> 8       6          2             judiciales #> 9       6          3                    CGT #> 10      7          1                  Ctera #>                                                                        predicado #> 1  marchan principales ciudades México exigir cambio política económica Gobierno #> 2               convocan paro docente presencialidad Larreta Ciudad Buenos Aires #> 3                                     rechazan volver aulas garantías sanitarias #> 4                                     rechazaron oferta salarial gobierno Chubut #> 5                              presiona que empleados cobren doble indemnización #> 6                                        rechazaron acuerdo CGT rebajar salarios #> 7                                                           levantó paro Tucumán #> 8                                                               ratificaron paro #> 9                                     marchó críticas economía evalúa llama paro #> 10                                                       convocó paro horas país #>          verbo  lemma_verb         aux_verbos #> 1      marchan     marchan         | exigir | #> 2     convocan    convocan             | NA | #> 3     rechazan    rechazan         | volver | #> 4   rechazaron  rechazaron             | NA | #> 5     presiona    presiona         | cobren | #> 6   rechazaron  rechazaron        | rebajar | #> 7      levantó     levantó             | NA | #> 8  ratificaron ratificaron             | NA | #> 9       marchó      marchó | evalúa | llama | #> 10     convocó     convocó             | NA | #>                                entidades #> 1                             | México | #> 2  | Larreta | Ciudad | Buenos | Aires | #> 3                                 | NA | #> 4                             | Chubut | #> 5                                | CGT | #> 6                          | CTA | CGT | #> 7                            | Tucumán | #> 8                                 | NA | #> 9                                | CGT | #> 10                             | Ctera | #>                                                    sust_pred #> 1           ciudades | México | cambio | política | Gobierno #> 2  paro | presencialidad | Larreta | Ciudad | Buenos | Aires #> 3                                          aulas | garantías #> 4                                 oferta | gobierno | Chubut #> 5                                  empleados | indemnización #> 6                                   acuerdo | CGT | salarios #> 7                                             paro | Tucumán #> 8                                                       paro #> 9                                 críticas | economía | paro #> 10                                       paro | horas | país"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"acep_lista_lemmas","dir":"Articles","previous_headings":"Función acep_svo()","what":"acep_lista_lemmas","title":"Extraer S-V-O con ACEP","text":"Este marco de datos es un análisis de frecuencias absolutas de lemmas presentes en el corpus procesado.","code":"head(titulares_svo$acep_lista_lemmas, n=10) #>       lemma n #> 45     paro 5 #> 7       CGT 3 #> 28   gremio 3 #> 52 rechazar 3 #> 9    ciudad 2 #> 13 convocar 2 #> 18  docente 2 #> 27 gobierno 2 #> 38  marchar 2 #> 1   acuerdo 1"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"acep_no_procesadas","dir":"Articles","previous_headings":"Función acep_svo()","what":"acep_no_procesadas","title":"Extraer S-V-O con ACEP","text":"Este marco de datos contiene las oraciones que pudieron ser procesadas por ser posible identificar sujeto y predicado.","code":"head(titulares_svo$acep_no_procesadas, n=10) #> Key: <doc_id, oracion_id> #>    doc_id oracion_id                                                 oracion #>     <int>      <int>                                                  <char> #> 1:      8          1 Conciliación obligatoria en el conflicto del neumático. #> 2:      9          1                                             Hola mundo."},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_de_svo_con_acep.html","id":"nota-final","dir":"Articles","previous_headings":"","what":"Nota final","title":"Extraer S-V-O con ACEP","text":"Los resultados obtenidos en este ejemplo son muy prometedores, pero la realidad es que la bondad de los resultados está determinada por la complejidad de las oraciones. Es verdad que los textos ingresados en este ejemplo fueron tomados de portales de noticias, pero también es verdad que todos los títulos son igual de descriptivos y muchos son oraciones unimembres. Sin embargo, con los cuidados del caso, los resultados arrojados por la función acep_svo() pueden ser muy útiles para una primera aproximación exploratoria de eventos de protesta en un corpus extenso de notas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_palabras_clave.html","id":"introducción","dir":"Articles","previous_headings":"","what":"Introducción","title":"Extracción de palabas clave","text":"En este artículo presentamos las utilidades de la función acep_extract() para la extracción de palabras clave en un corpus de notas sobre la conflictividad laboral en la industria pesquera argentina con un enfoque de diccionario.","code":""},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_palabras_clave.html","id":"el-corpus-de-notas","dir":"Articles","previous_headings":"","what":"El corpus de notas","title":"Extracción de palabas clave","text":"Las notas que componen el corpus utilizado en este ejercicio fueron raspadas del sitio revistapuerto.com.ar con las funciones del paquete rvest. Se compone de 7816 notas y 6 variables: fecha, titulo, bajada, nota, imagen, link. El corpus de notas cubre desde el 2 de marzo de 2009 hasta el 29 de diciembre de 2020. Para cargar todas las notas haremos uso de la función acep_load_base().","code":"# Cargamos la librería ACEP library(ACEP)  # Definimos la url url <- acep_bases$rp_mdp  # Descargamos el corpus de notas de la Revista Puerto rev_puerto <- acep_load_base(url)  # Imprimimos la base en consola rev_puerto #> # A tibble: 7,816 × 6 #>    fecha      titulo                                   bajada nota  imagen link  #>  * <date>     <chr>                                    <chr>  <chr> <chr>  <chr> #>  1 2020-12-29 ¡Feliz Año 2021 para todos nuestros ami… Con m… \"Con… https… http… #>  2 2020-12-28 Mapa del trabajo esclavo en aguas inter… Un re… \"El … https… http… #>  3 2020-12-24 Plantas piden tener garantizada la prov… En Ch… \"El … https… http… #>  4 2020-12-24 Los obreros navales despiden el año ana… En Ma… \"El … https… http… #>  5 2020-12-23 El incumplimiento del régimen de cuotif… Se ll… \"Las… https… http… #>  6 2020-12-23 Otro fallo ratifica cautelar contra el … La Cá… \"La … https… http… #>  7 2020-12-22 Recomendaciones de SENASA para las expo… Desde… \"En … https… http… #>  8 2020-12-22 Trelew consolida su inserción en la ind… En 20… \"Ins… https… http… #>  9 2020-12-21 El CFP presentó el estado y la captura … En la… \"Ant… https… http… #> 10 2020-12-21 La flota amarilla cierra el año con sos… Puert… \"El … https… http… #> # ℹ 7,806 more rows"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_palabras_clave.html","id":"los-diccionarios","dir":"Articles","previous_headings":"","what":"Los diccionarios","title":"Extracción de palabas clave","text":"Una vez descargada la base de notas vamos crear variables numéricas y una de carácter que contenga las frecuencias de palabras totales, la frecuencia de palabras de cada diccionario usado para cada una de las notas y las palabras clave mencionadas en cada nota. En esta parte del código haremos uso de tres funciones y un diccionario del paquete ACEP: acep_count(), acep_extract(), acep_load_base() y acep_diccionarios. También crearemos dos diccionarios breves para usarlos en las funciones acep_count() y acep_extract(), con un doble objetivo: 1) identificar las notas que refieran huelgas; 2) identificar las notas que refieran lxs trabajadorxs del procesamiento de pescado en tierra en la ciudad de Mar del Plata. Ahora vamos usar las función acep_extract() para extraer las palabras clave de los diccionarios de conflictividad, huelgas y SOIP que aparecen en cada una de las notas de la Revista Puerto.","code":"# Cargamos el diccionario de palabras que refieren a conflictividad dicc_conflictos <- acep_load_base(acep_diccionarios$dicc_confl_sismos)  # Creamos la variable con la frecuencia de palabras que refieren a conflictividad rev_puerto$frec_conflictos <- acep_count(rev_puerto$nota, dicc_conflictos)  # Creamos el diccionario de palabras que refieren a huelgas dicc_huelgas <- c(\"en paro\", \"al paro\", \"huelga\", \"huelguistas\", \"paro y movil\",                   \"paro de actividades\", \"conciliación obligatoria\", \"un paro\",                    \"paro total\", \"paro parcial\", \"trabajo a reglamento\",                    \"el paro\", \"de brazos caídos\")  # Creamos la variable con la frecuencia de palabras que refieren a huelgas rev_puerto$frec_huelgas <- acep_count(rev_puerto$nota, dicc_huelgas)  # Creamos el diccionario de palabras que refieren a lxs obrerxs del pescado dicc_soip <- c(\"soip\", \"sindicato obrero de la industria del pescado\",                 \"sindicato de la industria del pescado\", \"huelguistas\",                 \"obreras de la industria del pescado\", \"obreras del pescado\",                \"obreros de la industria del pescado\", \"obreros del pescado\",                \"fileteros\", \"fileteras\", \"obreros del filet\", \"obreras del filet\")  # Creamos la variable con la frecuencia de palabras que  # refieren a lxs obrerxs del pescado rev_puerto$frec_soip <- acep_count(rev_puerto$nota, dicc_soip)  # Imprimimos la base en consola rev_puerto #> # A tibble: 7,816 × 9 #>    fecha      titulo      bajada nota  imagen link  frec_conflictos frec_huelgas #>    <date>     <chr>       <chr>  <chr> <chr>  <chr>           <int>        <int> #>  1 2020-12-29 ¡Feliz Año… Con m… \"Con… https… http…               0            0 #>  2 2020-12-28 Mapa del t… Un re… \"El … https… http…               3            0 #>  3 2020-12-24 Plantas pi… En Ch… \"El … https… http…               3            0 #>  4 2020-12-24 Los obrero… En Ma… \"El … https… http…               7            0 #>  5 2020-12-23 El incumpl… Se ll… \"Las… https… http…               4            1 #>  6 2020-12-23 Otro fallo… La Cá… \"La … https… http…               6            0 #>  7 2020-12-22 Recomendac… Desde… \"En … https… http…               0            0 #>  8 2020-12-22 Trelew con… En 20… \"Ins… https… http…               4            0 #>  9 2020-12-21 El CFP pre… En la… \"Ant… https… http…               4            0 #> 10 2020-12-21 La flota a… Puert… \"El … https… http…               5            0 #> # ℹ 7,806 more rows #> # ℹ 1 more variable: frec_soip <int> # Creamos la variable con las palabras que refieren a conflictividad rev_puerto$extract_conflictos <- acep_extract(rev_puerto$nota, dicc_conflictos, izq = \"\")  # Creamos la variable con las palabras que refieren a huelgas rev_puerto$extract_huelgas <- acep_extract(rev_puerto$nota, dicc_huelgas)  # Creamos la variable con las palabras que  # refieren a lxs obrerxs del pescado rev_puerto$extract_soip <- acep_extract(rev_puerto$nota, dicc_soip)  # Imprimimos la base en consola rev_puerto #> # A tibble: 7,816 × 12 #>    fecha      titulo      bajada nota  imagen link  frec_conflictos frec_huelgas #>    <date>     <chr>       <chr>  <chr> <chr>  <chr>           <int>        <int> #>  1 2020-12-29 ¡Feliz Año… Con m… \"Con… https… http…               0            0 #>  2 2020-12-28 Mapa del t… Un re… \"El … https… http…               3            0 #>  3 2020-12-24 Plantas pi… En Ch… \"El … https… http…               3            0 #>  4 2020-12-24 Los obrero… En Ma… \"El … https… http…               7            0 #>  5 2020-12-23 El incumpl… Se ll… \"Las… https… http…               4            1 #>  6 2020-12-23 Otro fallo… La Cá… \"La … https… http…               6            0 #>  7 2020-12-22 Recomendac… Desde… \"En … https… http…               0            0 #>  8 2020-12-22 Trelew con… En 20… \"Ins… https… http…               4            0 #>  9 2020-12-21 El CFP pre… En la… \"Ant… https… http…               4            0 #> 10 2020-12-21 La flota a… Puert… \"El … https… http…               5            0 #> # ℹ 7,806 more rows #> # ℹ 4 more variables: frec_soip <int>, extract_conflictos <chr>, #> #   extract_huelgas <chr>, extract_soip <chr>"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_palabras_clave.html","id":"las-palabras-clave-extraídas","dir":"Articles","previous_headings":"","what":"Las palabras clave extraídas","title":"Extracción de palabas clave","text":"Ya construidas las variables nos ocuparemos de poner el foco en el rendimiento de la función acep_extract(). Seleccionaremos las columnas referidas las extracciones de conflictos y huelgas. Veamos.","code":"# Seleccionamos las variables de extracción de palabras clave rev_puerto_huelgas <- rev_puerto[rev_puerto$extract_huelgas != \"\",] rev_puerto_soip <- rev_puerto_huelgas[rev_puerto_huelgas$extract_soip != \"\",] rev_puerto_seleccion <- rev_puerto_soip[ , c('extract_conflictos', 'extract_huelgas', 'extract_soip')]  # Imprimimos la base en consola rev_puerto_seleccion #> # A tibble: 76 × 3 #>    extract_conflictos                               extract_huelgas extract_soip #>    <chr>                                            <chr>           <chr>        #>  1 amenazaba; conflicto; conciliación obligatoria;… conciliación o… obreros del… #>  2 piquete; conciliación obligatoria; conflictos; … conciliación o… obreros del… #>  3 reclama; reclamo; reclamando; retención de tare… conciliación o… fileteros; … #>  4 concentración; quema; paro; exigiera; concentra… un paro         fileteros    #>  5 se manifestaron; reclamaron; denunciaron; manif… conciliación o… fileteros    #>  6 paro                                             un paro         obreros del… #>  7 paro; rechazo; acatamiento; medida de fuerza; p… al paro; al pa… fileteros    #>  8 reclaman; reclamo; se manifestaron; exigir; con… conciliación o… fileteros    #>  9 paro; paró; paró; lucha; paró; lucha; reclamo    del paro        fileteros    #> 10 reclamaban; paro                                 el paro         fileteros    #> # ℹ 66 more rows"},{"path":"https://agusnieto77.github.io/ACEP/articles/extraccion_palabras_clave.html","id":"nota-final","dir":"Articles","previous_headings":"","what":"Nota final","title":"Extracción de palabas clave","text":"lo largo de este breve tutorial sobre la función acep_extract() del paquete ACEP buscamos ejemplificar de qué modo puede ser usada esta función para individualizar cada una de las palabras clave que fueron contabilizadas en las notas con la función acep_count().","code":""},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"to-lower","dir":"Articles","previous_headings":"","what":"to lower","title":"Limpieza de texto con ACEP","text":"El parámetro tolower refiere llevar todo el texto minúscula. Teniendo en cuenta que R es un software “case sensitive” (es decir, sensible las mayúsculas y minúsculas) resulta de interés que todas las palabras queden en minúscula para que al realizar un conteo, se consideren distintas las palabras que difieran en el tipeo de mayúscula o minúscula. Lo que haremos será aislar cada uno de los parámetros, poniéndolos en FALSE excepción del que queremos probar. En primer lugar cargamos la base de ejemplo: Seleccionemos ahora tan sólo un tweet: Vemos que tiene algunas letras en mayúscula. Aplicamos el parámetro tolower de la función acep_clean() y verificamos el resultado. Efectivamente, los caracteres en mayúscula pasan minúscula.","code":"library(ACEP)  url <- \"https://observatoriodeconflictividad.org/basesdatos/la_fraternidad.rds\"  base <- base::subset(acep_load_base(url), select = text)$text primer_tweet <- base[2]  primer_tweet #> [1] \"👉PROTESTA/La Fraternidad desoye conciliación obligatoria y mantiene paralizados los trenes\\nhttps://t.co/644Ak0HZ7I\" minus <- acep_clean(primer_tweet,                tolower = TRUE,                rm_cesp = FALSE,                rm_emoji = FALSE,                rm_hashtag = FALSE,                rm_users = FALSE,                rm_punt = FALSE,                rm_num = FALSE,                rm_url = FALSE,                rm_meses = FALSE,                rm_dias = FALSE,                rm_stopwords = FALSE,                rm_shortwords = FALSE,                rm_newline = FALSE,                rm_whitespace = FALSE,                other_sw = NULL)  cat(paste(\"****SIN tolower****\\n\", primer_tweet, \"****\\n\", sep=\"\")) #> ****SIN tolower**** #> 👉PROTESTA/La Fraternidad desoye conciliación obligatoria y mantiene paralizados los trenes #> https://t.co/644Ak0HZ7I**** cat(paste(\"****CON tolower****\\n\", minus, \"****\\n\", sep=\"\")) #> ****CON tolower**** #> 👉protesta/la fraternidad desoye conciliación obligatoria y mantiene paralizados los trenes #> https://t.co/644ak0hz7i****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"rm_cesp","dir":"Articles","previous_headings":"","what":"rm_cesp","title":"Limpieza de texto con ACEP","text":"El parámetros rm_cesp refiere los caracteres especiales. Es común que en una base conformada por tweets (aunque solamente) aparezcan muchos caracteres especiales tales como tildes. Estos caracteres hacen ningún aporte al análisis semántico por lo que es conveniente removerlos. Al igual que el caso anterior, aislamos el parámetro rm_cesp. En este caso hay sólo una tilde en “conciliación” y fue removida.","code":"cesp <- acep_clean(primer_tweet,                      tolower = FALSE,                      rm_cesp = TRUE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = FALSE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_cesp****\\n\", primer_tweet, \"****\\n\", sep=\"\")) #> ****SIN rm_cesp**** #> 👉PROTESTA/La Fraternidad desoye conciliación obligatoria y mantiene paralizados los trenes #> https://t.co/644Ak0HZ7I**** cat(paste(\"****CON rm_cesp****\\n\", cesp, \"****\\n\", sep=\"\")) #> ****CON rm_cesp**** #> 👉PROTESTA/La Fraternidad desoye conciliacion obligatoria y mantiene paralizados los trenes #> https://t.co/644Ak0HZ7I****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"emoji","dir":"Articles","previous_headings":"","what":"Emoji","title":"Limpieza de texto con ACEP","text":"Es común que aparezcan emojis en tweets o texto obtenido través de redes sociales. Estos caracteres puede ser problemáticos para el análisis de texto y por este motivo se remueven con el parámetro rm_emoji.","code":"emoji <- acep_clean(primer_tweet,                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = TRUE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = FALSE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_emoji****\\n\", primer_tweet, \"***\\n\", sep=\"\")) #> ****SIN rm_emoji**** #> 👉PROTESTA/La Fraternidad desoye conciliación obligatoria y mantiene paralizados los trenes #> https://t.co/644Ak0HZ7I*** cat(paste(\"****CON rm_emoji****\\n\", emoji, \"****\\n\", sep=\"\")) #> ****CON rm_emoji**** #>  PROTESTA/La Fraternidad desoye conciliación obligatoria y mantiene paralizados los trenes #> https://t.co/644Ak0HZ7I****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"hashtag","dir":"Articles","previous_headings":"","what":"Hashtag","title":"Limpieza de texto con ACEP","text":"Los #hashtags son muy comunes en los textos de redes sociales. Son también caracteres que esconden palabras cuando realizamos un análisis semántico. Para removerlos, utilizamos el parámetro rm_hashtag. Utilizamos otro tweet de la base que contiene #hashtag NOTA: se elimina todo el #hashtags, sólo el símbolo (#Transporte)","code":"con_hash <- base[40] hash <- acep_clean(base[40],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = TRUE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = FALSE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_hashtag****\\n\", con_hash, \"****\\n\", sep=\"\")) #> ****SIN rm_hashtag**** #> #Transporte | El gremio de los ferroviarios realiza un paro desde las 00hs en el marco de un conflicto por el reclamo del pago de un bono de 50 mil pesos a jubilados y pensionados. Miles de usuarios se ven afectados. #> https://t.co/1bHDoEVS76**** cat(paste(\"****CON rm_hashtag****\\n\", hash, \"****\\n\", sep=\"\")) #> ****CON rm_hashtag**** #>  | El gremio de los ferroviarios realiza un paro desde las 00hs en el marco de un conflicto por el reclamo del pago de un bono de 50 mil pesos a jubilados y pensionados. Miles de usuarios se ven afectados. #> https://t.co/1bHDoEVS76****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"users","dir":"Articles","previous_headings":"","what":"Users","title":"Limpieza de texto con ACEP","text":"La mención de usuarios es algo que suele aparecer en análisis de texto en redes. Respuestas otros tweets o menciones usuarios que queremos remover. Para esto utilizamos el parámetro rm_users NOTA: Igual que con el #hashtag, quita todo, sólo el símbolo @","code":"con_user <- base[12] user <- acep_clean(base[12],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = TRUE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = FALSE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_users****\\n\", con_user, \"****\\n\", sep=\"\")) #> ****SIN rm_users**** #> @TrenesArg Estaría bueno que empiecen por corroborar las empresas tercerizadas dónde la mayoría de los principales accionistas forman parte de la fraternidad. También son tan forros que discriminan a los trabajadores que se la pasan caminando en las vías para que el servicio funcione.**** cat(paste(\"****CON rm_users****\\n\", user, \"****\\n\", sep=\"\")) #> ****CON rm_users**** #>  Estaría bueno que empiecen por corroborar las empresas tercerizadas dónde la mayoría de los principales accionistas forman parte de la fraternidad. También son tan forros que discriminan a los trabajadores que se la pasan caminando en las vías para que el servicio funcione.****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"puntuación","dir":"Articles","previous_headings":"","what":"Puntuación","title":"Limpieza de texto con ACEP","text":"La puntuación son caracteres que pueden aparecer muchísimas veces, pero nuevamente, aportan la compresión lectora pero al conteo de palabras o análisis semántica. La podemos remover con el parámetro rm_punt.","code":"punt <- base[13] s_punt <- acep_clean(base[13],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = TRUE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = FALSE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_punt****\\n\", punt, \"****\\n\", sep=\"\")) #> ****SIN rm_punt**** #> Sociedad: Paro de trenes: La Fraternidad no acató la conciliación y no habrá servicio en el país #> ✍️por Agostina Carlesso  #> 👉https://t.co/WI6mzHYM1i #> #InformacionEsPoder**** cat(paste(\"****CON rm_punt****\\n\", s_punt, \"****\\n\", sep=\"\")) #> ****CON rm_punt**** #> Sociedad  Paro de trenes  La Fraternidad no acató la conciliación y no habrá servicio en el país #> ✍ por Agostina Carlesso  #> 👉https   t co WI6mzHYM1i #> #InformacionEsPoder****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"números","dir":"Articles","previous_headings":"","what":"Números","title":"Limpieza de texto con ACEP","text":"Siguiendo la misma lógica, los números aportan información relevante y requieren ser limpiados de nuestra base. Más aún en análisis de texto obtenido través de redes sociales, ya sea por nombres de usuario o información codificada, aparece una gran cantidad de números. Se remueve con el parámetro rm_num.","code":"num <- base[70] num_s <- acep_clean(base[70],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = TRUE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = FALSE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_num****\\n\", num, \"****\\n\", sep=\"\")) #> ****SIN rm_num**** #> Del 14 al 20 de noviembre celebramos la V #FMSemanaSVL bajo el lema “Cede el paso a una conducción segura”.  #>  #> Este año contaremos con grandes profesionales en nuestras jornadas virtuales y presenciales. #>  #>  Consulta aquí todo el programa 🔗https://t.co/rXOewZj0ih  #>  #> ¡Te esperamos! https://t.co/vJHkN3nYFo**** cat(paste(\"****CON rm_num****\\n\", num_s, \"****\\n\", sep=\"\")) #> ****CON rm_num**** #> Del  al  de noviembre celebramos la V #FMSemanaSVL bajo el lema “Cede el paso a una conducción segura”.  #>  #> Este año contaremos con grandes profesionales en nuestras jornadas virtuales y presenciales. #>  #>  Consulta aquí todo el programa 🔗https://t.co/rXOewZjih  #>  #> ¡Te esperamos! https://t.co/vJHkNnYFo****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"urls","dir":"Articles","previous_headings":"","what":"URLs","title":"Limpieza de texto con ACEP","text":"Las URLs aparecen comúnmente, links o imágenes que se codifican como urls. Para removerlas usamos el parámetro rm_url","code":"num <- base[70] num_s <- acep_clean(base[70],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = TRUE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = FALSE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_url****\\n\", num, \"****\\n\", sep=\"\")) #> ****SIN rm_url**** #> Del 14 al 20 de noviembre celebramos la V #FMSemanaSVL bajo el lema “Cede el paso a una conducción segura”.  #>  #> Este año contaremos con grandes profesionales en nuestras jornadas virtuales y presenciales. #>  #>  Consulta aquí todo el programa 🔗https://t.co/rXOewZj0ih  #>  #> ¡Te esperamos! https://t.co/vJHkN3nYFo**** cat(paste(\"****CON rm_url****\\n\", num_s,  \"****\\n\", sep=\"\")) #> ****CON rm_url**** #> Del 14 al 20 de noviembre celebramos la V #FMSemanaSVL bajo el lema “Cede el paso a una conducción segura”.  #>  #> Este año contaremos con grandes profesionales en nuestras jornadas virtuales y presenciales. #>  #>  Consulta aquí todo el programa 🔗  #>  #> ¡Te esperamos! ****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"meses","dir":"Articles","previous_headings":"","what":"Meses","title":"Limpieza de texto con ACEP","text":"En el caso de querer remover meses del año, podemos utilizar el parámetro rm_meses. En este caso, el tweet tiene la palabra “noviembre”","code":"meses <- base[70] meses_s <- acep_clean(base[70],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = TRUE,                      rm_dias = FALSE,                      rm_stopwords = FALSE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_mes****\\n\", meses, \"****\\n\", sep=\"\")) #> ****SIN rm_mes**** #> Del 14 al 20 de noviembre celebramos la V #FMSemanaSVL bajo el lema “Cede el paso a una conducción segura”.  #>  #> Este año contaremos con grandes profesionales en nuestras jornadas virtuales y presenciales. #>  #>  Consulta aquí todo el programa 🔗https://t.co/rXOewZj0ih  #>  #> ¡Te esperamos! https://t.co/vJHkN3nYFo**** cat(paste(\"****CON rm_mes****\\n\", meses_s, \"****\\n\", sep=\"\")) #> ****CON rm_mes**** #> Del 14 al 20 de  celebramos la V #FMSemanaSVL bajo el lema “Cede el paso a una conducción segura”.  #>  #> Este año contaremos con grandes profesionales en nuestras jornadas virtuales y presenciales. #>  #>  Consulta aquí todo el programa 🔗https://t.co/rXOewZj0ih  #>  #> ¡Te esperamos! https://t.co/vJHkN3nYFo****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"días","dir":"Articles","previous_headings":"","what":"Días","title":"Limpieza de texto con ACEP","text":"En el caso de querer remover días de la semana, podemos utilizar el parámetro rm_dias. En este caso, el tweet tiene la palabra “martes”","code":"dia <- base[429] dia_s <- acep_clean(base[429],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = TRUE,                      rm_stopwords = FALSE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_dias****\\n\", dia, \"****\\n\", sep=\"\")) #> ****SIN rm_dias**** #> Paro de trenes: el sindicato de la Fraternidad no acatará la conciliación obligatoria que dictó el ministerio de Trabajo y este martes no habrá servicio - Infobae https://t.co/0YH6FDeGXN**** cat(paste(\"****CON rm_dias****\\n\", dia_s, \"****\\n\", sep=\"\")) #> ****CON rm_dias**** #> Paro de trenes: el sindicato de la Fraternidad no acatará la conciliación obligatoria que dictó el ministerio de Trabajo y este  no habrá servicio - Infobae https://t.co/0YH6FDeGXN****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"stop-words","dir":"Articles","previous_headings":"","what":"Stop words","title":"Limpieza de texto con ACEP","text":"Las stopwords son palabras que tienen distintas funciones aportando la comprensión del texto. Sin embargo, si buscamos realizar un conteo de palabras, resultan contraproducentes ya que se repiten muchas veces y aportan al contenido. Se pueden remover con el parámetro rm_stopwords. La lista de las palabras consideradas “stop words” puede verificarse en el siguiente link: stopwords <- readRDS(url(“https://github.com/HDyCSC/datos/raw/222dd7c060fabc2904c1ceffbea6958f9a275b57/stopwords.rds”))","code":"url <- \"https://github.com/HDyCSC/datos/raw/222dd7c060fabc2904c1ceffbea6958f9a275b57/stopwords.rds\" stopwords <- acep_clean(url) stopw <- base[429] stopw_w <- acep_clean(base[429],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = TRUE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_stopwords****\\n\", stopw, \"****\\n\", sep=\"\")) #> ****SIN rm_stopwords**** #> Paro de trenes: el sindicato de la Fraternidad no acatará la conciliación obligatoria que dictó el ministerio de Trabajo y este martes no habrá servicio - Infobae https://t.co/0YH6FDeGXN**** cat(paste(\"****CON rm_stopwords****\\n\", stopw_w, \"****\\n\", sep=\"\")) #> ****CON rm_stopwords**** #> Paro   trenes:   sindicato     Fraternidad   acatará   conciliación obligatoria   dictó   ministerio   Trabajo     martes     servicio - Infobae https://t.co/0YH6FDeGXN****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"short-words","dir":"Articles","previous_headings":"","what":"Short words","title":"Limpieza de texto con ACEP","text":"En caso de querer eliminar las palabras de 1 sólo caracter que pueden quedar como “residuos” de limpiezas previas y que probablemente tengan contenido útil, lo hacemos con el parámetro rm_shortwords.","code":"short <- base[97] short_s <- acep_clean(base[97],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = FALSE,                      rm_shortwords = TRUE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_shortwords****\\n\", short, \"****\\n\", sep=\"\")) #> ****SIN rm_shortwords**** #> @GusDeheza @PolloSobrero NO es un paro de la Fraternidad y x primera vez en mi vida ESTOY DE ACUERDO ..es un apoyo a los JUBILADOS.para q le den un bono a fin de año...jamás nadie se acordó de apoyar a los jubilados x primera vez un gremio rompe un pacto con la CGT..ya q no querían .**** cat(paste(\"****CON rm_shortwords****\\n\", short_s, \"****\\n\", sep=\"\")) #> ****CON rm_shortwords**** #> @GusDeheza @PolloSobrero NO es un paro de la Fraternidad     primera vez en mi vida ESTOY DE ACUERDO ..es un apoyo   los JUBILADOS.para   le den un bono   fin de año...jamás nadie se acordó de apoyar   los jubilados   primera vez un gremio rompe un pacto con la CGT..ya   no querían .****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"new-line","dir":"Articles","previous_headings":"","what":"New line","title":"Limpieza de texto con ACEP","text":"El parámetro rm_newline se utiliza en caso de querer eliminar los saltos de línea. En este ejemplo hay un salgo de línea antes del link del final del tweet.","code":"newl <- base[2] newl_s <- acep_clean(base[2],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = FALSE,                      rm_shortwords = FALSE,                      rm_newline = TRUE,                      rm_whitespace = FALSE,                      other_sw = NULL)  cat(paste(\"****SIN rm_newline****\\n\",newl, \"****\\n\", sep=\"\")) #> ****SIN rm_newline**** #> 👉PROTESTA/La Fraternidad desoye conciliación obligatoria y mantiene paralizados los trenes #> https://t.co/644Ak0HZ7I**** cat(paste(\"****CON rm_newline****\\n\",newl_s, \"****\\n\", sep=\"\")) #> ****CON rm_newline**** #> 👉PROTESTA/La Fraternidad desoye conciliación obligatoria y mantiene paralizados los trenes https://t.co/644Ak0HZ7I****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"whitespace","dir":"Articles","previous_headings":"","what":"Whitespace","title":"Limpieza de texto con ACEP","text":"Ya sea porque los usuarios tipean dobles espacios por error o por limpiezas previas, suelen quedar espacios en blanco en los textos que ayudan la legibilidad del texto. El parámetro rm_whitespace elimina los espacios en blanco. En este ejemplo, entre “en nuestro” hay un doble espacio.","code":"white <- base[60] white_s <- acep_clean(base[60],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = FALSE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = TRUE,                      other_sw = NULL)  cat(paste(\"****SIN rm_whitespace****\\n\", white, \"****\\n\", sep=\"\")) #> ****SIN rm_whitespace**** #> El @INSST_MITES_GOB presenta 3 infografías con datos estadísticos sobre los accidentes de trabajo en  nuestro país.  #>  #> Consulta toda la info en https://t.co/piMaTqoMiF https://t.co/lcJe8ed0x4**** cat(paste(\"****CON rm_whitespace****\\n\", white_s, \"****\\n\", sep=\"\")) #> ****CON rm_whitespace**** #> El @INSST_MITES_GOB presenta 3 infografías con datos estadísticos sobre los accidentes de trabajo en nuestro país.  #>  #> Consulta toda la info en https://t.co/piMaTqoMiF https://t.co/lcJe8ed0x4****"},{"path":"https://agusnieto77.github.io/ACEP/articles/limpieza_de_texto_con_acep.html","id":"other-stop-words","dir":"Articles","previous_headings":"","what":"Other Stop words","title":"Limpieza de texto con ACEP","text":"Es posible que la lista de stop words sea exhaustiva. Si el usuario desea agregar palabras la lista de stop words, lo puede hacer con el parámetro other_sw. En este ejemplo, agregamos la palabra “Fraternidad” como stop word para que la detect y la remueva. Hay que tener en cuenta que para este caso, también debe estar en TRUE el parámetro “rm_stopwords”. Posteriormente, se agrega entre comillas la palabra de remover. En caso de querer agregar más de una palabra, se puede crear un vector string con cada una de las palabras separadas por coma. En este caso se agregan las palabras “conciliación” y “Fraternidad”.","code":"osw <- base[2] osw_s <- acep_clean(base[2],                      tolower = FALSE,                      rm_cesp = FALSE,                      rm_emoji = FALSE,                      rm_hashtag = FALSE,                      rm_users = FALSE,                      rm_punt = FALSE,                      rm_num = FALSE,                      rm_url = FALSE,                      rm_meses = FALSE,                      rm_dias = FALSE,                      rm_stopwords = TRUE,                      rm_shortwords = FALSE,                      rm_newline = FALSE,                      rm_whitespace = FALSE,                      other_sw = c(\"conciliación\", \"Fraternidad\"))  cat(paste(\"****SIN other_sw****\\n\", osw, \"****\\n\", sep=\"\")) #> ****SIN other_sw**** #> 👉PROTESTA/La Fraternidad desoye conciliación obligatoria y mantiene paralizados los trenes #> https://t.co/644Ak0HZ7I**** cat(paste(\"****CON other_sw****\\n\", osw_s, \"****\\n\", sep=\"\")) #> ****CON other_sw**** #> 👉PROTESTA/La   desoye   obligatoria   mantiene paralizados   trenes #> https://t.co/644Ak0HZ7I****"},{"path":"https://agusnieto77.github.io/ACEP/articles/tokenizar_con_acep.html","id":"funciones-a-presentar","dir":"Articles","previous_headings":"","what":"Funciones a presentar:","title":"Tokenizar con ACEP","text":"En este artículo se explicarán los procesos que realizan las funciones: acep_token() acep_token_table() acep_token_plot()","code":""},{"path":"https://agusnieto77.github.io/ACEP/articles/tokenizar_con_acep.html","id":"función-acep_token","dir":"Articles","previous_headings":"","what":"Función acep_token()","title":"Tokenizar con ACEP","text":"En primer lugar cargamos la librería ACEP. Luego, cargamos una base de tweets para su prueba. Ejecutamos la función acep_token() para los primeros dos elementos de la base. ¿Cuál es el resultado? La función acep_token toma el vector y realiza diferentes acciones: Verifica que el objeto entregado sea un vector (de lo contrario indica un mensaje de advertencia) Cambia todo el texto minúsculas Crea un nuevo data frame con la siguiente información: texto_id (columna que numera el documento) tokens (el token propiamente) Cabe mencionar que los tokens quedarán identificados través de los espacios en blanco, es decir, cada palabra es un token. En este resultado podemos ver cómo la función identifica cada observación como un documento aparte (en este caso, cada tweet es un documento identificado en la columna ‘texto_id’). Por su parte, la columna ‘tokens’ es la columna en la que la función aísla cada token.","code":"library(ACEP)  url <- \"https://github.com/HDyCSC/datos/raw/main/la_fraternidad.rds\"  base <- subset(acep_load_base(url), select = text)$text tweets <- acep_token(base[1:2])  head(tweets) #>   texto_id       tokens #> 1        1      googlea #> 2        1  fraternidad #> 3        2     protesta #> 4        2  fraternidad #> 5        2       desoye #> 6        2 conciliacion"},{"path":"https://agusnieto77.github.io/ACEP/articles/tokenizar_con_acep.html","id":"función-acep_token_table","dir":"Articles","previous_headings":"","what":"Función acep_token_table()","title":"Tokenizar con ACEP","text":"Una vez que tenemos el data frame creado partir de la función acep_token(), podemos utilizar la función acep_table() para obtener un nuevo data frame que nos proveerá la siguiente información: token frec (frecuencia que aparece ese token) prop (el peso que tiene ese token en el total del corpus) Para obtener una tabla que tenga sentido, podemos utilizar en primer lugar la función acep_clean() para deshacernos de los stopwords, urls, menciones, hashtags, etc. En segunda instancia, creamos un nuevo objeto derivado de la base limpia con acep_token() que nos devuelve, como vimos previamente, una tabla con la información de cada token. Por último, aplicamos la función acep_token_table() la columna ‘tokens’. Por defecto, acep_token_table() nos devuelve los 10 primeros registros, es decir, las 10 palabras con mayor frecuencia. Si quisiéramos modificar la cantidad de palabras, debemos modificar el parámetro ‘u’ = Suponiendo que queremos obtener los 20 token de mayor frecuencia: acep_token_table(tabla_tokenizada$token, u = 20)","code":"base_limpia <- acep_clean(base) tabla_tokenizada <- acep_token(base_limpia) head(tabla_tokenizada) #>   texto_id       tokens #> 1        1      googlea #> 2        1  fraternidad #> 3        2     protesta #> 4        2  fraternidad #> 5        2       desoye #> 6        2 conciliacion acep_token_table(tabla_tokenizada$tokens, u = 15) #>           token frec       prop #> 1   fraternidad 1956 0.47847358 #> 2        trenes  264 0.06457926 #> 3          paro  217 0.05308219 #> 4  conciliacion  184 0.04500978 #> 5           paz  175 0.04280822 #> 6   obligatoria  163 0.03987280 #> 7      libertad  160 0.03913894 #> 8      igualdad  157 0.03840509 #> 9            si  140 0.03424658 #> 10         amor  120 0.02935421 #> 11    universal  120 0.02935421 #> 12       fuerza  117 0.02862035 #> 13       medida  107 0.02617417 #> 14        mundo  106 0.02592955 #> 15          ser  102 0.02495108"},{"path":"https://agusnieto77.github.io/ACEP/articles/tokenizar_con_acep.html","id":"función-acep_token_plot","dir":"Articles","previous_headings":"","what":"Función acep_token_plot()","title":"Tokenizar con ACEP","text":"Esta función permite visualizar en un gráfico de barras, los tokens más frecuentes. partir del resultado de acep_token(), podemos obtener el gráfico con los tokens más frecuentes. Por defecto, el resultado serán los 10 tokens más frecuentes, sin embargo, través del parámetro “u =” podemos modificar la cantidad de tokens visualizar. En este ejemplo, tomamos la tabla tokenizada y le indicamos la columna “token” visualizar.","code":"acep_token_plot(tabla_tokenizada$tokens, u = 15)"},{"path":"https://agusnieto77.github.io/ACEP/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Agustín Nieto. Author, maintainer.","code":""},{"path":"https://agusnieto77.github.io/ACEP/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Nieto (2025). ACEP: Análisis Computacional de Eventos de Protesta. R package version 0.1.0.9000, https://github.com/agusnieto77/ACEP.","code":"@Manual{,   title = {ACEP: Análisis Computacional de Eventos de Protesta},   author = {Agustín Nieto},   year = {2025},   note = {R package version 0.1.0.9000},   url = {https://github.com/agusnieto77/ACEP}, }"},{"path":[]},{"path":"https://agusnieto77.github.io/ACEP/index.html","id":"vision-general","dir":"","previous_headings":"","what":"Vision general","title":"Análisis Computacional de Eventos de Protesta","text":"ACEP es un paquete de funciones en lenguaje R útiles para la detección y el análisis de eventos de protesta en corpus de textos periodísticos. Sus funciones son aplicables cualquier corpus de textos. Ademas de las funciones, ACEP contiene también bases de datos con colecciones de notas sobre protestas y una colección de diccionarios de palabras conflictivas y otros tópicos referidos diferentes aspectos del análisis de eventos de protesta.","code":""},{"path":"https://agusnieto77.github.io/ACEP/index.html","id":"instalacion-de-la-version-estable","dir":"","previous_headings":"","what":"Instalacion de la version estable","title":"Análisis Computacional de Eventos de Protesta","text":"Puedes instalar la versión estable de ACEP desde CRAN con:","code":"install.packages(\"ACEP\")"},{"path":"https://agusnieto77.github.io/ACEP/index.html","id":"instalacion-de-la-version-en-desarrollo","dir":"","previous_headings":"","what":"Instalacion de la version en desarrollo","title":"Análisis Computacional de Eventos de Protesta","text":"Puedes instalar la versión de desarrollo de ACEP desde GitHub con:","code":"# install.packages(\"devtools\") devtools::install_github(\"agusnieto77/ACEP\")"},{"path":[]},{"path":[]},{"path":"https://agusnieto77.github.io/ACEP/index.html","id":"corpus","dir":"","previous_headings":"","what":"Corpus","title":"Análisis Computacional de Eventos de Protesta","text":"Colección de notas del diario La Nación Subset de notas del diario La Nación Colección de notas del Ecos Diarios Colección de notas de la Revista Puerto Colección de notas del diario La Nueva Colección de notas del diario La Capital","code":""},{"path":"https://agusnieto77.github.io/ACEP/index.html","id":"bases-de-datos-de-eventos-de-protesta-disponibles-online","dir":"","previous_headings":"","what":"Bases de datos de Eventos de protesta disponibles online","title":"Análisis Computacional de Eventos de Protesta","text":"ACLED: Armed Conflict Location & Event Data Project. GDELT: GDELT Project . GPT: Global Protest Tracker. MMPD: Mass Mobilization Protest Data Project. NAVCO: Nonviolent Violent Campaigns Outcomes data project. NVCO: Global Nonviolent Action Database. SCAD: Social Conflict Analysis Database. SPEED: Social, Political Economic Event Database Project. UCDP: Uppsala Conflict Data Program.","code":""},{"path":"https://agusnieto77.github.io/ACEP/index.html","id":"bases-de-datos-de-interes-general","dir":"","previous_headings":"","what":"Bases de datos de interes general","title":"Análisis Computacional de Eventos de Protesta","text":"FMI: FMI Data. BM: Datos de libre acceso del Banco Mundial. OIT: Estadísticas y bases de datos. CEPAL: Datos y estadísticas. DARG: Datos abiertos de Argentina. MGP: Datos abiertos del Municipio de Gral. Pueyrredon, Buenos Aires, Argentina.","code":""},{"path":"https://agusnieto77.github.io/ACEP/index.html","id":"uso-de-las-funciones-del-paquete-acep-un-ejemplo","dir":"","previous_headings":"","what":"Uso de las funciones del paquete ACEP: un ejemplo.","title":"Análisis Computacional de Eventos de Protesta","text":"","code":"# Cargamos la librería require(ACEP)  # Cargamos la base de notas de la Revista Puerto con la función acep_load_base() rev_puerto <- acep_load_base(acep_bases$rp_mdp)  # Cargamos el diccionario de conflictos de SISMOS dicc_confl_sismos <- acep_diccionarios$dicc_confl_sismos  # Con la función acep_frec() contamos la frecuencia de palabras de cada nota # y creamos una nueva columna llamada  n_palabras rev_puerto$n_palabras <- acep_frec(rev_puerto$nota)  # Imprimimos en pantalla la base con la nueva columna de frecuencia de palabras head(rev_puerto) #> # A tibble: 6 × 7 #>   fecha      titulo                         bajada nota  imagen link  n_palabras #>   <date>     <chr>                          <chr>  <chr> <chr>  <chr>      <int> #> 1 2020-12-29 ¡Feliz Año 2021 para todos nu… Con m… \"Con… https… http…         28 #> 2 2020-12-28 Mapa del trabajo esclavo en a… Un re… \"El … https… http…       1142 #> 3 2020-12-24 Plantas piden tener garantiza… En Ch… \"El … https… http…        536 #> 4 2020-12-24 Los obreros navales despiden … En Ma… \"El … https… http…        489 #> 5 2020-12-23 El incumplimiento del régimen… Se ll… \"Las… https… http…        529 #> 6 2020-12-23 Otro fallo ratifica cautelar … La Cá… \"La … https… http…        467 # Ahora con la función acep_count() contamos la frecuencia de menciones de # términos del diccionario de conflictividad de SISMOS de cada nota y # creamos una nueva columna llamada  conflictos. # Elaboramos un corpus acotado para el ejemplo rev_puerto <- rev_puerto[1:100, ] rev_puerto$conflictos <- acep_count(rev_puerto$nota, dicc_confl_sismos)  # Imprimimos en pantalla la base con la nueva columna de # menciones del diccionario de conflictividad head(rev_puerto) #> # A tibble: 6 × 8 #>   fecha      titulo              bajada nota  imagen link  n_palabras conflictos #>   <date>     <chr>               <chr>  <chr> <chr>  <chr>      <int>      <int> #> 1 2020-12-29 ¡Feliz Año 2021 pa… Con m… \"Con… https… http…         28          0 #> 2 2020-12-28 Mapa del trabajo e… Un re… \"El … https… http…       1142          0 #> 3 2020-12-24 Plantas piden tene… En Ch… \"El … https… http…        536          0 #> 4 2020-12-24 Los obreros navale… En Ma… \"El … https… http…        489          0 #> 5 2020-12-23 El incumplimiento … Se ll… \"Las… https… http…        529          0 #> 6 2020-12-23 Otro fallo ratific… La Cá… \"La … https… http…        467          0 # Ahora con la función acep_int() calculamos un índice de intensidad de # la conflictividad y creamos una nueva columna llamada  intensidad rev_puerto$intensidad <- acep_int(   rev_puerto$conflictos,   rev_puerto$n_palabras,   3)  # Imprimimos en pantalla la base con la nueva columna de intensidad head(rev_puerto) #> # A tibble: 6 × 9 #>   fecha      titulo   bajada nota  imagen link  n_palabras conflictos intensidad #>   <date>     <chr>    <chr>  <chr> <chr>  <chr>      <int>      <int>      <dbl> #> 1 2020-12-29 ¡Feliz … Con m… \"Con… https… http…         28          0          0 #> 2 2020-12-28 Mapa de… Un re… \"El … https… http…       1142          0          0 #> 3 2020-12-24 Plantas… En Ch… \"El … https… http…        536          0          0 #> 4 2020-12-24 Los obr… En Ma… \"El … https… http…        489          0          0 #> 5 2020-12-23 El incu… Se ll… \"Las… https… http…        529          0          0 #> 6 2020-12-23 Otro fa… La Cá… \"La … https… http…        467          0          0 # Volvemos a cargar la base de notas de la Revista Puerto sin procesar rev_puerto <- acep_load_base(acep_bases$rp_mdp)  # Creamos un subset subset_rp <- rev_puerto[1:100, ]  # Cargamos el diccionario de conflictos de SISMOS dicc_confl_sismos <- acep_diccionarios$dicc_confl_sismos  # Ahora con la función acep_db() aplicamos las tres funciones en un solo paso rp_procesada <- acep_db(subset_rp, subset_rp$nota, dicc_confl_sismos, 3)  # Imprimimos en pantalla la base con las tres columna creadas head(rp_procesada) #> # A tibble: 6 × 9 #>   fecha      titulo   bajada nota  imagen link  n_palabras conflictos intensidad #>   <date>     <chr>    <chr>  <chr> <chr>  <chr>      <int>      <int>      <dbl> #> 1 2020-12-29 ¡Feliz … Con m… \"Con… https… http…         28          0          0 #> 2 2020-12-28 Mapa de… Un re… \"El … https… http…       1142          0          0 #> 3 2020-12-24 Plantas… En Ch… \"El … https… http…        536          0          0 #> 4 2020-12-24 Los obr… En Ma… \"El … https… http…        489          0          0 #> 5 2020-12-23 El incu… Se ll… \"Las… https… http…        529          0          0 #> 6 2020-12-23 Otro fa… La Cá… \"La … https… http…        467          0          0 # Cargamos los datos procesados rp_procesada <- acep_bases$rp_procesada  # Ahora con la función acep_sst() elaboramos un resumen estadístico rp_procesada <- acep_sst(rp_procesada, st = \"anio\", u = 4)  # Imprimimos en pantalla la base con las métricas de conflictividad head(rp_procesada) #>     st frecn csn  frecp frecm  intac intensidad int_notas_confl #> 1 2009   632  58 496110  1025 1.2735     0.0021          0.0918 #> 2 2010   680  67 492231  1129 1.6273     0.0023          0.0985 #> 3 2011   601  40 425747   882 1.2204     0.0021          0.0666 #> 4 2012   739  67 564270  1242 1.6841     0.0022          0.0907 #> 5 2013   689  24 525718   758 1.0559     0.0014          0.0348 #> 6 2014   631  30 444823   802 1.2112     0.0018          0.0475 # Ahora con la función acep_plot_st() elaboramos un gráfico de barras # con menciones del diccionario de conflictividad acep_plot_st(rp_procesada$st, rp_procesada$frecm,  t = \"Evolucion de la conflictividad en el sector pesquero argentino\",  ejex = \"A\\u00f1os analizados\",  ejey = \"Menciones del diccionario de conflictos\",  etiquetax = \"horizontal\") # Ahora con la función acep_plot_rst() elaboramos una visualización resumen. # con cuatro gráficos de barras acep_plot_rst(rp_procesada, tagx = \"vertical\")"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_bases.html","id":null,"dir":"Reference","previous_headings":"","what":"Coleccion de notas y recursos de prueba — acep_bases","title":"Coleccion de notas y recursos de prueba — acep_bases","text":"Lista con fuentes de datos y muestras preprocesadas utilizadas en los ejemplos del paquete. Incluye enlaces de descarga para distintos portales, resumenes estadisticos y conjuntos anotados manualmente que permiten evaluar diccionarios, extraccion de tripletes y desempeno de modelos generativos.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_bases.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coleccion de notas y recursos de prueba — acep_bases","text":"","code":"data(acep_bases)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_bases.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Coleccion de notas y recursos de prueba — acep_bases","text":"Lista con 11 objetos: la_nueva URL para descargar una muestra del corpus de notas del diario La Nueva Provincia de Bahia Blanca. rev_puerto URL para descargar el corpus de notas de Revista Puerto. rp_procesada data frame con indicadores de conflictividad construidos partir de Revista Puerto. lc_mdp URL para descargar el corpus de notas del diario La Capital (Mar del Plata). rp_mdp URL para descargar el corpus de notas de Revista Puerto (edicion Mar del Plata). ed_neco URL para descargar el corpus de notas del diario Ecos Diarios (Necochea). ln_bb URL para descargar el corpus de notas de La Nueva (Bahia Blanca). ln_arg URL para descargar un subconjunto de notas de La Nacion. lc_720 data frame con 720 notas de La Capital publicadas entre 2016 y 2019, curado y documentado por Guillermina Laitano. Contiene etiquetas binarias manuales que permiten evaluar el diccionario de conflictividad, la extraccion de tripletes semanticos y la capacidad de distintos modelos generativos para tareas de clasificacion binaria y extraccion estructurada de eventos de protesta. spacy_postag data frame con una oracion procesada con spacyr que sirve como ejemplo para funciones de dependencias y SVO. titulares vector con titulares sinteticos referidos conflictos sociales.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_bases.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Coleccion de notas y recursos de prueba — acep_bases","text":"Revista Puerto La Nueva","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_bases.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Coleccion de notas y recursos de prueba — acep_bases","text":"Nieto, Agustin 2020 \"Intersecciones entre historia digital e historia social: un ejercicio de lectura distante sobre la conflictividad maritima en la historia argentina reciente\". Drassana: revista del Museu Maritim (28):122-42. (Revista Drassana)","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_bases.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coleccion de notas y recursos de prueba — acep_bases","text":"","code":"acep_bases$rp_procesada[1:6, ] #> # A tibble: 6 × 4 #>   fecha      n_palabras conflictos intensidad #>   <date>          <int>      <int>      <dbl> #> 1 2020-12-29         31          0     0      #> 2 2020-12-28       1128          4     0.0035 #> 3 2020-12-24        530          0     0      #> 4 2020-12-24        483          3     0.0062 #> 5 2020-12-23        525          1     0.0019 #> 6 2020-12-23        462          0     0"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_claude.html","id":null,"dir":"Reference","previous_headings":"","what":"Interaccion con modelos Claude usando Structured Outputs — acep_claude","title":"Interaccion con modelos Claude usando Structured Outputs — acep_claude","text":"Funcion para interactuar con la API de Anthropic Claude utilizando Tool Calling para garantizar respuestas en formato JSON que cumplen estrictamente con un esquema predefinido. diferencia de OpenAI, Anthropic utiliza \"forced tool use\" para lograr structured outputs, definiendo el esquema deseado como input_schema de una herramienta y forzando al modelo usarla. Compatible con todos los modelos Claude.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_claude.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interaccion con modelos Claude usando Structured Outputs — acep_claude","text":"","code":"acep_claude(   texto,   instrucciones,   modelo = \"claude-sonnet-4-20250514\",   api_key = Sys.getenv(\"ANTHROPIC_API_KEY\"),   schema = NULL,   parse_json = TRUE,   temperature = 0,   max_tokens = 2000,   top_p = 0.2,   top_k = NULL )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_claude.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interaccion con modelos Claude usando Structured Outputs — acep_claude","text":"texto Texto analizar con Claude. Puede ser una noticia, tweet, documento, etc. instrucciones Instrucciones en lenguaje natural que indican al modelo que hacer con el texto. Ejemplo: \"Extrae todas las entidades nombradas\", \"Clasifica el sentimiento\". modelo Modelo de Claude utilizar. Modelos disponibles (ordenados por potencia): - Claude 4.5: `\"claude-sonnet-4-5-20250929\"` (mas reciente y potente),   `\"claude-haiku-4-5-20251001\"` (rapido) - Claude 4.1: `\"claude-opus-4-1-20250805\"` (razonamiento excepcional) - Claude 4: `\"claude-opus-4-20250514\"`, `\"claude-sonnet-4-20250514\"` - Claude 3.7: `\"claude-3-7-sonnet-20250219\"` - Claude 3.5: `\"claude-3-5-haiku-20241022\"` (rapido y economico) - Claude 3: `\"claude-3-opus-20240229\"`, `\"claude-3-haiku-20240307\"` Por defecto: `\"claude-sonnet-4-20250514\"`. Ver: https://docs.anthropic.com/en/docs/-claude/models api_key Clave de API de Anthropic. Si se proporciona, busca la variable de entorno `ANTHROPIC_API_KEY`. Para obtener una clave: https://console.anthropic.com/ schema Esquema JSON que define la estructura de la respuesta. Puede usar `acep_gpt_schema()` para obtener esquemas predefinidos o crear uno personalizado. Si es `NULL`, usa un esquema simple con campo \"respuesta\". parse_json Logico. Si `TRUE` (por defecto), parsea automaticamente el JSON un objeto R (lista o data frame). Si `FALSE`, devuelve el JSON como string. temperature Parametro de temperatura (0-1). Valores bajos (0-0.3) generan respuestas mas deterministas y consistentes. Valores altos (0.7-1) mas creativas. Por defecto: 0 (maxima determinismo). NOTA: Anthropic permite usar `temperature` y `top_p` simultaneamente. max_tokens Numero maximo de tokens en la respuesta. Por defecto: 2000. top_p Parametro top-p para nucleus sampling (0-1). Controla la diversidad de la respuesta. Por defecto: 0.2. NOTA: Solo se usa si `temperature` es 0 (valor por defecto). top_k Parametro top-k (solo disponible en Claude). Limita la seleccion los K tokens mas probables. Por defecto: NULL (deshabilitado).","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_claude.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interaccion con modelos Claude usando Structured Outputs — acep_claude","text":"Si `parse_json=TRUE`, devuelve una lista o data frame con la respuesta   estructurada segun el esquema. Si `parse_json=FALSE`, devuelve un string JSON.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_claude.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interaccion con modelos Claude usando Structured Outputs — acep_claude","text":"**Diferencias importantes entre modelos Claude:** - **Claude Sonnet 4.5** (`claude-sonnet-4-5`): permite `temperature` y `top_p`   simultaneamente. La funcion solo envia uno de los dos si fue modificado del default. - **Otros modelos Claude** (`claude-sonnet-4-20250514`, `claude-3-5-haiku-20241022`,   `claude-3-opus-20240229`, etc.): SI permiten ambos parametros simultaneamente. La funcion detecta automaticamente el modelo y aplica la logica correcta.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_claude.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interaccion con modelos Claude usando Structured Outputs — acep_claude","text":"","code":"if (FALSE) { # \\dontrun{ # Extraer entidades de un texto texto <- \"El SUTEBA convoco a un paro en Buenos Aires el 15 de marzo.\" instrucciones <- \"Extrae todas las entidades nombradas del texto.\" schema <- acep_gpt_schema(\"extraccion_entidades\") resultado <- acep_claude(texto, instrucciones, schema = schema) print(resultado)  # Analisis de sentimiento texto <- \"La protesta fue pacifica y bien organizada.\" schema <- acep_gpt_schema(\"sentimiento\") resultado <- acep_claude(texto, \"Analiza el sentimiento del texto\", schema = schema) print(resultado$sentimiento_general)  # Clasificar noticia texto <- \"Trabajadores reclamaron mejoras salariales.\" schema <- acep_gpt_schema(\"clasificacion\") resultado <- acep_claude(texto, \"Clasifica esta noticia\", schema = schema) print(resultado$categoria) } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_clean.html","id":null,"dir":"Reference","previous_headings":"","what":"Limpieza de texto. — acep_clean","title":"Limpieza de texto. — acep_clean","text":"Función que limpia y normaliza las notas/textos.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_clean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Limpieza de texto. — acep_clean","text":"","code":"acep_clean(   x,   tolower = TRUE,   rm_cesp = TRUE,   rm_emoji = TRUE,   rm_hashtag = TRUE,   rm_users = TRUE,   rm_punt = TRUE,   rm_num = TRUE,   rm_url = TRUE,   rm_meses = TRUE,   rm_dias = TRUE,   rm_stopwords = TRUE,   rm_shortwords = TRUE,   rm_newline = TRUE,   rm_whitespace = TRUE,   other_sw = NULL,   u = 1 )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_clean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Limpieza de texto. — acep_clean","text":"x vector de textos al que se le aplica la función de limpieza de texto. tolower convierte los textos minúsculas. rm_cesp remueve caracteres especiales. rm_emoji remueve los emojis. rm_hashtag remueve los hashtags. rm_users remueve las menciones de usuarixs de redes sociales. rm_punt remueve la puntuación. rm_num remueve números. rm_url remueve las url. rm_meses remueve los meses del año. rm_dias remueve los dias de la semana. rm_stopwords remueve palabras vacías. rm_shortwords remueve las palabras cortas. rm_newline remueve los saltos de linea. rm_whitespace remueve los espacios en blanco. other_sw su valor por defecto es NULL, sirve para ampliar el listado de stopwords con un nuevo vector de palabras. u umbral de caracteres para la función rm_shortwords.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_clean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Limpieza de texto. — acep_clean","text":"Si todas las entradas son correctas, la salida sera un vector de textos normalizados.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_clean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Limpieza de texto. — acep_clean","text":"","code":"acep_clean(\"El SUTEBA fue al paro. Reclaman mejoras salariales.\", rm_stopword = FALSE) #> [1] \"el suteba fue al paro reclaman mejoras salariales\" acep_clean(\"El SUTEBA fue al paro. Reclaman mejoras salariales.\", rm_stopword = TRUE) #> [1] \"suteba paro reclaman mejoras salariales\""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_clear_regex_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Limpiar caché de expresiones regulares — acep_clear_regex_cache","title":"Limpiar caché de expresiones regulares — acep_clear_regex_cache","text":"Elimina todos los patrones regex almacenados en el caché interno de `acep_count()`. Útil para liberar memoria cuando se han procesado muchos diccionarios diferentes o cuando se quiere forzar la recompilación de patrones.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_clear_regex_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Limpiar caché de expresiones regulares — acep_clear_regex_cache","text":"","code":"acep_clear_regex_cache()"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_clear_regex_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Limpiar caché de expresiones regulares — acep_clear_regex_cache","text":"Devuelve `NULL` invisiblemente.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_clear_regex_cache.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Limpiar caché de expresiones regulares — acep_clear_regex_cache","text":"","code":"# Limpiar el caché acep_clear_regex_cache()"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_context.html","id":null,"dir":"Reference","previous_headings":"","what":"Función para extraer contexto de palabras o frases. — acep_context","title":"Función para extraer contexto de palabras o frases. — acep_context","text":"Versión optimizada que usa vectorización en lugar de bucles anidados. Mejora de rendimiento de 70-80","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_context.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Función para extraer contexto de palabras o frases. — acep_context","text":"","code":"acep_context(texto, clave, izq = 1, der = 1, ci = \"\\\\b\", cd = \"\\\\S*\")"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_context.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Función para extraer contexto de palabras o frases. — acep_context","text":"texto vector con los textos procesar. clave vector de palabras clave contextualizar. izq número de palabras de la ventana hacia la izquierda. der número de palabras de la ventana hacia la derecha. ci expresión regular la izquierda de la palabra clave. cd expresión regular la derecha de la palabra clave.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_context.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Función para extraer contexto de palabras o frases. — acep_context","text":"Data frame con id de textos y contexto de palabras/frases.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_context.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Función para extraer contexto de palabras o frases. — acep_context","text":"","code":"texto <- \"El SOIP para por aumento de salarios\" texto_context <- acep_context(texto = texto, clave = \"para\") texto_context #>   doc_id oraciones_id             texto w_izq  key w_der #> 1      1            1 SOIP | para | por  SOIP para   por"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructor de corpus para analisis de texto — acep_corpus","title":"Constructor de corpus para analisis de texto — acep_corpus","text":"Crea un objeto de clase `acep_corpus` que encapsula una coleccion de textos junto con su metadata asociada. Este objeto esta disenado para trabajar con las funciones pipeline de ACEP (`pipe_clean`, `pipe_count`, etc.), permitiendo un flujo de trabajo encadenado y manteniendo trazabilidad de las transformaciones aplicadas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructor de corpus para analisis de texto — acep_corpus","text":"","code":"acep_corpus(texto, metadata = NULL, id = NULL)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructor de corpus para analisis de texto — acep_corpus","text":"texto Vector de caracteres con los textos almacenar en el corpus. metadata Lista opcional con informacion adicional sobre el corpus (ej: fuente, fecha de recoleccion, categorias tematicas). id Vector opcional de identificadores unicos para cada texto. Si se proporciona, se asignan IDs secuenciales (1, 2, 3, ...).","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructor de corpus para analisis de texto — acep_corpus","text":"Objeto de clase `acep_corpus` con la siguiente estructura: texto_original: Vector con los textos originales sin procesar texto_procesado: Vector con textos procesados (NULL inicialmente) id: Identificadores de cada texto metadata: Metadata adicional del corpus procesamiento: Registro de transformaciones aplicadas","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_corpus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructor de corpus para analisis de texto — acep_corpus","text":"","code":"# Crear corpus simple textos <- c(\"El SUTEBA va al paro\", \"SOIP protesta por salarios\") corpus <- acep_corpus(textos) print(corpus) #> acep_corpus object #> ================== #> Documentos: 2  #> Procesado: FALSE  #> Pasos aplicados: 0   # Crear corpus con metadata e IDs personalizados corpus <- acep_corpus(   texto = c(\"Noticia 1\", \"Noticia 2\"),   metadata = list(fuente = \"Diario La Nacion\", year = 2024),   id = c(\"LN001\", \"LN002\") )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Conteo de menciones de palabras de un diccionario — acep_count","title":"Conteo de menciones de palabras de un diccionario — acep_count","text":"Cuenta el número de veces que aparecen palabras de un diccionario en cada texto. Utiliza expresiones regulares con límites de palabra (word boundaries) para evitar coincidencias parciales. Incluye un sistema de caché que almacena los patrones regex compilados para acelerar ejecuciones repetidas con el mismo diccionario.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conteo de menciones de palabras de un diccionario — acep_count","text":"","code":"acep_count(texto, dic, use_cache = TRUE)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conteo de menciones de palabras de un diccionario — acep_count","text":"texto vector de textos al que se le aplica la función de conteo. dic vector de palabras del diccionario utilizado. use_cache logical, usar caché de regex (default TRUE).","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conteo de menciones de palabras de un diccionario — acep_count","text":"Vector con frecuencia de palabras del diccionario.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conteo de menciones de palabras de un diccionario — acep_count","text":"","code":"df <- data.frame(texto = c(\"El SUTEBA fue al paro. Reclaman mejoras salariales.\", \"El SOIP lleva adelante un plan de lucha con paros y piquetes.\")) diccionario <- c(\"paro\", \"lucha\", \"piquetes\") df$detect <- acep_count(df$texto, diccionario) df #>                                                           texto detect #> 1           El SUTEBA fue al paro. Reclaman mejoras salariales.      1 #> 2 El SOIP lleva adelante un plan de lucha con paros y piquetes.      3"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_db.html","id":null,"dir":"Reference","previous_headings":"","what":"Frecuencia, menciones e intensidad. — acep_db","title":"Frecuencia, menciones e intensidad. — acep_db","text":"Función que usa las funciones acep_frec, acep_count y acep_int y devuelve una tabla con tres columnas nuevas: numero de palabras, número de menciones del diccionario, indice de intensidad.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Frecuencia, menciones e intensidad. — acep_db","text":"","code":"acep_db(db, t, d, n)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_db.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Frecuencia, menciones e intensidad. — acep_db","text":"db data frame con los textos procesar. t columna de data frame que contiene el vector de textos procesar. d diccionario en formato vector. n cantidad de decimales del indice de intensidad.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_db.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Frecuencia, menciones e intensidad. — acep_db","text":"Si todas las entradas son correctas, la salida sera una base de datos en formato tabular con tres nuevas variables.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_db.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Frecuencia, menciones e intensidad. — acep_db","text":"","code":"df <- data.frame(texto = c(\"El SUTEBA fue al paro. Reclaman mejoras salariales.\", \"El SOIP lleva adelante un plan de lucha con paros y piquetes.\")) diccionario <- c(\"paro\", \"lucha\", \"piquetes\") acep_db(df, df$texto, diccionario, 4) #>                                                           texto n_palabras #> 1           El SUTEBA fue al paro. Reclaman mejoras salariales.          8 #> 2 El SOIP lleva adelante un plan de lucha con paros y piquetes.         12 #>   conflictos intensidad #> 1          1      0.125 #> 2          3      0.250"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_detect.html","id":null,"dir":"Reference","previous_headings":"","what":"Detección de menciones de palabras. — acep_detect","title":"Detección de menciones de palabras. — acep_detect","text":"Función que detecta de menciones de palabras que refieren conflictos en cada una de las notas/textos.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_detect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detección de menciones de palabras. — acep_detect","text":"","code":"acep_detect(x, y, u = 1, tolower = TRUE)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_detect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detección de menciones de palabras. — acep_detect","text":"x vector de textos al que se le aplica la función de detección de menciones de palabras del diccionario. y vector de palabras del diccionario utilizado. u umbral para atribuir valor positivo la detección de las menciones. tolower convierte los textos minúsculas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_detect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detección de menciones de palabras. — acep_detect","text":"Si todas las entradas son correctas, la salida sera un vector numérico.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_detect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detección de menciones de palabras. — acep_detect","text":"","code":"df <- data.frame(texto = c(\"El SUTEBA fue al paro. Reclaman mejoras salariales.\", \"El SOIP lleva adelante un plan de lucha con paros y piquetes.\")) diccionario <- c(\"paro\", \"lucha\", \"piquetes\") df$detect <- acep_detect(df$texto, diccionario) df #>                                                           texto detect #> 1           El SUTEBA fue al paro. Reclaman mejoras salariales.      1 #> 2 El SOIP lleva adelante un plan de lucha con paros y piquetes.      1"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_diccionarios.html","id":null,"dir":"Reference","previous_headings":"","what":"Colección de diccionarios. — acep_diccionarios","title":"Colección de diccionarios. — acep_diccionarios","text":"Colección de diccionarios que reúne diccionarios de diferentes orígenes. El diccionario dicc_confl_acep fueron construidos en el marco del Observatorio de Conflictividad de la UNMdP. Los diccionarios dicc_confl_gp y dicc_viol_gp fueron extraídos de Albrieu y Palazzo (2020).","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_diccionarios.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Colección de diccionarios. — acep_diccionarios","text":"","code":"data(acep_diccionarios)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_diccionarios.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Colección de diccionarios. — acep_diccionarios","text":"Es un objeto de clase 'list' con 3 componentes. dicc_confl_gp es un vector con palabras de un diccionario de términos que refieren conflictos dicc_viol_gp es un  vector con palabras de un diccionario de términos que refieren violencia dicc_confl_sismos es un  vector con palabras de un diccionario de términos que refieren conflictos","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_diccionarios.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Colección de diccionarios. — acep_diccionarios","text":"Revista Puerto La Nueva","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_diccionarios.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Colección de diccionarios. — acep_diccionarios","text":"Albrieu, Ramiro y Gabriel Palazzo 2020 «Categorización de conflictos sociales en el ámbito de los recursos naturales: un estudio de las actividades extractivas mediante la minería de textos». Revista CEPAL (131):29-59. (Revista CEPAL) Laitano, Guillermina y Agustín Nieto «Análisis computacional de la conflictividad laboral en Mar del Plata durante el gobierno de Cambiemos». Ponencia presentado en VI Workshop - Los conflictos laborales en la Argentina del siglo XX y XXI: un abordaje interdisciplinario de conceptos, problemas y escalas de análisis, Tandil, 2021.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_diccionarios.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Colección de diccionarios. — acep_diccionarios","text":"","code":"diccionario <- acep_load_base(acep_diccionarios$dicc_viol_gp) #> Descargando... diccionario #>   [1] \"agresivo\"         \"combativo\"        \"provocador\"       #>   [4] \"violento\"         \"agresividad\"      \"belicosidad\"      #>   [7] \"combatividad\"     \"provocación\"      \"emboscada\"        #>  [10] \"celada\"           \"trampa\"           \"asechanza\"        #>  [13] \"artería\"          \"artimaña\"         \"emboscar\"         #>  [16] \"trampear\"         \"asechar\"          \"armas\"            #>  [19] \"armamento\"        \"armado\"           \"asaltar\"          #>  [22] \"atracar\"          \"robar\"            \"agredir\"          #>  [25] \"acometer\"         \"irrumpir\"         \"invadir\"          #>  [28] \"ataque\"           \"embate\"           \"irrupción\"        #>  [31] \"combate\"          \"lucha\"            \"agresión\"         #>  [34] \"golpear\"          \"golpe\"            \"sanguinario\"      #>  [37] \"choque\"           \"asalto\"           \"atropello\"        #>  [40] \"atentado\"         \"coletazo\"         \"bomba\"            #>  [43] \"explosivo\"        \"granada\"          \"munición\"         #>  [46] \"bala\"             \"brutalidad\"       \"bestialidad\"      #>  [49] \"ferocidad\"        \"crueldad\"         \"atrocidad\"        #>  [52] \"monstruosidad\"    \"irracionalidad\"   \"vandalismo\"       #>  [55] \"salvajada\"        \"grosería\"         \"masacre\"          #>  [58] \"matanza\"          \"mortandad\"        \"hecatombe\"        #>  [61] \"catástrofe\"       \"degollina\"        \"aplastar\"         #>  [64] \"triturar\"         \"reventar\"         \"destripar\"        #>  [67] \"moler\"            \"aplastamiento\"    \"mortal\"           #>  [70] \"mortífero\"        \"letal\"            \"fatídico\"         #>  [73] \"fatal\"            \"funesto\"          \"disparar\"         #>  [76] \"tirotear\"         \"ametrallar\"       \"despedir\"         #>  [79] \"expulsar\"         \"destituir\"        \"guerrilla\"        #>  [82] \"guerrillero\"      \"milicia\"          \"arma\"             #>  [85] \"pistola\"          \"revólver\"         \"pistolete\"        #>  [88] \"ametralladora\"    \"metralleta\"       \"pistolero\"        #>  [91] \"atracador\"        \"bandido\"          \"forajido\"         #>  [94] \"delincuente\"      \"gánster\"          \"terrorista\"       #>  [97] \"asesino\"          \"matar\"            \"asesinar\"         #> [100] \"ahorcar\"          \"ahogar\"           \"decapitar\"        #> [103] \"desnucar\"         \"degollar\"         \"fusilar\"          #> [106] \"guillotinar\"      \"asfixiar\"         \"electrocutar\"     #> [109] \"envenenar\"        \"linchar\"          \"asesinato\"        #> [112] \"crimen\"           \"homicidio\"        \"delito\"           #> [115] \"muerte\"           \"parricidio\"       \"fratricidio\"      #> [118] \"magnicidio\"       \"regicidio\"        \"criminal\"         #> [121] \"homicida\"         \"monstruo\"         \"engendro\"         #> [124] \"deforme\"          \"monstruosa\"       \"rebelarse\"        #> [127] \"incitar\"          \"sublevarse\"       \"insubordinarse\"   #> [130] \"levantarse\"       \"alzarse\"          \"amotinarse\"       #> [133] \"insurreccionarse\" \"rebelión\"         \"levantamiento\"    #> [136] \"revuelta\"         \"alzamiento\"       \"revolución\"       #> [139] \"subversión\"       \"conspiración\"     \"conjuración\"      #> [142] \"sedición\"         \"insurrección\"     \"motín\"            #> [145] \"acuchillar\"       \"apuñalar\"         \"lesionar\"         #> [148] \"violencia\"        \"exabrupto\"        \"coacción\"         #> [151] \"profanación\"      \"furia\"            \"ensañamiento\"     #> [154] \"violación\"        \"implacable\"       \"furioso\"          #> [157] \"guerrero\"         \"soldado\"          \"militar\"          #> [160] \"látigo\"           \"azote\"            \"fusta\"            #> [163] \"tralla\"           \"vergajo\"          \"flagelo\"          #> [166] \"zurriago\"         \"latigazos\"        \"azotando\"         #> [169] \"litigar\"          \"azotar\"           \"fustigar\"         #> [172] \"flagelar\""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_extract.html","id":null,"dir":"Reference","previous_headings":"","what":"Función para buscar y extraer palabras en un texto. — acep_extract","title":"Función para buscar y extraer palabras en un texto. — acep_extract","text":"Esta función busca palabras clave en un texto y extrae los resultados en un formato especifico.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_extract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Función para buscar y extraer palabras en un texto. — acep_extract","text":"","code":"acep_extract(texto, dic, sep = \"; \", izq = \"\\\\b\\\\w*\", der = \"\\\\w*\\\\b\")"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_extract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Función para buscar y extraer palabras en un texto. — acep_extract","text":"texto El texto en el que se buscaran las palabras clave. dic Un vector con las palabras clave buscar. sep El separador utilizado para concatenar las palabras clave encontradas (por defecto: \" | \"). izq expresión regular para incorporar otros caracteres la izquierda de los términos del vector 'dic'. der expresión regular para incorporar otros caracteres la derecha de los términos del vector 'dic'.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_extract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Función para buscar y extraer palabras en un texto. — acep_extract","text":"Si todas las entradas son correctas, la salida sera un vector de tipo caracter. procesado y el contexto de las palabras y/o frases entradas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_extract.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Función para buscar y extraer palabras en un texto. — acep_extract","text":"","code":"texto <- \"Los obreros del pescado, en el marco de una huelga y realizaron una manifestación con piquete en el puerto de la ciudad.\" dicc <- c(\"huel\", \"manif\", \"piq\") acep_extract(texto, dicc) #> [1] \"huelga; manifestación; piquete\""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_frec.html","id":null,"dir":"Reference","previous_headings":"","what":"Frecuencia de palabras totales. — acep_frec","title":"Frecuencia de palabras totales. — acep_frec","text":"Función que cuenta la frecuencia de palabras totales en cada una de las notas/textos.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_frec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Frecuencia de palabras totales. — acep_frec","text":"","code":"acep_frec(x)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_frec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Frecuencia de palabras totales. — acep_frec","text":"x vector de textos al que se le aplica la función de conteo de la frecuencia de palabras.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_frec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Frecuencia de palabras totales. — acep_frec","text":"Si todas las entradas son correctas, la salida sera un vector con una frecuencia de palabras.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_frec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Frecuencia de palabras totales. — acep_frec","text":"","code":"acep_frec(\"El SUTEBA fue al paro. Reclaman mejoras salariales.\") #> [1] 8"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gemini.html","id":null,"dir":"Reference","previous_headings":"","what":"Interaccion con modelos Gemini usando Structured Outputs — acep_gemini","title":"Interaccion con modelos Gemini usando Structured Outputs — acep_gemini","text":"Funcion para interactuar con la API de Google Gemini utilizando Structured Outputs nativos. Gemini soporta generacion de JSON estructurado mediante el parametro `responseSchema` que garantiza que las respuestas cumplan con el esquema definido. Compatible con todos los modelos Gemini 2.5 y Gemini 2.0. Acceso gratuito para uso limitado disponible en Google AI Studio.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gemini.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interaccion con modelos Gemini usando Structured Outputs — acep_gemini","text":"","code":"acep_gemini(   texto,   instrucciones,   modelo = \"gemini-2.5-flash\",   api_key = Sys.getenv(\"GEMINI_API_KEY\"),   schema = NULL,   parse_json = TRUE,   temperature = 0,   max_tokens = 2000,   top_p = 0.95,   top_k = 40 )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gemini.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interaccion con modelos Gemini usando Structured Outputs — acep_gemini","text":"texto Texto analizar con Gemini. Puede ser una noticia, tweet, documento, etc. instrucciones Instrucciones en lenguaje natural que indican al modelo que hacer con el texto. Ejemplo: \"Extrae todas las entidades nombradas\", \"Clasifica el sentimiento\". modelo Modelo de Gemini utilizar. Opciones recomendadas: - Gemini 2.5: `\"gemini-2.5-flash\"` (rapido, multimodal, por defecto),   `\"gemini-2.5-flash-lite\"` (mas economico), `\"gemini-2.5-pro\"` (mas potente) - Gemini 2.0: `\"gemini-2.0-flash\"`, `\"gemini-2.0-flash-lite\"` Por defecto: `\"gemini-2.5-flash\"`. Ver: https://ai.google.dev/gemini-api/docs/models api_key Clave de API de Google Gemini. Si se proporciona, busca la variable de entorno `GEMINI_API_KEY`. Para obtener una clave: https://aistudio.google.com/apikey schema Esquema JSON que define la estructura de la respuesta. Puede usar `acep_gpt_schema()` para obtener esquemas predefinidos o crear uno personalizado. Si es `NULL`, usa un esquema simple con campo \"respuesta\". NOTA: Gemini usa un subconjunto de OpenAPI 3.0 Schema para definir estructuras. parse_json Logico. Si `TRUE` (por defecto), parsea automaticamente el JSON un objeto R (lista o data frame). Si `FALSE`, devuelve el JSON como string. temperature Parametro de temperatura (0-2). Valores bajos (0-0.3) generan respuestas mas deterministas. Valores altos (0.7-1) mas creativas. Por defecto: 0. Valor recomendado por Google: 1.0. max_tokens Numero maximo de tokens en la respuesta. Por defecto: 2000. top_p Parametro top-p para nucleus sampling (0-1). Controla la diversidad de la respuesta. Por defecto: 0.95 (valor tipico para Gemini). top_k Parametro top-k. Limita la seleccion los K tokens mas probables. Por defecto: 40 (valor tipico para Gemini).","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gemini.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interaccion con modelos Gemini usando Structured Outputs — acep_gemini","text":"Si `parse_json=TRUE`, devuelve una lista o data frame con la respuesta   estructurada segun el esquema. Si `parse_json=FALSE`, devuelve un string JSON.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gemini.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interaccion con modelos Gemini usando Structured Outputs — acep_gemini","text":"La API de Gemini usa un enfoque diferente para structured outputs: - Define `responseMimeType: \"application/json\"` en `generationConfig` - Usa `responseSchema` con formato OpenAPI 3.0 Schema - Soporta tipos: string, integer, number, boolean, array, object - Campo opcional `propertyOrdering` controla orden de propiedades en respuesta Diferencias importantes con OpenAI: - requiere campo `additionalProperties: false` (se maneja automaticamente) - Los campos son opcionales por defecto (usar `required` para campos obligatorios) - El esquema cuenta como tokens de entrada","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gemini.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interaccion con modelos Gemini usando Structured Outputs — acep_gemini","text":"","code":"if (FALSE) { # \\dontrun{ # Configurar API key Sys.setenv(GEMINI_API_KEY = \"tu-api-key\")  # Extraer entidades con Gemini 2.5 Flash texto <- \"El SUTEBA convoco a un paro en Buenos Aires el 15 de marzo.\" resultado <- acep_gemini(texto, \"Extrae las entidades nombradas\",                          schema = acep_gpt_schema(\"extraccion_entidades\"))  # Analisis de sentimiento con modelo economico resultado <- acep_gemini(texto, \"Analiza el sentimiento\",                          modelo = \"gemini-2.5-flash-lite\",                          schema = acep_gpt_schema(\"sentimiento\"))  # Usar Gemini 2.0 Flash Lite (mas rapido) resultado <- acep_gemini(texto, \"Extrae entidades\",                          modelo = \"gemini-2.0-flash-lite\",                          schema = acep_gpt_schema(\"extraccion_entidades\")) } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gpt.html","id":null,"dir":"Reference","previous_headings":"","what":"Interaccion con modelos GPT usando Structured Outputs — acep_gpt","title":"Interaccion con modelos GPT usando Structured Outputs — acep_gpt","text":"Funcion para interactuar con la API de OpenAI utilizando Structured Outputs, una funcionalidad que garantiza respuestas en formato JSON que cumplen estrictamente con un esquema predefinido. Esto elimina la necesidad de parseo y validacion manual, haciendo las respuestas mas confiables y estructuradas. Compatible con modelos `gpt-4o` y `gpt-4o-mini`.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gpt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interaccion con modelos GPT usando Structured Outputs — acep_gpt","text":"","code":"acep_gpt(   texto,   instrucciones,   modelo = \"gpt-4o-mini\",   api_key = Sys.getenv(\"OPENAI_API_KEY\"),   schema = NULL,   parse_json = TRUE,   temperature = 0,   max_tokens = 2000,   top_p = 0.2,   frequency_penalty = 0.2,   seed = 123456 )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gpt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interaccion con modelos GPT usando Structured Outputs — acep_gpt","text":"texto Texto analizar con GPT. Puede ser una noticia, tweet, documento, etc. instrucciones Instrucciones en lenguaje natural que indican al modelo que hacer con el texto. Ejemplo: \"Extrae todas las entidades nombradas\", \"Clasifica el sentimiento\". modelo Modelo de OpenAI utilizar. Compatible con Structured Outputs: `\"gpt-4o-mini\"` (mas rapido y economico), `\"gpt-4o\"`, `\"gpt-4o-2024-08-06\"` (mas potente), `\"gpt-4.1\"`, `\"gpt-5-nano\"`, `\"gpt-5-mini\"`, `\"o1-mini\"`, `\"o4-mini\"`, entre otros. Por defecto: `\"gpt-4o-mini\"`. Ver: https://platform.openai.com/docs/guides/structured-outputs api_key Clave de API de OpenAI. Si se proporciona, busca la variable de entorno `OPENAI_API_KEY`. Para obtener una clave: https://platform.openai.com/api-keys schema Esquema JSON que define la estructura de la respuesta. Puede usar `acep_gpt_schema()` para obtener esquemas predefinidos o crear uno personalizado. Si es `NULL`, usa un esquema simple con campo \"respuesta\". parse_json Logico. Si `TRUE` (por defecto), parsea automaticamente el JSON un objeto R (lista o data frame). Si `FALSE`, devuelve el JSON como string. temperature Parametro de temperatura (0-2). Valores bajos (0-0.3) generan respuestas mas deterministas y consistentes. Valores altos (0.7-1) mas creativas. Por defecto: 0 (maxima determinismo). NOTA: Los modelos gpt-5, o1 y o4 solo aceptan temperature = 1 (default de OpenAI). max_tokens Numero maximo de tokens en la respuesta. Por defecto: 2000. top_p Parametro top-p para nucleus sampling (0-1). Controla la diversidad de la respuesta. Por defecto: 0.2. NOTA: Ignorado en modelos gpt-5, o1 y o4. frequency_penalty Penalizacion por repeticion de tokens frecuentes (-2 2). Por defecto: 0.2. NOTA: Ignorado en modelos gpt-5, o1 y o4. seed Semilla numerica para reproducibilidad. Usar el mismo seed con los mismos parametros genera respuestas identicas. Por defecto: 123456. NOTA: Ignorado en modelos gpt-5, o1 y o4.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gpt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interaccion con modelos GPT usando Structured Outputs — acep_gpt","text":"Si `parse_json=TRUE`, devuelve una lista o data frame con la respuesta   estructurada segun el esquema. Si `parse_json=FALSE`, devuelve un string JSON.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gpt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interaccion con modelos GPT usando Structured Outputs — acep_gpt","text":"**Diferencias entre modelos:** - **Modelos GPT-4o/GPT-4.1**: Soportan todos los parametros (temperature, top_p,   frequency_penalty, seed). Usan `max_tokens`. - **Modelos GPT-5/o1/o4**: Solo aceptan temperature = 1 (default). Los parametros   temperature, top_p, frequency_penalty y seed son automaticamente omitidos.   Usan `max_completion_tokens` en lugar de `max_tokens`. La funcion maneja estas diferencias automaticamente segun el modelo especificado.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gpt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interaccion con modelos GPT usando Structured Outputs — acep_gpt","text":"","code":"if (FALSE) { # \\dontrun{ # Extraer entidades de un texto texto <- \"El SUTEBA convoco a un paro en Buenos Aires el 15 de marzo.\" instrucciones <- \"Extrae todas las entidades nombradas del texto.\" schema <- acep_gpt_schema(\"extraccion_entidades\") resultado <- acep_gpt(texto, instrucciones, schema = schema) print(resultado)  # Analisis de sentimiento texto <- \"La protesta fue pacifica y bien organizada.\" schema <- acep_gpt_schema(\"sentimiento\") resultado <- acep_gpt(texto, \"Analiza el sentimiento del texto\", schema = schema) print(resultado$sentimiento_general)  # Clasificar noticia texto <- \"Trabajadores reclamaron mejoras salariales.\" schema <- acep_gpt_schema(\"clasificacion\") resultado <- acep_gpt(texto, \"Clasifica esta noticia\", schema = schema) print(resultado$categoria) } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gpt_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Esquemas JSON predefinidos para analisis de texto con GPT — acep_gpt_schema","title":"Esquemas JSON predefinidos para analisis de texto con GPT — acep_gpt_schema","text":"Proporciona esquemas JSON predefinidos y validados para casos de uso comunes en analisis de texto con GPT. Estos esquemas garantizan respuestas estructuradas y consistentes para tareas como extraccion de entidades, clasificacion, analisis de sentimiento, resumen, pregunta-respuesta, extraccion de tripletes y analisis de acciones de protesta.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gpt_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Esquemas JSON predefinidos para analisis de texto con GPT — acep_gpt_schema","text":"","code":"acep_gpt_schema(tipo = \"extraccion_entidades\")"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gpt_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Esquemas JSON predefinidos para analisis de texto con GPT — acep_gpt_schema","text":"tipo Tipo de esquema devolver. Opciones: \"extraccion_entidades\": Extrae personas, organizaciones, lugares, fechas y eventos \"clasificacion\": Clasifica el texto en categorias con nivel de confianza \"sentimiento\": Analiza sentimiento general y por aspectos especificos \"resumen\": Genera resumenes cortos y detallados con puntos clave \"qa\": Responde preguntas con citas textuales y nivel de confianza \"tripletes\": Extrae relaciones sujeto-predicado-objeto \"protesta_breve\": Extrae informacion basica de acciones de protesta (fecha, sujeto, accion, objeto, lugar) \"protesta_detallada\": Extrae informacion detallada de multiples acciones de protesta con 9 campos por accion \"verdadero_falso\": Devuelve una respuesta booleana simple (TRUE o FALSE) con nivel de confianza (0 1) y justificacion opcional","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gpt_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Esquemas JSON predefinidos para analisis de texto con GPT — acep_gpt_schema","text":"Lista con esquema JSON compatible con OpenAI Structured Outputs.   Puede usarse directamente en el parametro `schema` de `acep_gpt()` o `acep_ollama()`.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_gpt_schema.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Esquemas JSON predefinidos para analisis de texto con GPT — acep_gpt_schema","text":"","code":"# Obtener esquema para extraccion de entidades schema_entidades <- acep_gpt_schema(\"extraccion_entidades\") names(schema_entidades$properties)  # personas, organizaciones, lugares, fechas, eventos #> [1] \"personas\"       \"organizaciones\" \"lugares\"        \"fechas\"         #> [5] \"eventos\"         # Obtener esquema para clasificacion schema_clasif <- acep_gpt_schema(\"clasificacion\") names(schema_clasif$properties)  # categoria, confianza, justificacion #> [1] \"categoria\"     \"confianza\"     \"justificacion\"  # Obtener esquema para analisis de sentimiento schema_sent <- acep_gpt_schema(\"sentimiento\") names(schema_sent$properties)  # sentimiento_general, puntuacion, aspectos #> [1] \"sentimiento_general\" \"puntuacion\"          \"aspectos\"             # Obtener esquema para analisis breve de protestas schema_protesta <- acep_gpt_schema(\"protesta_breve\") names(schema_protesta$properties)  # fecha, sujeto, accion, objeto, lugar #> [1] \"fecha\"  \"sujeto\" \"accion\" \"objeto\" \"lugar\"   # Obtener esquema para analisis detallado de protestas schema_protesta_det <- acep_gpt_schema(\"protesta_detallada\") names(schema_protesta_det$properties)  # acciones (array con 9 campos cada una) #> [1] \"acciones\"  # Obtener esquema para respuesta verdadero/falso schema_bool <- acep_gpt_schema(\"verdadero_falso\") names(schema_bool$properties)  # respuesta, nivel_confianza, justificacion #> [1] \"respuesta\"       \"nivel_confianza\" \"justificacion\""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_int.html","id":null,"dir":"Reference","previous_headings":"","what":"Índice de intensidad. — acep_int","title":"Índice de intensidad. — acep_int","text":"Función que elabora un indice de intensidad en base la relación entre palabras totales y palabras del diccionario presentes en el texto.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Índice de intensidad. — acep_int","text":"","code":"acep_int(pc, pt, decimales = 4)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Índice de intensidad. — acep_int","text":"pc vector numérico con la frecuencia de palabras conflictivas presentes en cada texto. pt vector de palabras totales en cada texto. decimales cantidad de decimales, por defecto tiene 4 pero se puede modificar.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_int.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Índice de intensidad. — acep_int","text":"Si todas las entradas son correctas, la salida sera un vector numérico.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_int.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Índice de intensidad. — acep_int","text":"","code":"conflictos <- c(1, 5, 0, 3, 7) palabras <- c(4, 11, 12, 9, 34) acep_int(conflictos, palabras, 3) #> [1] 0.250 0.455 0.000 0.333 0.206"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_load_base.html","id":null,"dir":"Reference","previous_headings":"","what":"Carga los corpus y las bases creadas por el Observatorio. — acep_load_base","title":"Carga los corpus y las bases creadas por el Observatorio. — acep_load_base","text":"Función para cargar bases de datos disponibles online. Por ahora están disponibles las siguientes bases: Revista Puerto 'rp_mdp'; La Nueva 'ln_bb', La Capital 'lc_mdp', Ecos Diarios 'ed_neco', La Nación 'ln_arg'","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_load_base.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Carga los corpus y las bases creadas por el Observatorio. — acep_load_base","text":"","code":"acep_load_base(tag)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_load_base.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Carga los corpus y las bases creadas por el Observatorio. — acep_load_base","text":"tag etiqueta identificatoria del data frame cargar: acep_bases$rp_mdp, acep_bases$ln_bb, acep_bases$lc_mdp, acep_bases$ed_neco, acep_bases$ln_arg","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_load_base.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Carga los corpus y las bases creadas por el Observatorio. — acep_load_base","text":"Si todas las entradas son correctas, la salida sera una base de datos en formato tabular con un corpus de notas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_load_base.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Carga los corpus y las bases creadas por el Observatorio. — acep_load_base","text":"","code":"bd_sismos <- acep_bases$rev_puerto head(acep_load_base(tag = bd_sismos)) #> Descargando... #> # A tibble: 6 × 3 #>   fecha      titulo                                                        nota  #>   <date>     <chr>                                                         <chr> #> 1 2019-03-29 Astillero Contessi botó al Luca Santino, un fresquero de nue… \"Tra… #> 2 2019-03-29 Di Leva despidió a trabajadores de El Marisco y Sebastián Ga… \"Tra… #> 3 2019-03-29 El Consejo aprobó la apertura al norte para el calamar        \"En … #> 4 2019-03-28 “Todos los empresarios me dicen que tendrían que achicarse”   \"Cri… #> 5 2019-03-28 En el Puerto de Montevideo siguen bajando un muerto por mes   \"La … #> 6 2019-03-28 Habilitan el muelle Piedra Buena para descarga de congelador… \"La …"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_may.html","id":null,"dir":"Reference","previous_headings":"","what":"Convierte caracteres a mayusculas. — acep_may","title":"Convierte caracteres a mayusculas. — acep_may","text":"Esta función toma un vector de texto y convierte todas las letras minúsculas en mayúsculas, manteniendo el resto de los caracteres sin cambios.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_may.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convierte caracteres a mayusculas. — acep_may","text":"","code":"acep_may(x)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_may.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convierte caracteres a mayusculas. — acep_may","text":"x es un vector de texto (caracteres) que se desea convertir mayúsculas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_may.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convierte caracteres a mayusculas. — acep_may","text":"Devuelve un nuevo vector con todas las letras en mayúsculas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_may.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convierte caracteres a mayusculas. — acep_may","text":"","code":"vector_texto <- c(\"soip\", \"cGt\", \"Sutna\") acep_may(vector_texto) #> [1] \"SOIP\"  \"CGT\"   \"SUTNA\" vector_numeros <- c(1, 2, 3, 4, 5) acep_may(vector_numeros) #> No ingresaste un vector de texto. #>             Vuelve a intentarlo ingresando un vector de texto. vector_mezclado <- c(\"sutna\", 123, \"Ate\") acep_may(vector_mezclado) #> [1] \"SUTNA\" \"123\"   \"ATE\""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_min.html","id":null,"dir":"Reference","previous_headings":"","what":"Convierte caracteres a minúsculas. — acep_min","title":"Convierte caracteres a minúsculas. — acep_min","text":"Esta función toma un vector de texto y convierte todas las letras mayusculas en minúsculas, manteniendo el resto de los caracteres sin cambios.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_min.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convierte caracteres a minúsculas. — acep_min","text":"","code":"acep_min(x)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_min.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convierte caracteres a minúsculas. — acep_min","text":"x Un vector de texto (caracteres) que se desea convertir minúsculas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_min.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convierte caracteres a minúsculas. — acep_min","text":"Devuelve un nuevo vector con todas las letras en minúsculas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_min.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convierte caracteres a minúsculas. — acep_min","text":"","code":"vector_texto <- c(\"SUTEBA\", \"Sindicato\", \"PEN\") acep_min(vector_texto) #> [1] \"suteba\"    \"sindicato\" \"pen\"       vector_numeros <- c(1, 2, 3, 4, 5) acep_min(vector_numeros) #> No ingresaste un vector de texto. #>             Vuelve a intentarlo ingresando un vector de texto. vector_mezclado <- c(\"Soip\", 123, \"CGT\") acep_min(vector_mezclado) #> [1] \"soip\" \"123\"  \"cgt\""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_ollama.html","id":null,"dir":"Reference","previous_headings":"","what":"Interaccion con modelos Ollama locales y cloud usando Structured Outputs — acep_ollama","title":"Interaccion con modelos Ollama locales y cloud usando Structured Outputs — acep_ollama","text":"Funcion para interactuar con modelos de lenguaje usando Ollama. Soporta tanto modelos locales (ejecutados en tu computadora sin costos) como modelos cloud de Ollama (modelos grandes como DeepSeek 671B, Qwen3 Coder 480B, Kimi 1T que se ejecutan en la nube sin necesidad de GPU local). Utiliza structured outputs para garantizar respuestas en formato JSON que cumplen con un esquema predefinido.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_ollama.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interaccion con modelos Ollama locales y cloud usando Structured Outputs — acep_ollama","text":"","code":"acep_ollama(   texto,   instrucciones,   modelo = \"qwen3:1.7b\",   schema = NULL,   parse_json = TRUE,   temperature = 0,   max_tokens = 4000,   host = \"http://localhost:11434\",   api_key = Sys.getenv(\"OLLAMA_API_KEY\"),   seed = 123456 )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_ollama.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interaccion con modelos Ollama locales y cloud usando Structured Outputs — acep_ollama","text":"texto Texto analizar. Puede ser una noticia, tweet, documento, etc. instrucciones Instrucciones en lenguaje natural que indican al modelo que hacer con el texto. Ejemplo: \"Extrae todas las entidades nombradas\", \"Clasifica el sentimiento\". modelo Modelo de Ollama utilizar. - Para Ollama local: \"qwen3:1.7b\", \"llama3.2:latest\", \"mistral\", \"phi3\", \"gemma2\"   (debe estar previamente descargado con `ollama pull nombre_modelo`) - Para Ollama Cloud API: modelos cloud especificos disponibles sin GPU local:   \"deepseek-v3.1:671b-cloud\", \"gpt-oss:20b-cloud\", \"gpt-oss:120b-cloud\",   \"kimi-k2:1t-cloud\", \"qwen3-coder:480b-cloud\", \"glm-4.6:cloud\", \"minimax-m2:cloud\" Por defecto: \"qwen3:1.7b\" schema Esquema JSON que define la estructura de la respuesta. Puede usar `acep_gpt_schema()` para obtener esquemas predefinidos o crear uno personalizado. Si es NULL, usa un esquema simple con campo \"respuesta\". parse_json Logico. Si TRUE (por defecto), parsea automaticamente el JSON un objeto R (lista o data frame). Si FALSE, devuelve el JSON como string. temperature Parametro de temperatura (0-2). Valores bajos (0-0.3) generan respuestas mas deterministas. Valores altos (0.7-1) mas creativas. Por defecto: 0. max_tokens Numero maximo de tokens en la respuesta. Por defecto: 4000. host URL del servidor Ollama. Por defecto: \"http://localhost:11434\" para uso local. Para usar Ollama Cloud API, especificar \"https://ollama.com\" (sin /api, se agrega automaticamente). api_key API key para Ollama API remota. Solo requerido si usas un servidor remoto. Por defecto busca la variable de entorno OLLAMA_API_KEY. Para uso local (localhost) es necesario. seed Semilla numerica para reproducibilidad. Por defecto: 123456.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_ollama.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interaccion con modelos Ollama locales y cloud usando Structured Outputs — acep_ollama","text":"Si parse_json=TRUE, devuelve una lista o data frame con la respuesta   estructurada segun el esquema. Si parse_json=FALSE, devuelve un string JSON.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_ollama.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interaccion con modelos Ollama locales y cloud usando Structured Outputs — acep_ollama","text":"","code":"if (FALSE) { # \\dontrun{ # Primero, instalar Ollama y descargar un modelo: # Terminal: ollama pull llama3.1  # Extraer entidades de un texto texto <- \"El SUTEBA convoco a un paro en Buenos Aires el 15 de marzo.\" instrucciones <- \"Extrae todas las entidades nombradas del texto.\" schema <- acep_gpt_schema(\"extraccion_entidades\") resultado <- acep_ollama(texto, instrucciones, schema = schema) print(resultado)  # Analisis de sentimiento texto <- \"La protesta fue pacifica y bien organizada.\" schema <- acep_gpt_schema(\"sentimiento\") resultado <- acep_ollama(texto, \"Analiza el sentimiento del texto\", schema = schema) print(resultado$sentimiento_general)  # Usar Ollama Cloud API (requiere API key) # Los modelos cloud se ejecutan sin necesidad de GPU local Sys.setenv(OLLAMA_API_KEY = \"tu-api-key\") resultado_remoto <- acep_ollama(   texto = texto,   instrucciones = \"Extrae entidades\",   modelo = \"deepseek-v3.1:671b-cloud\",  # Modelo cloud de 671B parametros   host = \"https://ollama.com\",   schema = acep_gpt_schema(\"extraccion_entidades\") )  } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_ollama_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Guia de instalacion y uso de Ollama — acep_ollama_setup","title":"Guia de instalacion y uso de Ollama — acep_ollama_setup","text":"Imprime instrucciones para instalar y configurar Ollama en tu sistema.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_ollama_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Guia de instalacion y uso de Ollama — acep_ollama_setup","text":"","code":"acep_ollama_setup()"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":null,"dir":"Reference","previous_headings":"","what":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"Funcion para interactuar con multiples proveedores de IA (OpenAI, Anthropic, Google, Meta, etc.) traves de la API unificada de OpenRouter. Soporta Structured Outputs para modelos compatibles (OpenAI GPT-4o+, Fireworks, y otros). OpenRouter normaliza las diferencias entre proveedores, permitiendo acceder 400+ modelos con una sola API. Ideal para comparar modelos o usar fallbacks automaticos.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"","code":"acep_openrouter(   texto,   instrucciones,   modelo = \"openai/gpt-4o-mini\",   api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),   schema = NULL,   parse_json = TRUE,   temperature = 0,   max_tokens = 2000,   top_p = 0.2,   app_name = NULL,   site_url = NULL,   use_fallback = FALSE,   fallback_provider_order = NULL,   fallback_models = NULL )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"texto Texto analizar. Puede ser una noticia, tweet, documento, etc. instrucciones Instrucciones en lenguaje natural que indican al modelo que hacer con el texto. Ejemplo: \"Extrae todas las entidades nombradas\", \"Clasifica el sentimiento\". modelo Modelo utilizar con formato \"proveedor/modelo\". Ejemplos populares: - OpenAI: `\"openai/gpt-4o-mini\"` (rapido y economico), `\"openai/gpt-4o\"` (potente) - Anthropic: `\"anthropic/claude-sonnet-4.5\"`, `\"anthropic/claude-3.5-haiku\"` - Google: `\"google/gemini-2.5-flash\"`, `\"google/gemini-2.0-flash-001\"` - Meta: `\"meta-llama/llama-3.3-70b-instruct\"`, `\"meta-llama/llama-4-maverick:free\"` - Qwen: `\"qwen/qwen3-next-80b-a3b-instruct-2509\"` - DeepSeek: `\"deepseek/deepseek-chat-v3-0324:free\"`, `\"deepseek/deepseek-r1:free\"` Por defecto: `\"openai/gpt-4o-mini\"`. Ver lista completa: https://openrouter.ai/models api_key Clave de API de OpenRouter. Si se proporciona, busca la variable de entorno `OPENROUTER_API_KEY`. Para obtener una clave: https://openrouter.ai/settings/keys schema Esquema JSON que define la estructura de la respuesta. Puede usar `acep_gpt_schema()` para obtener esquemas predefinidos o crear uno personalizado. Si es `NULL`, usa un esquema simple con campo \"respuesta\". NOTA: Structured Outputs solo funciona con modelos compatibles (OpenAI GPT-4o+, Fireworks). Para otros modelos, se usara JSON mode basico. parse_json Logico. Si `TRUE` (por defecto), parsea automaticamente el JSON un objeto R (lista o data frame). Si `FALSE`, devuelve el JSON como string. temperature Parametro de temperatura (0-2). Valores bajos (0-0.3) generan respuestas mas deterministas. Valores altos (0.7-1) mas creativas. Por defecto: 0. max_tokens Numero maximo de tokens en la respuesta. Por defecto: 2000. top_p Parametro top-p para nucleus sampling (0-1). Por defecto: 0.2. app_name Nombre de tu aplicacion (opcional). Se muestra en openrouter.ai/activity. site_url URL de tu aplicacion (opcional). Para estadisticas en OpenRouter. use_fallback Logico. Si `TRUE`, OpenRouter usara modelos alternativos si el proveedor primario falla. Por defecto: FALSE (sin fallbacks). fallback_provider_order Vector opcional de slugs de proveedores para forzar un orden especifico de enrutamiento (ej.: `c(\"openai\", \"anthropic\")`). Requiere `use_fallback = TRUE` para habilitar intentos sucesivos. fallback_models Vector opcional de modelos alternativos (en formato `\"proveedor/modelo\"`) que se probaran en orden si el modelo principal devuelve un error recuperable (429, 5xx, timeouts). Ideal para definir variantes pagas cuando la version `:free` alcance su limite.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"Si `parse_json=TRUE`, devuelve una lista o data frame con la respuesta   estructurada segun el esquema. Si `parse_json=FALSE`, devuelve un string JSON.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"OpenRouter abstrae las diferencias entre proveedores, mapeando automaticamente los parametros la interfaz nativa de cada modelo. Los parametros soportados por un modelo son ignorados silenciosamente. Esto permite usar la misma funcion para cualquier modelo sin preocuparse por las especificidades de cada API. Cuando `use_fallback = TRUE`, la funcion configura el objeto `provider` de OpenRouter para conservar la resiliencia ante errores transitorios y, si se define `fallback_models`, intenta llamar secuencialmente cada modelo alternativo ante codigos recuperables (429, 5xx, timeouts). Esto evita depender del campo `route`, ya deprecado en la API. Para Structured Outputs estrictos, recomendamos usar modelos OpenAI (gpt-4o+) o Fireworks. Otros modelos intentaran seguir el esquema pero sin garantias estrictas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"modelos-compatibles-y-probados-actualizado-","dir":"Reference","previous_headings":"","what":"MODELOS COMPATIBLES Y PROBADOS (ACTUALIZADO)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"**Importante:** los modelos etiquetados como `:free` operan con cuotas comunitarias y suelen estar sometidos limites de tasa estrictos por parte de OpenRouter. Es frecuente recibir respuestas HTTP 429 (Many Requests) cuando la demanda supera la cuota disponible; este codigo indica que el proveedor rechazo la peticion para proteger la infraestructura compartida. Si ocurre, espera unos segundos y reintenta, o selecciona la variante de pago equivalente (sin sufijo `:free`) o activa `use_fallback` para que OpenRouter cambie automaticamente un modelo disponible.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"openai-familia-gpt-ultima-generacion-","dir":"Reference","previous_headings":"","what":"OpenAI - Familia GPT-5 (Ultima Generacion)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"openai/gpt-5 - Modelo principal GPT-5 openai/gpt-5-pro - Version Pro, maxima precision openai/gpt-5-mini - Version mini, economica openai/gpt-5-nano - Version nano, ultrarrapida openai/gpt-5-chat - Optimizado para chat","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"openai-familia-gpt-","dir":"Reference","previous_headings":"","what":"OpenAI - Familia GPT-4.1","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"openai/gpt-4.1 - Modelo principal GPT-4.1 openai/gpt-4.1-mini - Version mini openai/gpt-4.1-nano - Version nano","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"openai-familia-gpt--1","dir":"Reference","previous_headings":"","what":"OpenAI - Familia GPT-4","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"openai/gpt-4o - GPT-4 optimizado openai/gpt-4o-mini - Economico, rapido, ideal para produccion openai/gpt-4-turbo - Version turbo openai/gpt-4 - Modelo base GPT-4","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"openai-familia-gpt--2","dir":"Reference","previous_headings":"","what":"OpenAI - Familia GPT-3.5","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"openai/gpt-3.5-turbo - Version turbo, economica","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"openai-modelos-oss-open-source-style-","dir":"Reference","previous_headings":"","what":"OpenAI - Modelos OSS (Open Source Style)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"openai/gpt-oss-120b - Modelo grande (120B parametros) openai/gpt-oss-120b:exacto - Version exacta openai/gpt-oss-20b - Modelo pequeno (20B parametros) openai/gpt-oss-20b:free - Version gratuita","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"xai-familia-grok-ultima-generacion-","dir":"Reference","previous_headings":"","what":"xAI - Familia Grok 4 (Ultima Generacion)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"x-ai/grok-4 - Modelo principal Grok 4 x-ai/grok-4-fast - Version rapida, optimizada","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"xai-familia-grok-","dir":"Reference","previous_headings":"","what":"xAI - Familia Grok 3","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"x-ai/grok-3 - Modelo principal Grok 3 x-ai/grok-3-mini - Version mini, economica x-ai/grok-3-beta - Version beta x-ai/grok-3-mini-beta - Version mini beta","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"deepseek-familia-v-ultima-generacion-","dir":"Reference","previous_headings":"","what":"DeepSeek - Familia V3 (Ultima Generacion)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"deepseek/deepseek-v3.2-exp - Version experimental 3.2 deepseek/deepseek-v3.1-terminus - Version terminus 3.1 deepseek/deepseek-v3.1-terminus:exacto - Version terminus exacta","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"deepseek-familia-r-razonamiento-","dir":"Reference","previous_headings":"","what":"DeepSeek - Familia R1 (Razonamiento)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"deepseek/deepseek-r1-0528 - Version R1 de mayo 2028 deepseek/deepseek-r1 - Modelo principal R1 deepseek/deepseek-r1:free - Version R1 gratuita","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"deepseek-r-distilled-basado-en-llama-","dir":"Reference","previous_headings":"","what":"DeepSeek - R1 Distilled (Basado en Llama)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"deepseek/deepseek-r1-distill-llama-70b - R1 destilado en Llama 70B deepseek/deepseek-r1-distill-llama-70b:free - Version gratuita","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"deepseek-chat-y-otros","dir":"Reference","previous_headings":"","what":"DeepSeek - Chat y Otros","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"deepseek/deepseek-chat - Optimizado para chat","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"deepcogito-modelos-especializados","dir":"Reference","previous_headings":"","what":"DeepCogito - Modelos Especializados","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"deepcogito/cogito-v2-preview-deepseek-671b - Modelo cogito 671B basado en DeepSeek","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"meta-llama-familia-","dir":"Reference","previous_headings":"","what":"Meta Llama - Familia 4","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"meta-llama/llama-4-maverick - Llama 4 Maverick","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"meta-llama-familia--1","dir":"Reference","previous_headings":"","what":"Meta Llama - Familia 3.3","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"meta-llama/llama-3.3-70b-instruct - Version de pago meta-llama/llama-3.3-70b-instruct:free - Version gratuita","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"meta-llama-familia--2","dir":"Reference","previous_headings":"","what":"Meta Llama - Familia 3.2","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"meta-llama/llama-3.2-90b-vision-instruct - Con capacidades de vision","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"meta-llama-familia--3","dir":"Reference","previous_headings":"","what":"Meta Llama - Familia 3.1","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"meta-llama/llama-3.1-405b-instruct - Modelo grande 405B meta-llama/llama-3.1-70b-instruct - Modelo mediano 70B","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"nousresearch-modelos-hermes","dir":"Reference","previous_headings":"","what":"NousResearch - Modelos Hermes","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"nousresearch/hermes-3-llama-3.1-405b - Hermes 3 basado en Llama 405B","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"mistral-ai-familia-magistral","dir":"Reference","previous_headings":"","what":"Mistral AI - Familia Magistral","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"mistralai/magistral-medium-2506 - Magistral medium mistralai/magistral-medium-2506:thinking - Con razonamiento extendido","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"mistral-ai-otros-modelos","dir":"Reference","previous_headings":"","what":"Mistral AI - Otros Modelos","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"mistralai/mistral-large-2407 - Mistral large mistralai/mixtral-8x22b-instruct - Mixtral 8x22B (MoE)","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"moonshotai-familia-kimi-k-","dir":"Reference","previous_headings":"","what":"MoonshotAI - Familia Kimi K2","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"moonshotai/kimi-k2 - Modelo principal Kimi K2 moonshotai/kimi-k2-0905 - Version 09/05 moonshotai/kimi-k2-0905:exacto - Version exacta moonshotai/kimi-k2-thinking - Con razonamiento extendido","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"qwen-familia-qwen-b-modelos-grandes-","dir":"Reference","previous_headings":"","what":"Qwen - Familia Qwen3 (235B - Modelos Grandes)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"qwen/qwen3-235b-a22b-2507 - Modelo grande 235B (version 2507) qwen/qwen3-235b-a22b - Modelo grande 235B qwen/qwen3-235b-a22b-thinking-2507 - Con razonamiento extendido qwen/qwen3-max - Version maxima","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"qwen-familia-qwen-b-b-modelos-medianos-","dir":"Reference","previous_headings":"","what":"Qwen - Familia Qwen3 (30B-80B - Modelos Medianos)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"qwen/qwen3-next-80b-a3b-instruct - Modelo next 80B qwen/qwen3-32b - Modelo 32B qwen/qwen3-30b-a3b - Modelo 30B qwen/qwen3-30b-a3b-instruct-2507 - Version instruct 2507 qwen/qwen3-30b-a3b:free - Version 30B gratuita","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"qwen-familia-qwen-modelos-pequenos-","dir":"Reference","previous_headings":"","what":"Qwen - Familia Qwen3 (Modelos Pequenos)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"qwen/qwen3-14b:free - Modelo 14B gratuito qwen/qwen3-4b:free - Modelo 4B gratuito, ultrarrapido","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"qwen-familia-qwen-","dir":"Reference","previous_headings":"","what":"Qwen - Familia Qwen 2.5","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"qwen/qwen-2.5-72b-instruct - Modelo 2.5 generacion anterior qwen/qwen-plus - Version plus","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"google-gemini-familia-ultima-generacion-","dir":"Reference","previous_headings":"","what":"Google Gemini - Familia 2.5 (Ultima Generacion)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"google/gemini-2.5-flash - Rapido, ultima generacion google/gemini-2.5-pro - Mayor precision, ultima generacion google/gemini-2.5-flash-lite - Ultrarrapido, ligero google/gemini-2.5-flash-preview-09-2025 - Preview version septiembre google/gemini-2.5-flash-lite-preview-09-2025 - Preview lite septiembre","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"google-gemini-familia-","dir":"Reference","previous_headings":"","what":"Google Gemini - Familia 2.0","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"google/gemini-2.0-flash-001 - Version estable 2.0 google/gemini-2.0-flash-lite-001 - Version ligera 2.0","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"google-gemini-familia--1","dir":"Reference","previous_headings":"","what":"Google Gemini - Familia 1.5","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"google/gemini-pro-1.5 - Version anterior, estable","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"anthropic-claude-familia-haiku-rapidos-y-economicos-","dir":"Reference","previous_headings":"","what":"Anthropic Claude - Familia Haiku (Rapidos y Economicos)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"anthropic/claude-3.5-haiku - Version 3.5, muy rapido anthropic/claude-3-haiku - Version 3, economico anthropic/claude-haiku-4.5 - Ultima version, mas preciso","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"anthropic-claude-familia-sonnet-equilibrados-","dir":"Reference","previous_headings":"","what":"Anthropic Claude - Familia Sonnet (Equilibrados)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"anthropic/claude-3.5-sonnet - Popular, buen balance anthropic/claude-3.7-sonnet - Version mejorada anthropic/claude-3.7-sonnet:thinking - Con razonamiento extendido anthropic/claude-sonnet-4 - Generacion 4 anthropic/claude-sonnet-4.5 - Ultima version, mas preciso","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"anthropic-claude-familia-opus-maxima-precision-","dir":"Reference","previous_headings":"","what":"Anthropic Claude - Familia Opus (Maxima Precision)","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"anthropic/claude-3-opus - Version 3, muy preciso anthropic/claude-opus-4 - Generacion 4 anthropic/claude-opus-4.1 - Ultima version disponible","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_openrouter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interaccion con modelos de IA usando OpenRouter — acep_openrouter","text":"","code":"if (FALSE) { # \\dontrun{ # Configurar API key Sys.setenv(OPENROUTER_API_KEY = \"tu-api-key\")  # Usar GPT-4o mini (rapido y economico) texto <- \"El SUTEBA convoco a un paro en Buenos Aires el 15 de marzo.\" resultado <- acep_openrouter(texto, \"Extrae las entidades nombradas\",                               modelo = \"openai/gpt-4o-mini\",                               schema = acep_gpt_schema(\"extraccion_entidades\"))  # Comparar con Claude resultado_claude <- acep_openrouter(texto, \"Extrae las entidades nombradas\",                                      modelo = \"anthropic/claude-sonnet-4.5\",                                      schema = acep_gpt_schema(\"extraccion_entidades\"))  # Usar modelo gratuito resultado_free <- acep_openrouter(texto, \"Clasifica el sentimiento\",                                    modelo = \"meta-llama/llama-4-maverick:free\",                                    schema = acep_gpt_schema(\"sentimiento\"))  # Definir fallback hacia variantes pagas o proveedores alternativos resultado_resiliente <- acep_openrouter(   texto,   \"Extrae las entidades nombradas\",   modelo = \"meta-llama/llama-4-maverick:free\",   schema = acep_gpt_schema(\"extraccion_entidades\"),   use_fallback = TRUE,   fallback_models = c(\"meta-llama/llama-4-maverick\", \"openai/gpt-4o-mini\") )  } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_pipeline.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipeline completo de análisis de conflictividad — acep_pipeline","title":"Pipeline completo de análisis de conflictividad — acep_pipeline","text":"Ejecuta un flujo de trabajo completo de análisis de texto que incluye: limpieza opcional, conteo de menciones de un diccionario, y cálculo de intensidad. Esta función encadena automáticamente las funciones `pipe_clean()`, `pipe_count()` y `pipe_intensity()` para facilitar análisis rápidos.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_pipeline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipeline completo de análisis de conflictividad — acep_pipeline","text":"","code":"acep_pipeline(texto, dic, clean = TRUE, ...)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_pipeline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipeline completo de análisis de conflictividad — acep_pipeline","text":"texto Vector de caracteres con los textos analizar. dic Vector de caracteres con las palabras del diccionario de conflictividad (o cualquier otro diccionario temático) buscar en los textos. clean Lógico. Si `TRUE` (por defecto), aplica limpieza y normalización al texto antes del análisis usando `acep_clean()`. ... Argumentos adicionales para pasar `acep_clean()` cuando `clean = TRUE`. Por ejemplo: `rm_stopwords = TRUE`, `rm_num = TRUE`, `tolower = TRUE`.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_pipeline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipeline completo de análisis de conflictividad — acep_pipeline","text":"Objeto de clase `acep_result` con tipo `\"intensidad\"` que contiene: id: Identificadores de cada texto texto: Textos analizados (limpios si `clean = TRUE`) frecuencia: Número de menciones del diccionario por texto n_palabras: Número total de palabras por texto intensidad: Índice normalizado de intensidad (frecuencia/n_palabras)","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_pipeline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pipeline completo de análisis de conflictividad — acep_pipeline","text":"","code":"if (FALSE) { # \\dontrun{ # Pipeline completo con limpieza textos <- c(\"El SUTEBA va al paro por mejoras salariales\",             \"SOIP en lucha contra despidos\") dic_conflictos <- c(\"paro\", \"lucha\", \"reclamo\", \"protesta\") resultado <- acep_pipeline(textos, dic_conflictos,                            clean = TRUE, rm_stopwords = TRUE) print(resultado)  # Pipeline sin limpieza resultado <- acep_pipeline(textos, dic_conflictos, clean = FALSE) } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_plot_rst.html","id":null,"dir":"Reference","previous_headings":"","what":"Resumen visual de la serie temporal de los indices de conflictividad. — acep_plot_rst","title":"Resumen visual de la serie temporal de los indices de conflictividad. — acep_plot_rst","text":"Función que devuelve un panel visual de cuatro gráficos de barras con variables proxy de los indices de conflictividad agrupados por segmento de tiempo.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_plot_rst.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resumen visual de la serie temporal de los indices de conflictividad. — acep_plot_rst","text":"","code":"acep_plot_rst(datos, tagx = \"horizontal\")"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_plot_rst.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resumen visual de la serie temporal de los indices de conflictividad. — acep_plot_rst","text":"datos data frame con datos procesados. tagx orientación de las etiquetas del eje x ('horizontal' | 'vertical').","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_plot_rst.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resumen visual de la serie temporal de los indices de conflictividad. — acep_plot_rst","text":"Si todas las entradas son correctas, la salida sera una imagen de cuatro paneles.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_plot_rst.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Resumen visual de la serie temporal de los indices de conflictividad. — acep_plot_rst","text":"","code":"datos <- acep_bases$rp_procesada datos_procesados_anio <- acep_sst(datos, st = 'anio') acep_plot_rst(datos_procesados_anio, tagx = 'vertical')"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_plot_st.html","id":null,"dir":"Reference","previous_headings":"","what":"Gráfico de barras de la serie temporal de indices de conflictividad. — acep_plot_st","title":"Gráfico de barras de la serie temporal de indices de conflictividad. — acep_plot_st","text":"Función que devuelve un gráfico de barras con la serie temporal de indices de conflictividad por dia, mes o anio.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_plot_st.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gráfico de barras de la serie temporal de indices de conflictividad. — acep_plot_st","text":"","code":"acep_plot_st(   x,   y,   t = \"\",   ejex = \"\",   ejey = \"\",   etiquetax = \"horizontal\",   color = \"mint\" )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_plot_st.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gráfico de barras de la serie temporal de indices de conflictividad. — acep_plot_st","text":"x vector de valores del eje x (por ejemplo, fechas). y vector de valores numéricos del eje y (por ejemplo, menciones). t titulo del gráfico. ejex nombre del eje x. ejey nombre del eje y. etiquetax orientación de las etiquetas del eje x ('horizontal' | 'vertical'). color color de las barras.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_plot_st.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gráfico de barras de la serie temporal de indices de conflictividad. — acep_plot_st","text":"Si todas las entradas son correctas, la salida sera una imagen de un panel.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_plot_st.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gráfico de barras de la serie temporal de indices de conflictividad. — acep_plot_st","text":"","code":"datos <- acep_bases$rp_procesada dpa <- acep_sst(datos, st = 'anio') acep_plot_st( dpa$st, dpa$frecm, t = 'Evoluci\\u00f3n de la conflictividad en el sector pesquero argentino', ejex = 'A\\u00f1os analizados', ejey = 'Menciones de t\\u00e9rminos del diccionario de conflictos', etiquetax = 'horizontal')"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_postag.html","id":null,"dir":"Reference","previous_headings":"","what":"Etiquetado POS adaptativo con optimizaciones avanzadas — acep_postag","title":"Etiquetado POS adaptativo con optimizaciones avanzadas — acep_postag","text":"Version optimizada de acep_postag que se adapta automaticamente al tamano del input. Implementa procesamiento por lotes (chunking) para grandes volumenes, cache de geocodificacion para evitar consultas repetidas, y estrategias de procesamiento adaptativas segun la cantidad de textos. Puede procesar desde 10 hasta millones de textos de forma eficiente.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_postag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Etiquetado POS adaptativo con optimizaciones avanzadas — acep_postag","text":"","code":"acep_postag(   texto,   core = \"es_core_news_lg\",   bajar_core = TRUE,   inst_spacy = FALSE,   inst_miniconda = FALSE,   inst_reticulate = FALSE,   chunk_size = 1000,   geocode_cache_file = \"geocode_cache.json\",   use_cache = TRUE,   show_progress = TRUE )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_postag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Etiquetado POS adaptativo con optimizaciones avanzadas — acep_postag","text":"texto Vector de caracteres con los textos procesar. core Idioma del modelo de etiquetado POS del paquete spacyr. Opciones disponibles: 'es_core_news_sm', 'es_core_news_md', 'es_core_news_lg' (espanol), 'pt_core_news_sm', 'pt_core_news_md', 'pt_core_news_lg' (portugues), 'en_core_web_sm', 'en_core_web_md', 'en_core_web_lg', 'en_core_web_trf' (ingles). Default: \"es_core_news_lg\". bajar_core Parametro booleano que define si descargar o el modelo de etiquetado POS. Default: TRUE. inst_spacy Parametro booleano que define si instalar o spacy (Python). Default: FALSE. inst_miniconda Parametro booleano que define si instalar o miniconda. Default: FALSE. inst_reticulate Parametro booleano que define si instalar o el paquete reticulate. Default: FALSE. chunk_size Tamano de los lotes para procesamiento chunking. Ajustar segun RAM disponible: 500 para sistemas con 2-4 GB RAM, 1000 para 8 GB RAM (default), 2000-5000 para 16+ GB RAM. Default: 1000. geocode_cache_file Ruta del archivo JSON para guardar cache de geocodificacion. Permite evitar consultas repetidas la API de Nominatim y compartir cache entre proyectos. Default: \"geocode_cache.json\". use_cache Parametro booleano que activa/desactiva el sistema de cache de geocodificacion. Desactivar para forzar re-geocodificacion de todas las ubicaciones. Default: TRUE. show_progress Parametro booleano que controla la visualizacion de mensajes de progreso durante el procesamiento. Util para operaciones largas. Default: TRUE.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_postag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Etiquetado POS adaptativo con optimizaciones avanzadas — acep_postag","text":"Lista con seis elementos en formato tabular: texto_tag: Data frame con tokens etiquetados (POS, lemas, dependencias, etc.) texto_tag_entity: Data frame con entidades nombradas consolidadas texto_only_entity: Data frame con solo las entidades extraidas texto_only_entity_loc: Data frame con entidades de tipo LOC geocodificadas (lat/long) texto_nounphrase: Data frame con frases nominales consolidadas texto_only_nounphrase: Data frame con solo las frases nominales extraidas","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_postag.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Etiquetado POS adaptativo con optimizaciones avanzadas — acep_postag","text":"La funcion implementa dos estrategias de procesamiento automaticas: Batch Processing (<= 100 textos): Procesa todos los textos en una sola llamada   para maxima velocidad. Chunking (> 100 textos): Divide los textos en lotes del tamano especificado   en chunk_size para controlar el uso de memoria y permitir procesamiento de grandes volumenes. El sistema de cache de geocodificacion guarda las coordenadas de ubicaciones ya consultadas en formato JSON, evitando consultas repetidas la API de Nominatim (que tiene limite de 1 req/seg). Esto puede reducir el tiempo de procesamiento en 50-90 Para datasets muy grandes (>100,000 textos), se recomienda procesar en lotes usando la funcion auxiliar proporcionada en los ejemplos y guardar resultados incrementalmente.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_postag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Etiquetado POS adaptativo con optimizaciones avanzadas — acep_postag","text":"","code":"if (FALSE) { # \\dontrun{ # Ejemplo basico con pocos textos textos <- c(   \"En Mar del Plata el SOIP declara la huelga en demanda de aumento salarial.\",   \"La manifestacion se realizo en Buenos Aires el 15 de marzo.\",   \"El presidente visito Cordoba para inaugurar la nueva planta.\" ) resultado <- acep_postag(texto = textos, bajar_core = FALSE) head(resultado$texto_tag)  # Ejemplo con dataset mediano y configuracion personalizada resultado <- acep_postag(   texto = mis_1000_textos,   bajar_core = FALSE,   chunk_size = 500,   geocode_cache_file = \"cache/ubicaciones_argentina.json\",   use_cache = TRUE )  # Ver ubicaciones geocodificadas head(resultado$texto_only_entity_loc)  # Procesamiento incremental para datasets muy grandes procesar_incremental <- function(textos, batch_size = 10000) {   dir.create(\"resultados\", showWarnings = FALSE)   n_batches <- ceiling(length(textos) / batch_size)    for (i in 1:n_batches) {     start_idx <- (i - 1) * batch_size + 1     end_idx <- min(i * batch_size, length(textos))     batch <- textos[start_idx:end_idx]      resultado <- acep_postag(       texto = batch,       bajar_core = FALSE,       chunk_size = 2000,       use_cache = TRUE,       geocode_cache_file = \"cache_global.json\"     )      saveRDS(resultado, sprintf(\"resultados/batch_%04d.rds\", i))     message(sprintf(\"Batch %d/%d completado\", i, n_batches))   } }  # Usar funcion incremental procesar_incremental(mis_millones_de_textos, batch_size = 10000)  # Ver contenido del cache cache <- jsonlite::read_json(\"geocode_cache.json\", simplifyVector = TRUE) print(paste(\"Ubicaciones en cache:\", nrow(cache))) } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_postag_hibrido.html","id":null,"dir":"Reference","previous_headings":"","what":"Etiquetado POS, lematizacion y extraccion de entidades con spacyr — acep_postag_hibrido","title":"Etiquetado POS, lematizacion y extraccion de entidades con spacyr — acep_postag_hibrido","text":"Realiza analisis linguistico completo de textos usando la biblioteca spaCy traves de spacyr. Incluye: etiquetado POS (Part--Speech), lematizacion, tokenizacion, extraccion de entidades nombradas, frases nominales y geocodificacion de ubicaciones. La funcion procesa automaticamente grandes volumenes de texto dividiendolos en lotes (chunks) y soporta procesamiento paralelo para acelerar el analisis","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_postag_hibrido.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Etiquetado POS, lematizacion y extraccion de entidades con spacyr — acep_postag_hibrido","text":"","code":"acep_postag_hibrido(   texto,   core = \"es_core_news_lg\",   bajar_core = TRUE,   inst_spacy = FALSE,   inst_miniconda = FALSE,   inst_reticulate = FALSE,   chunk_size = 1000,   parallel_chunks = FALSE,   n_cores = NULL,   geocode_cache_file = \"geocode_cache.json\",   use_cache = TRUE,   show_progress = TRUE )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_postag_hibrido.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Etiquetado POS, lematizacion y extraccion de entidades con spacyr — acep_postag_hibrido","text":"texto Vector de caracteres con los textos analizar. core Modelo de lenguaje de spaCy utilizar. Opciones: `\"es_core_news_sm\"`, `\"es_core_news_md\"`, `\"es_core_news_lg\"` (espanol), `\"en_core_web_sm\"`, `\"en_core_web_md\"`, `\"en_core_web_lg\"` (ingles), `\"pt_core_news_sm\"`, `\"pt_core_news_md\"`, `\"pt_core_news_lg\"` (portugues). Por defecto: `\"es_core_news_lg\"`. bajar_core Logico. Si `TRUE`, descarga automaticamente el modelo si esta instalado. inst_spacy Logico. Si `TRUE`, instala la biblioteca spaCy en el entorno Python. inst_miniconda Logico. Si `TRUE`, instala Miniconda (necesario para spaCy). inst_reticulate Logico. Si `TRUE`, instala el paquete reticulate de R. chunk_size Numero de textos procesar por lote. Valores mas bajos consumen menos memoria pero tardan mas. Por defecto: 1000. parallel_chunks Logico. Si `TRUE`, procesa los lotes en paralelo usando multiples nucleos del CPU. Requiere los paquetes `future` y `furrr`. Por defecto: `FALSE`. n_cores Numero de nucleos de CPU usar en modo paralelo. Si es `NULL`, detecta automaticamente el numero de nucleos disponibles menos uno. geocode_cache_file Ruta al archivo JSON donde se almacena el cache de geocodificacion para evitar consultas repetidas. Por defecto: `\"geocode_cache.json\"`. use_cache Logico. Si `TRUE`, usa y actualiza el cache de geocodificacion. show_progress Logico. Si `TRUE`, muestra mensajes de progreso en la consola.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_postag_hibrido.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Etiquetado POS, lematizacion y extraccion de entidades con spacyr — acep_postag_hibrido","text":"Lista con 6 data frames que contienen diferentes niveles de analisis: texto_tag: Tokenizacion completa con etiquetas POS, lemas, dependencias     sintacticas y atributos morfologicos para cada token texto_tag_entity: Tokens con entidades nombradas consolidadas     (ej: \"Mar del Plata\" como una sola entidad en lugar de 3 tokens separados) texto_only_entity: Solo las entidades nombradas extraidas     (personas, organizaciones, ubicaciones, fechas, etc.) texto_only_entity_loc: Entidades de tipo ubicacion (LOC)     con coordenadas geograficas (latitud/longitud) obtenidas mediante geocodificacion texto_nounphrase: Tokens con frases nominales consolidadas texto_only_nounphrase: Solo las frases nominales extraidas","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_postag_hibrido.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Etiquetado POS, lematizacion y extraccion de entidades con spacyr — acep_postag_hibrido","text":"","code":"if (FALSE) { # \\dontrun{ # Analisis basico de un texto texto <- \"El SUTEBA convoco a un paro en Mar del Plata el 15 de marzo.\" resultado <- acep_postag_hibrido(texto)  # Ver tokens con etiquetas POS head(resultado$texto_tag)  # Ver entidades nombradas print(resultado$texto_only_entity)  # Ver ubicaciones geocodificadas print(resultado$texto_only_entity_loc)  # Procesar multiples textos con procesamiento paralelo textos <- c(\"Primera noticia sobre conflictos.\",             \"Segunda noticia sobre protestas.\",             \"Tercera noticia sobre reclamos.\") resultado <- acep_postag_hibrido(textos,                                  parallel_chunks = TRUE,                                  chunk_size = 100) } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_process_chunks.html","id":null,"dir":"Reference","previous_headings":"","what":"Procesamiento de textos en lotes para optimizar memoria — acep_process_chunks","title":"Procesamiento de textos en lotes para optimizar memoria — acep_process_chunks","text":"Divide un vector grande de textos en lotes (chunks) mas pequenos y los procesa secuencialmente aplicando una funcion de ACEP. Esta estrategia permite analizar corpus extensos (millones de documentos) sin superar la capacidad de memoria RAM disponible. La funcion combina automaticamente los resultados de todos los lotes.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_process_chunks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Procesamiento de textos en lotes para optimizar memoria — acep_process_chunks","text":"","code":"acep_process_chunks(   texto,   funcion,   chunk_size = 1000,   show_progress = TRUE,   ... )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_process_chunks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Procesamiento de textos en lotes para optimizar memoria — acep_process_chunks","text":"texto Vector de caracteres con los textos procesar. funcion Funcion de ACEP aplicar cada lote. Ejemplos: `acep_clean`, `acep_token`, `acep_count`, `acep_upos`, etc. Debe ser una funcion que acepte un vector de textos como primer argumento. chunk_size Numero de textos por lote. Valores mas bajos reducen el consumo de memoria pero aumentan el tiempo total de procesamiento. Por defecto: 1000. show_progress Logico. Si `TRUE`, muestra mensajes informativos sobre el progreso del procesamiento (que lote se esta procesando). Por defecto: `TRUE`. ... Argumentos adicionales que se pasan directamente la funcion especificada en el parametro `funcion`. Ejemplo: si `funcion = acep_clean`, puede pasar `rm_stopwords = TRUE`, `tolower = TRUE`, etc.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_process_chunks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Procesamiento de textos en lotes para optimizar memoria — acep_process_chunks","text":"El tipo de resultado depende de la funcion aplicada: Si la funcion retorna un vector, devuelve un vector combinado Si la funcion retorna un data frame, devuelve un data frame combinado (rbind) Si la funcion retorna una lista, devuelve una lista de listas","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_process_chunks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Procesamiento de textos en lotes para optimizar memoria — acep_process_chunks","text":"","code":"if (FALSE) { # \\dontrun{ # Procesar 10,000 textos con limpieza en lotes de 1000 textos_limpios <- acep_process_chunks(   texto = corpus_grande,   funcion = acep_clean,   chunk_size = 1000,   rm_stopwords = TRUE )  # Tokenizar corpus masivo tokens <- acep_process_chunks(   texto = corpus_masivo,   funcion = acep_token,   chunk_size = 500,   tolower = TRUE )  # Contar menciones en corpus grande diccionario <- c(\"paro\", \"huelga\", \"protesta\") frecuencias <- acep_process_chunks(   texto = corpus_grande,   funcion = acep_count,   chunk_size = 2000,   dic = diccionario ) } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_prompt_gpt.html","id":null,"dir":"Reference","previous_headings":"","what":"Colección de instrucciones para GPT. — acep_prompt_gpt","title":"Colección de instrucciones para GPT. — acep_prompt_gpt","text":"Colección de instrucciones para interactuar con los modelos de OpenAI. Las instrucciones fueron testeadas en el marco de las tareas que realizamos en el Observatorio de Conflictividad Social de la Universidad Nacional de Mar del Plata.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_prompt_gpt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Colección de instrucciones para GPT. — acep_prompt_gpt","text":"","code":"data(acep_prompt_gpt)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_prompt_gpt.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Colección de instrucciones para GPT. — acep_prompt_gpt","text":"Es un objeto de clase 'list' con 4 componentes. instruccion_breve_sao_es es un texto en castellano con instrucciones breves para  extraer eventos de protesta y codificarlos con las siguientes claves: 'fecha',  'sujeto', 'accion', 'objeto', 'lugar'. instruccion_larga_sao_es es un texto en castellano con instrucciones largas para  extraer eventos de protesta y codificarlos con las siguientes claves: 'id',  'cronica', 'fecha', 'sujeto', 'organizacion', 'participacion', 'accion',  'objeto', 'lugar'. instruccion_breve_sao_en es un texto en inglés con instrucciones breves para  extraer eventos de protesta y codificarlos con las siguientes claves: 'date',  'subject', 'action', 'object', 'place'. instruccion_larga_sao_en es un texto en inglés con instrucciones largas para  extraer eventos de protesta y codificarlos con las siguientes claves: 'id',  'chronicle', 'date', 'subject', 'organization', 'participation', 'action',  'object', 'place'.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_prompt_gpt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Colección de instrucciones para GPT. — acep_prompt_gpt","text":"","code":"prompt01 <- acep_prompt_gpt$instruccion_larga_sao_es prompt01 #> [1] \"Su tarea consiste en identificar en el texto las acciones de protesta como unidades de análisis y generar un JSON que incluya sólo 9 claves por acción identificada: 'id', 'cronica', 'fecha', 'sujeto', 'organizacion', 'participacion', 'accion', 'objeto', 'lugar'.\\nSi el texto contiene más de una acción, cada una debe tratarse como unidad de análisis independiente.\\nLos valores de las 9 claves deben ser el producto de extracciones limpias del texto.\\n    'id': Identificador único del texto en formato numérico. Se repite para todas las acciones y es el primero en aparecer.\\n    'cronica': Un resumen de la acción identificada en una frase.\\n    'fecha': Formato 'yyyy-mm-dd' de la fecha de la acción de protesta. Se repite el mismo valor para todas las acciones y es la primera fecha que aparece.\\n    'sujeto': Describe quién realiza la acción de protesta en un máximo de 5 palabras.\\n    'organizacion': Identifica las organizaciones participantes en la acción de protesta. Si no hay información, repite el valor de 'sujeto'.\\n    'participacion': Número de individuos o población que participaron en la acción de protesta. Si no hay información, se introduce el número 0.\\n    'accion': Descripción de la acción de protesta en un máximo de 3 palabras.\\n    'objeto': Identifica contra quién o qué se lleva a cabo la acción de protesta en un máximo de 6 palabras. Si no hay información, se usa null.\\n    'lugar': Localidad o ubicación geográfica donde tiene lugar la acción de protesta en un máximo de 4 palabras.\""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_regex_cache_size.html","id":null,"dir":"Reference","previous_headings":"","what":"Consultar tamaño del caché de regex — acep_regex_cache_size","title":"Consultar tamaño del caché de regex — acep_regex_cache_size","text":"Devuelve el número de patrones regex almacenados actualmente en el caché interno de `acep_count()`. Cada diccionario único genera una entrada en el caché.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_regex_cache_size.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Consultar tamaño del caché de regex — acep_regex_cache_size","text":"","code":"acep_regex_cache_size()"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_regex_cache_size.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Consultar tamaño del caché de regex — acep_regex_cache_size","text":"Número entero con la cantidad de patrones en caché.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_regex_cache_size.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Consultar tamaño del caché de regex — acep_regex_cache_size","text":"","code":"# Ver cuántos patrones hay en caché acep_regex_cache_size() #> [1] 1"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructor de resultados de analisis — acep_result","title":"Constructor de resultados de analisis — acep_result","text":"Crea un objeto de clase `acep_result` que encapsula los resultados de un analisis de texto realizado con funciones de ACEP. Este objeto proporciona metodos especializados para visualizacion (`plot()`), resumen (`summary()`) y conversion data frame (`.data.frame()`).","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructor de resultados de analisis — acep_result","text":"","code":"acep_result(data, tipo = \"general\", metadata = NULL)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructor de resultados de analisis — acep_result","text":"data Data frame con los resultados del analisis. tipo Tipo de resultado que contiene el objeto. Valores comunes: `\"frecuencia\"`, `\"intensidad\"`, `\"svo\"`, `\"serie_temporal\"`, `\"general\"`. Este parametro determina el comportamiento de los metodos de impresion y visualizacion. metadata Lista opcional con informacion sobre el analisis realizado (ej: diccionario utilizado, parametros aplicados, corpus de origen).","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constructor de resultados de analisis — acep_result","text":"Objeto de clase `acep_result` con la siguiente estructura: data: Data frame con los resultados del analisis tipo: Etiqueta del tipo de resultado metadata: Informacion adicional del analisis fecha_creacion: Timestamp de creacion del objeto","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constructor de resultados de analisis — acep_result","text":"","code":"# Crear resultado de analisis de frecuencias datos <- data.frame(   texto = c(\"El SUTEBA va al paro\", \"SOIP protesta\"),   frecuencia = c(5, 3) ) resultado <- acep_result(datos, tipo = \"frecuencia\") print(resultado) #> acep_result object #> ================== #> Tipo: frecuencia  #> Filas: 2  #> Columnas: 2  #> Creado: 2025-11-10 00:42:20  #>  #> Primeras filas: #>                  texto frecuencia #> 1 El SUTEBA va al paro          5 #> 2        SOIP protesta          3 summary(resultado) #> acep_result summary #> =================== #> Tipo: frecuencia  #> Dimensiones: 2 x 2  #> Columnas: texto, frecuencia  #>   # Convertir a data frame df <- as.data.frame(resultado)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_rs.html","id":null,"dir":"Reference","previous_headings":"","what":"Cadenas de caracteres para limpiar y normalizar textos. — acep_rs","title":"Cadenas de caracteres para limpiar y normalizar textos. — acep_rs","text":"Cadenas de caracteres y expresiones regulares para limpiar y normalizar textos.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_rs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cadenas de caracteres para limpiar y normalizar textos. — acep_rs","text":"","code":"data(acep_rs)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_rs.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cadenas de caracteres para limpiar y normalizar textos. — acep_rs","text":"Son cadenas de caracteres. sw1 es un string de palabras vacias. sw1 es un string de palabras vacias. dias es un string de dias. meses es un string de meses. emoji es un string con expresiones regulares para emojis. sintildes es un string de letras sin tildes. tildes es un string de letras con tildes. punt es un string de puntuación. num es una expresión regular para números. hashtag es una expresión regular para hashtag. espacios es una expresión regular para espacios. saltos es una expresión regular para saltos de línea. url es una expresión regular para urls. users es una expresión regular para usuarixs.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_rs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cadenas de caracteres para limpiar y normalizar textos. — acep_rs","text":"","code":"print(acep_rs) #> $sintildes #> [1] \"SZszYAAAAAACEEEEIIIIDNOOOOOUUUUYaaaaaaceeeeiiiidnooooouuuuyy\" #>  #> $url #> [1] \"http\\\\S+|ftp\\\\S+|Http\\\\S+|Ftp\\\\S+|HTTP\\\\S+|FTP\\\\S+\" #>  #> $users #> [1] \"@\\\\S+\" #>  #> $saltos #> [1] \"[ \\t\\r\\n]\" #>  #> $espacios #> [1] \"^ *|(?<= ) | *$\" #>  #> $hashtag #> [1] \"#\\\\S+\" #>  #> $num #> [1] \"[[:digit:]]*\" #>  #> $sw1 #> [1] \"\\\\bde\\\\b|\\\\bla\\\\b|\\\\bque\\\\b|\\\\bel\\\\b|\\\\ben\\\\b|\\\\by\\\\b|\\\\ba\\\\b|\\\\blos\\\\b|\\\\bdel\\\\b|\\\\bse\\\\b|\\\\blas\\\\b|\\\\bpor\\\\b|\\\\bun\\\\b|\\\\bpara\\\\b|\\\\bcon\\\\b|\\\\bno\\\\b|\\\\buna\\\\b|\\\\bsu\\\\b|\\\\bal\\\\b|\\\\blo\\\\b|\\\\bcomo\\\\b|\\\\bmás\\\\b|\\\\bpero\\\\b|\\\\bsus\\\\b|\\\\ble\\\\b|\\\\bya\\\\b|\\\\bo\\\\b|\\\\beste\\\\b|\\\\bsí\\\\b|\\\\bporque\\\\b|\\\\besta\\\\b|\\\\bentre\\\\b|\\\\bcuando\\\\b|\\\\bmuy\\\\b|\\\\bsin\\\\b|\\\\bsobre\\\\b|\\\\btambién\\\\b|\\\\bme\\\\b|\\\\bhasta\\\\b|\\\\bhay\\\\b|\\\\bdonde\\\\b|\\\\bquien\\\\b|\\\\bdesde\\\\b|\\\\btodo\\\\b|\\\\bnos\\\\b|\\\\bdurante\\\\b|\\\\btodos\\\\b|\\\\buno\\\\b|\\\\bles\\\\b|\\\\bni\\\\b|\\\\bcontra\\\\b|\\\\botros\\\\b|\\\\bese\\\\b|\\\\beso\\\\b|\\\\bante\\\\b|\\\\bellos\\\\b|\\\\be\\\\b|\\\\besto\\\\b|\\\\bmí\\\\b|\\\\bantes\\\\b|\\\\balgunos\\\\b|\\\\bqué\\\\b|\\\\bunos\\\\b|\\\\byo\\\\b|\\\\botro\\\\b|\\\\botras\\\\b|\\\\botra\\\\b|\\\\bél\\\\b|\\\\btanto\\\\b|\\\\besa\\\\b|\\\\bestos\\\\b|\\\\bmucho\\\\b|\\\\bquienes\\\\b|\\\\bnada\\\\b|\\\\bmuchos\\\\b|\\\\bcual\\\\b|\\\\bpoco\\\\b|\\\\bella\\\\b|\\\\bestar\\\\b|\\\\bestas\\\\b|\\\\balgunas\\\\b|\\\\balgo\\\\b|\\\\bnosotros\\\\b|\\\\bmi\\\\b|\\\\bmis\\\\b|\\\\btú\\\\b|\\\\bte\\\\b|\\\\bti\\\\b|\\\\btu\\\\b|\\\\btus\\\\b|\\\\bellas\\\\b|\\\\bnosotras\\\\b|\\\\bvosotros\\\\b|\\\\bvosotras\\\\b|\\\\bos\\\\b|\\\\bmío\\\\b|\\\\bmía\\\\b|\\\\bmíos\\\\b|\\\\bmías\\\\b|\\\\btuyo\\\\b|\\\\btuya\\\\b|\\\\btuyos\\\\b|\\\\btuyas\\\\b|\\\\bsuyo\\\\b|\\\\bsuya\\\\b|\\\\bsuyos\\\\b|\\\\bsuyas\\\\b|\\\\bnuestro\\\\b|\\\\bnuestra\\\\b|\\\\bnuestros\\\\b|\\\\bnuestras\\\\b|\\\\bvuestro\\\\b|\\\\bvuestra\\\\b|\\\\bvuestros\\\\b|\\\\bvuestras\\\\b|\\\\besos\\\\b|\\\\besas\\\\b|\\\\bestoy\\\\b|\\\\bestás\\\\b|\\\\bestá\\\\b|\\\\bestamos\\\\b|\\\\bestáis\\\\b|\\\\bestán\\\\b|\\\\besté\\\\b|\\\\bestés\\\\b|\\\\bestemos\\\\b|\\\\bestéis\\\\b|\\\\bestén\\\\b|\\\\bestaré\\\\b|\\\\bestarás\\\\b|\\\\bestará\\\\b|\\\\bestaremos\\\\b|\\\\bestaréis\\\\b|\\\\bestarán\\\\b|\\\\bestaría\\\\b|\\\\bestarías\\\\b|\\\\bestaríamos\\\\b|\\\\bestaríais\\\\b|\\\\bestarían\\\\b|\\\\bestaba\\\\b|\\\\bestabas\\\\b|\\\\bestábamos\\\\b|\\\\bestabais\\\\b|\\\\bestaban\\\\b|\\\\bestuve\\\\b|\\\\bestuviste\\\\b|\\\\bestuvo\\\\b|\\\\bestuvimos\\\\b|\\\\bestuvisteis\\\\b|\\\\bestuvieron\\\\b|\\\\bestuviera\\\\b|\\\\bestuvieras\\\\b|\\\\bestuviéramos\\\\b|\\\\bestuvierais\\\\b|\\\\bestuvieran\\\\b|\\\\bestuviese\\\\b|\\\\bestuvieses\\\\b|\\\\bestuviésemos\\\\b|\\\\bestuvieseis\\\\b|\\\\bestuviesen\\\\b|\\\\bestando\\\\b|\\\\bestado\\\\b|\\\\bestada\\\\b|\\\\bestados\\\\b|\\\\bestadas\\\\b|\\\\bestad\\\\b|\\\\bhe\\\\b|\\\\bhas\\\\b|\\\\bha\\\\b|\\\\bhemos\\\\b|\" #>  #> $sw2 #> [1] \"\\\\bhabéis\\\\b|\\\\bhan\\\\b|\\\\bhaya\\\\b|\\\\bhayas\\\\b|\\\\bhayamos\\\\b|\\\\bhayáis\\\\b|\\\\bhayan\\\\b|\\\\bhabré\\\\b|\\\\bhabrás\\\\b|\\\\bhabrá\\\\b|\\\\bhabremos\\\\b|\\\\bhabréis\\\\b|\\\\bhabrán\\\\b|\\\\bhabría\\\\b|\\\\bhabrías\\\\b|\\\\bhabríamos\\\\b|\\\\bhabríais\\\\b|\\\\bhabrían\\\\b|\\\\bhabía\\\\b|\\\\bhabías\\\\b|\\\\bhabíamos\\\\b|\\\\bhabíais\\\\b|\\\\bhabían\\\\b|\\\\bhube\\\\b|\\\\bhubiste\\\\b|\\\\bhubo\\\\b|\\\\bhubimos\\\\b|\\\\bhubisteis\\\\b|\\\\bhubieron\\\\b|\\\\bhubiera\\\\b|\\\\bhubieras\\\\b|\\\\bhubiéramos\\\\b|\\\\bhubierais\\\\b|\\\\bhubieran\\\\b|\\\\bhubiese\\\\b|\\\\bhubieses\\\\b|\\\\bhubiésemos\\\\b|\\\\bhubieseis\\\\b|\\\\bhubiesen\\\\b|\\\\bhabiendo\\\\b|\\\\bhabido\\\\b|\\\\bhabida\\\\b|\\\\bhabidos\\\\b|\\\\bhabidas\\\\b|\\\\bsoy\\\\b|\\\\beres\\\\b|\\\\bes\\\\b|\\\\bsomos\\\\b|\\\\bsois\\\\b|\\\\bson\\\\b|\\\\bsea\\\\b|\\\\bseas\\\\b|\\\\bseamos\\\\b|\\\\bseáis\\\\b|\\\\bsean\\\\b|\\\\bseré\\\\b|\\\\bserás\\\\b|\\\\bserá\\\\b|\\\\bseremos\\\\b|\\\\bseréis\\\\b|\\\\bserán\\\\b|\\\\bsería\\\\b|\\\\bserías\\\\b|\\\\bseríamos\\\\b|\\\\bseríais\\\\b|\\\\bserían\\\\b|\\\\bera\\\\b|\\\\beras\\\\b|\\\\béramos\\\\b|\\\\berais\\\\b|\\\\beran\\\\b|\\\\bfui\\\\b|\\\\bfuiste\\\\b|\\\\bfue\\\\b|\\\\bfuimos\\\\b|\\\\bfuisteis\\\\b|\\\\bfueron\\\\b|\\\\bfuera\\\\b|\\\\bfueras\\\\b|\\\\bfuéramos\\\\b|\\\\bfuerais\\\\b|\\\\bfueran\\\\b|\\\\bfuese\\\\b|\\\\bfueses\\\\b|\\\\bfuésemos\\\\b|\\\\bfueseis\\\\b|\\\\bfuesen\\\\b|\\\\bsiendo\\\\b|\\\\bsido\\\\b|\\\\btengo\\\\b|\\\\btienes\\\\b|\\\\btiene\\\\b|\\\\btenemos\\\\b|\\\\btenéis\\\\b|\\\\btienen\\\\b|\\\\btenga\\\\b|\\\\btengas\\\\b|\\\\btengamos\\\\b|\\\\btengáis\\\\b|\\\\btengan\\\\b|\\\\btendré\\\\b|\\\\btendrás\\\\b|\\\\btendrá\\\\b|\\\\btendremos\\\\b|\\\\btendréis\\\\b|\\\\btendrán\\\\b|\\\\btendría\\\\b|\\\\btendrías\\\\b|\\\\btendríamos\\\\b|\\\\btendríais\\\\b|\\\\btendrían\\\\b|\\\\btenía\\\\b|\\\\btenías\\\\b|\\\\bteníamos\\\\b|\\\\bteníais\\\\b|\\\\btenían\\\\b|\\\\btuve\\\\b|\\\\btuviste\\\\b|\\\\btuvo\\\\b|\\\\btuvimos\\\\b|\\\\btuvisteis\\\\b|\\\\btuvieron\\\\b|\\\\btuviera\\\\b|\\\\btuvieras\\\\b|\\\\btuviéramos\\\\b|\\\\btuvierais\\\\b|\\\\btuvieran\\\\b|\\\\btuviese\\\\b|\\\\btuvieses\\\\b|\\\\btuviésemos\\\\b|\\\\btuvieseis\\\\b|\\\\btuviesen\\\\b|\\\\bteniendo\\\\b|\\\\btenido\\\\b|\\\\btenida\\\\b|\\\\btenidos\\\\b|\\\\btenidas\\\\b|\\\\btened\\\\b\" #>  #> $dias #> [1] \"\\\\bdomingo\\\\b|\\\\blunes\\\\b|\\\\bmartes\\\\b|\\\\bmiércoles\\\\b|\\\\bjueves\\\\b|\\\\bviernes\\\\b|\\\\bsábado\\\\b|\\\\bDomingo\\\\b|\\\\bLunes\\\\b|\\\\bMartes\\\\b|\\\\bMiércoles\\\\b|\\\\bJueves\\\\b|\\\\bViernes\\\\b|\\\\bSábado\\\\b|\\\\bMiercoles\\\\b|\\\\bmiercoles\\\\b|\\\\bMIERCOLES\\\\b|\\\\bSABADO\\\\b|\\\\bSabado\\\\b|\\\\bsabado\\\\b|\\\\bDOMINGO\\\\b|\\\\bLUNES\\\\b|\\\\bMARTES\\\\b|\\\\bMIÉRCOLES\\\\b|\\\\bJUEVES\\\\b|\\\\bVIERNES\\\\b|\\\\bSÁBADO\\\\b\" #>  #> $meses #> [1] \"\\\\benero\\\\b|\\\\bfebrero\\\\b|\\\\bmarzo\\\\b|\\\\babril\\\\b|\\\\bmayo\\\\b|\\\\bjunio\\\\b|\\\\bjulio\\\\b|\\\\bagosto\\\\b|\\\\bseptiembre\\\\b|\\\\boctubre\\\\b|\\\\bnoviembre\\\\b|\\\\bdiciembre\\\\b|\\\\bEnero\\\\b|\\\\bFebrero\\\\b|\\\\bMarzo\\\\b|\\\\bAbril\\\\b|\\\\bMayo\\\\b|\\\\bJunio\\\\b|\\\\bJulio\\\\b|\\\\bAgosto\\\\b|\\\\bSeptiembre\\\\b|\\\\bOctubre\\\\b|\\\\bNoviembre\\\\b|\\\\bDiciembre\\\\b|\\\\bENERO\\\\b|\\\\bFEBRERO\\\\b|\\\\bMARZO\\\\b|\\\\bABRIL\\\\b|\\\\bMAYO\\\\b|\\\\bJUNIO\\\\b|\\\\bJULIO\\\\b|\\\\bAGOSTO\\\\b|\\\\bSEPTIEMBRE\\\\b|\\\\bOCTUBRE\\\\b|\\\\bNOVIEMBRE\\\\b|\\\\bDICIEMBRE\\\\b\" #>  #> $punt #> [1] \"[^[:alnum:][:digit:][:blank:]\\\\p{So}|\\\\p{Cn}\\\\t\\\\r\\\\n#@ŠŽšžŸÀÁÂÃÄÅÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖÙÚÛÜÝàáâãäåçèéêëìíîïðñòóôõöùúûüýÿ]\" #>  #> $emojis #> [1] \"[^ñáéíóúüç…ÇÜÁÉÍÓÚÑ\\\\001-\\\\177]\" #>  #> $tildes #> [1] \"ŠŽšžŸÀÁÂÃÄÅÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖÙÚÛÜÝàáâãäåçèéêëìíîïðñòóôõöùúûüýÿ\" #>"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_sst.html","id":null,"dir":"Reference","previous_headings":"","what":"Serie temporal de índices de conflictividad. — acep_sst","title":"Serie temporal de índices de conflictividad. — acep_sst","text":"Función que devuelve los indices de conflictividad agrupados por segmento de tiempo: 'dia', 'mes', 'anio'. Esta función viene reemplazar acep_rst. Simplifica los parámetros.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_sst.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Serie temporal de índices de conflictividad. — acep_sst","text":"","code":"acep_sst(datos, st = \"mes\", u = 2, d = 4)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_sst.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Serie temporal de índices de conflictividad. — acep_sst","text":"datos data frame con las variables 'fecha' (en formato Date), 'n_palabras' (numérica), conflictos' (numérica), 'intensidad' (numérica). Las ultimas tres se pueden construir en un solo paso con la función 'acep_db' o en tres pasos con las funciones 'acep_frec', 'acep_men', 'acep_int'. st parámetro para establecer el segmento temporal ser agrupado: 'anio', 'mes', 'dia'. u umbral de menciones para contabilizar una nota como nota que refiere un conflicto, por defecto tiene 2 pero se puede modificar. d cantidad de decimales, por defecto tiene 4 pero se puede modificar.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_sst.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Serie temporal de índices de conflictividad. — acep_sst","text":"Si todas las entradas son correctas, la salida sera una base de datos en formato tabular con nuevas variables.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_sst.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Serie temporal de índices de conflictividad. — acep_sst","text":"","code":"datos <- acep_bases$rp_procesada head(datos) #> # A tibble: 6 × 4 #>   fecha      n_palabras conflictos intensidad #>   <date>          <int>      <int>      <dbl> #> 1 2020-12-29         31          0     0      #> 2 2020-12-28       1128          4     0.0035 #> 3 2020-12-24        530          0     0      #> 4 2020-12-24        483          3     0.0062 #> 5 2020-12-23        525          1     0.0019 #> 6 2020-12-23        462          0     0      datos_procesados_anio <- acep_sst(datos, st='anio', u=4) datos_procesados_mes <- acep_sst(datos) datos_procesados_dia <- acep_sst(datos, st ='dia', d=3) head(datos_procesados_anio) #>     st frecn csn  frecp frecm  intac intensidad int_notas_confl #> 1 2009   632  58 496110  1025 1.2735     0.0021          0.0918 #> 2 2010   680  67 492231  1129 1.6273     0.0023          0.0985 #> 3 2011   601  40 425747   882 1.2204     0.0021          0.0666 #> 4 2012   739  67 564270  1242 1.6841     0.0022          0.0907 #> 5 2013   689  24 525718   758 1.0559     0.0014          0.0348 #> 6 2014   631  30 444823   802 1.2112     0.0018          0.0475 head(datos_procesados_mes) #>        st frecn csn frecp frecm  intac intensidad int_notas_confl #> 1 2009-03    75  19 61252   146 0.1682     0.0024          0.2533 #> 2 2009-04    58   7 44076    75 0.0925     0.0017          0.1207 #> 3 2009-05    58   7 49037    55 0.0633     0.0011          0.1207 #> 4 2009-06    71   8 55727    82 0.1059     0.0015          0.1127 #> 5 2009-07    65  14 53299   110 0.1307     0.0021          0.2154 #> 6 2009-08    60  13 45458    94 0.1124     0.0021          0.2167 head(datos_procesados_dia) #>           st frecn csn frecp frecm  intac intensidad int_notas_confl #> 1 2009-03-02    10   4 10941    24 0.0201      0.002           0.400 #> 2 2009-03-03     3   0  2313     2 0.0019      0.001           0.000 #> 3 2009-03-04     5   1  4168    11 0.0092      0.003           0.200 #> 4 2009-03-05     3   1  2189     7 0.0090      0.003           0.333 #> 5 2009-03-06     5   1  3895     8 0.0098      0.002           0.200 #> 6 2009-03-09     3   0  2031     2 0.0034      0.001           0.000"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_svo.html","id":null,"dir":"Reference","previous_headings":"","what":"Función para extraer tripletes SVO (Sujeto-Verbo-Objeto). — acep_svo","title":"Función para extraer tripletes SVO (Sujeto-Verbo-Objeto). — acep_svo","text":"Función que devuelve seis objetos data.frame con etiquetado POS (modelo spacyr) y relaciones sintácticas (modelo rsyntax) que permiten reconstruir estructuras sintácticas como SVO y Sujeto-Predicado. Una vez seleccionadas las notas periodísticas referidas conflictos, esta función permite extraer sujetos de la protesta, acción realizada y objeto(s) de la acción. También devuelve entidades nombradas (NER).","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_svo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Función para extraer tripletes SVO (Sujeto-Verbo-Objeto). — acep_svo","text":"","code":"acep_svo(acep_tokenindex, prof_s = 3, prof_o = 3, u = 1)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_svo.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Función para extraer tripletes SVO (Sujeto-Verbo-Objeto). — acep_svo","text":"Dependencias Universales para taggeo POS Sobre el paquete rsyntax","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_svo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Función para extraer tripletes SVO (Sujeto-Verbo-Objeto). — acep_svo","text":"acep_tokenindex data.frame con el etiquetado POS y las relaciones de dependencia generado con la función acep_postag. prof_s es un numero entero positivo que determina la profundidad la que se buscan las relaciones dentro del sujeto. Este parámetro se hereda del la función children() del paquete {rsyntax}. Se recomienda superar el valor 2. prof_o es un numero entero positivo que determina la profundidad la que se buscan las relaciones dentro del objeto. Este parámetro se hereda del la función children() del paquete {rsyntax}. Se recomienda superar el valor 2. u numero entero que indica el umbral de palabras del objeto en la reconstrucción SVO.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_svo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Función para extraer tripletes SVO (Sujeto-Verbo-Objeto). — acep_svo","text":"Si todas las entradas son correctas, la salida sera una lista con tres bases de datos en formato tabular.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_svo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Función para extraer tripletes SVO (Sujeto-Verbo-Objeto). — acep_svo","text":"Welbers, K., Atteveldt, W. van, & Kleinnijenhuis, J. 2021. Extracting semantic relations using syntax: R package querying reshaping dependency trees. Computational Communication Research, 3-2, 1-16. (link al articulo)","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_svo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Función para extraer tripletes SVO (Sujeto-Verbo-Objeto). — acep_svo","text":"","code":"if (FALSE) { # \\dontrun{ acep_svo(acep_bases$spacy_postag) } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_together.html","id":null,"dir":"Reference","previous_headings":"","what":"Interaccion con modelos de IA usando TogetherAI — acep_together","title":"Interaccion con modelos de IA usando TogetherAI — acep_together","text":"Funcion para interactuar con modelos de IA traves de la API de TogetherAI. TogetherAI proporciona acceso modelos open-source de alta calidad como Llama, Qwen, Mistral, DeepSeek y muchos otros. Soporta JSON mode para respuestas estructuradas. La API es compatible con el formato de OpenAI, lo que facilita la integracion.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_together.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interaccion con modelos de IA usando TogetherAI — acep_together","text":"","code":"acep_together(   texto,   instrucciones,   modelo = \"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",   api_key = Sys.getenv(\"TOGETHER_API_KEY\"),   schema = NULL,   parse_json = TRUE,   temperature = 0,   max_tokens = 2000,   top_p = 0.2,   top_k = 50,   repetition_penalty = 1,   stop = NULL,   prompt_system = \"json\" )"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_together.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interaccion con modelos de IA usando TogetherAI — acep_together","text":"texto Texto analizar. Puede ser una noticia, tweet, documento, etc. instrucciones Instrucciones en lenguaje natural que indican al modelo que hacer con el texto. Ejemplo: \"Extrae todas las entidades nombradas\", \"Clasifica el sentimiento\". modelo Modelo utilizar. Ejemplos populares: - Moonshot: `\"moonshotai/Kimi-K2-Instruct-0905\"` (128K context) - Meta Llama: `\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\"`, `\"meta-llama/Llama-3.3-70B-Instruct-Turbo\"` - Qwen: `\"Qwen/Qwen2.5-72B-Instruct-Turbo\"`, `\"Qwen/QwQ-32B-Preview\"` - Mistral: `\"mistralai/Mixtral-8x22B-Instruct-v0.1\"`, `\"mistralai/Mistral-7B-Instruct-v0.3\"` - DeepSeek: `\"deepseek-ai/DeepSeek-V3\"`, `\"deepseek-ai/DeepSeek-R1\"` - Google: `\"google/gemma-2-27b-\"`, `\"google/gemma-2-9b-\"` Por defecto: `\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\"`. Ver lista completa: https://docs.together.ai/docs/chat-models api_key Clave de API de TogetherAI. Si se proporciona, busca la variable de entorno `TOGETHER_API_KEY`. Para obtener una clave: https://api.together.xyz/settings/api-keys schema Esquema JSON que define la estructura de la respuesta. Puede usar `acep_gpt_schema()` para obtener esquemas predefinidos o crear uno personalizado. Si es `NULL`, usa un esquema simple con campo \"respuesta\". NOTA: TogetherAI soporta JSON mode con response_format: {type: \"json_object\"} para modelos compatibles. Consulta la lista de modelos soportados en: https://docs.together.ai/docs/json-mode parse_json Logico. Si `TRUE` (por defecto), parsea automaticamente el JSON un objeto R (lista o data frame). Si `FALSE`, devuelve el JSON como string. temperature Parametro de temperatura (0-2). Valores bajos (0-0.3) generan respuestas mas deterministas. Valores altos (0.7-1) mas creativas. Por defecto: 0. max_tokens Numero maximo de tokens en la respuesta. Por defecto: 2000. top_p Parametro top-p para nucleus sampling (0-1). Por defecto: 0.2. top_k Parametro top-k para muestreo. Limita las opciones los k tokens mas probables. Por defecto: 50. Usar 0 o -1 para desactivar. repetition_penalty Penalizacion por repeticion de tokens (0.1-2.0). Valores > 1 penalizan repeticiones. Por defecto: 1. stop Secuencias de parada opcionales. Vector de strings que detienen la generacion. Por defecto: NULL. prompt_system Prompt del sistema que define el comportamiento del modelo. Opciones: - `\"json\"` (por defecto): Usa un prompt estructurado que instruye al modelo responder   SOLO en formato JSON siguiendo el esquema proporcionado. Agrega response_format: {type: \"json_object\"} - `\"texto\"`: Usa un prompt simple para respuestas en texto plano sin estructura.   Elimina automaticamente el contenido de pensamiento (<think>...<\/think>) de modelos como Qwen3-Thinking - String personalizado: Cualquier texto que definas como prompt del sistema","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_together.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interaccion con modelos de IA usando TogetherAI — acep_together","text":"Si `parse_json=TRUE`, devuelve una lista o data frame con la respuesta   estructurada segun el esquema. Si `parse_json=FALSE`, devuelve un string JSON.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_together.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interaccion con modelos de IA usando TogetherAI — acep_together","text":"**Sobre TogetherAI:** TogetherAI es una plataforma especializada en modelos open-source que ofrece: - Precios competitivos y modelos gratuitos - Alta velocidad de inferencia optimizada - Acceso modelos de ultima generacion (Llama, Qwen, DeepSeek, etc.) - API compatible con formato OpenAI **JSON Mode:** La funcion utiliza JSON mode de TogetherAI para obtener respuestas estructuradas. Cuando `prompt_system = \"json\"`, la funcion: 1. Incluye el esquema JSON en el prompt del sistema (REQUERIDO por TogetherAI) 2. Agrega response_format: {type: \"json_object\"} al body de la peticion 3. Instruye explicitamente al modelo responder SOLO en JSON Esta combinacion de esquema textual + response_format asegura respuestas JSON validas y consistentes en cada llamada. **Modelos compatibles con JSON mode:** Los modelos mas recientes que soportan JSON mode incluyen: - Qwen3, Qwen2.5 (Instruct, Coder, VL, Thinking) - DeepSeek-R1, DeepSeek-V3 - Meta Llama 3.1, 3.3, 4 - Mistral 7B Instruct - Google Gemma Ver lista completa: https://docs.together.ai/docs/json-mode **Validaciones:** La funcion incluye validacion de limite de tokens. Si la respuesta es truncada por `max_tokens`, devuelve un mensaje claro indicando que se necesitan mas tokens.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_together.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interaccion con modelos de IA usando TogetherAI — acep_together","text":"","code":"if (FALSE) { # \\dontrun{ # Configurar API key Sys.setenv(TOGETHER_API_KEY = \"tu-api-key\")  # Usar Llama 3.1 70B (rapido y potente) texto <- \"El SUTEBA convoco a un paro en Buenos Aires el 15 de marzo.\" resultado <- acep_together(texto, \"Extrae las entidades nombradas\",                            modelo = \"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",                            schema = acep_gpt_schema(\"extraccion_entidades\"))  # Usar Qwen para analisis de sentimiento resultado_qwen <- acep_together(texto, \"Clasifica el sentimiento\",                                 modelo = \"Qwen/Qwen2.5-72B-Instruct-Turbo\",                                 schema = acep_gpt_schema(\"sentimiento\"))  # Usar DeepSeek-V3 resultado_ds <- acep_together(texto, \"Analiza el texto\",                               modelo = \"deepseek-ai/DeepSeek-V3\",                               schema = acep_gpt_schema(\"clasificacion\"))  # Usar Moonshot Kimi con 128K context resultado_kimi <- acep_together(texto, \"Resume el texto\",                                 modelo = \"moonshotai/Kimi-K2-Instruct-0905\",                                 schema = acep_gpt_schema(\"resumen\"))  # Usar modo texto plano (sin estructura JSON) resultado_texto <- acep_together(texto, \"Resume este texto en una frase\",                                  modelo = \"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",                                  prompt_system = \"texto\",                                  parse_json = FALSE) print(resultado_texto)  # Devuelve string de texto plano  # Usar prompt del sistema personalizado resultado_custom <- acep_together(   texto,   \"Analiza el sentimiento\",   modelo = \"Qwen/Qwen2.5-72B-Instruct-Turbo\",   prompt_system = paste(     \"Eres un experto en analisis de sentimientos politicos.\",     \"Se objetivo y neutral.\"   ),   parse_json = FALSE ) } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token.html","id":null,"dir":"Reference","previous_headings":"","what":"Tokenizador. — acep_token","title":"Tokenizador. — acep_token","text":"Función que tokeniza las notas/textos.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tokenizador. — acep_token","text":"","code":"acep_token(x, tolower = TRUE, cleaning = TRUE)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tokenizador. — acep_token","text":"x vector de textos al que se le aplica la función de tokenización. tolower convierte los textos minúsculas. cleaning hace una limpieza de los textos.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tokenizador. — acep_token","text":"Si todas las entradas son correctas, la salida será un data.frame con las palabras tokenizadas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tokenizador. — acep_token","text":"","code":"acep_token(\"Huelga de obreros del pescado en el puerto\") #>   texto_id  tokens #> 1        1  huelga #> 2        1 obreros #> 3        1 pescado #> 4        1  puerto"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Gráfico de barras de palabras más recurrentes en un corpus. — acep_token_plot","title":"Gráfico de barras de palabras más recurrentes en un corpus. — acep_token_plot","text":"Función que devuelve un gráfico de barras con las palabras mas recurrentes en un corpus textual.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gráfico de barras de palabras más recurrentes en un corpus. — acep_token_plot","text":"","code":"acep_token_plot(x, u = 10, frec = TRUE)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gráfico de barras de palabras más recurrentes en un corpus. — acep_token_plot","text":"x vector de palabras tokenizadas. u numero de corte para el top de palabras mas frecuentes. frec parámetro para determinar si los valores se visualizaran como frecuencia absoluta o relativa.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gráfico de barras de palabras más recurrentes en un corpus. — acep_token_plot","text":"Si todas las entradas son correctas, la salida sera un gráfico de barras.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gráfico de barras de palabras más recurrentes en un corpus. — acep_token_plot","text":"","code":"tokens <- c(rep(\"paro\",15), rep(\"piquete\",25), rep(\"corte\",20), rep(\"manifestación\",10), rep(\"bloqueo\",5), rep(\"alerta\",16), rep(\"ciudad\",12), rep(\"sindicato\",11), rep(\"paritaria\",14), rep(\"huelga\",14), rep(\"escrache\",15)) acep_token_plot(tokens)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Tabla de frecuencia de palabras tokenizadas. — acep_token_table","title":"Tabla de frecuencia de palabras tokenizadas. — acep_token_table","text":"Función que cuenta la frecuencia de palabras tokenizadas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tabla de frecuencia de palabras tokenizadas. — acep_token_table","text":"","code":"acep_token_table(x, u = 10)"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tabla de frecuencia de palabras tokenizadas. — acep_token_table","text":"x vector de palabras tokenizadas. u número de corte para el top de palabras más frecuentes.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tabla de frecuencia de palabras tokenizadas. — acep_token_table","text":"Si todas las entradas son correctas, la salida sera una tabla con la frecuencia relativa y absoluta de palabras tokenizadas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_token_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tabla de frecuencia de palabras tokenizadas. — acep_token_table","text":"","code":"tokens <- c(rep(\"paro\",15), rep(\"piquete\",25), rep(\"corte\",20), rep(\"manifestación\",10), rep(\"bloqueo\",5), rep(\"alerta\",16), rep(\"ciudad\",12), rep(\"sindicato\",11), rep(\"paritaria\",14), rep(\"huelga\",14), rep(\"escrache\",15)) acep_token_table(tokens) #>            token frec       prop #> 1        piquete   25 0.16447368 #> 2          corte   20 0.13157895 #> 3         alerta   16 0.10526316 #> 4       escrache   15 0.09868421 #> 5           paro   15 0.09868421 #> 6         huelga   14 0.09210526 #> 7      paritaria   14 0.09210526 #> 8         ciudad   12 0.07894737 #> 9      sindicato   11 0.07236842 #> 10 manifestación   10 0.06578947"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_upos.html","id":null,"dir":"Reference","previous_headings":"","what":"Función para etiquetado POS, lematización, tokenización. — acep_upos","title":"Función para etiquetado POS, lematización, tokenización. — acep_upos","text":"Función que devuelve un marco de datos objetos con etiquetado POS (modelo udpipe) para su posterior procesamiento con la función acep_postag.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_upos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Función para etiquetado POS, lematización, tokenización. — acep_upos","text":"","code":"acep_upos(texto, modelo = \"spanish\")"},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_upos.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Función para etiquetado POS, lematización, tokenización. — acep_upos","text":"Dependencias Universales para taggeo POS Sobre el modelo UDPipe Sobre el paquete rsyntax","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_upos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Función para etiquetado POS, lematización, tokenización. — acep_upos","text":"texto vector con los textos procesar. modelo idioma del modelo de etiquetado POS del paquete udpipe.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_upos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Función para etiquetado POS, lematización, tokenización. — acep_upos","text":"Si todas las entradas son correctas, la salida sera un marco de datos con 17 variables.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_upos.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Función para etiquetado POS, lematización, tokenización. — acep_upos","text":"Welbers, K., Atteveldt, W. van, & Kleinnijenhuis, J. 2021. Extracting semantic relations using syntax: R package querying reshaping dependency trees. Computational Communication Research, 3-2, 1-16. (link al articulo)","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/acep_upos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Función para etiquetado POS, lematización, tokenización. — acep_upos","text":"","code":"if (FALSE) { # \\dontrun{ texto <- \"El SOIP declara la huelga en demanda de aumento salarial.\" acep_upos(texto) } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/dot-acep_regex_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Cache para regex compilados — .acep_regex_cache","title":"Cache para regex compilados — .acep_regex_cache","text":"Cache para regex compilados","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/dot-acep_regex_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cache para regex compilados — .acep_regex_cache","text":"","code":".acep_regex_cache"},{"path":"https://agusnieto77.github.io/ACEP/reference/dot-acep_regex_cache.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cache para regex compilados — .acep_regex_cache","text":"object class environment length 0.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator para ACEP — %>%","title":"Pipe operator para ACEP — %>%","text":"Pipe operator para ACEP","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator para ACEP — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_clean.html","id":null,"dir":"Reference","previous_headings":"","what":"Limpieza de texto en pipeline — pipe_clean","title":"Limpieza de texto en pipeline — pipe_clean","text":"Aplica limpieza y normalización de texto dentro de un flujo pipeline. Esta función actúa como adaptador de `acep_clean()` para trabajar con objetos `acep_corpus`, registrando las transformaciones aplicadas.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_clean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Limpieza de texto en pipeline — pipe_clean","text":"","code":"pipe_clean(corpus, ...)"},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_clean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Limpieza de texto en pipeline — pipe_clean","text":"corpus Objeto `acep_corpus` o vector de caracteres. Si se pasa un vector, se crea automáticamente un objeto `acep_corpus`. ... Argumentos para `acep_clean()`. Ejemplos: `rm_stopwords = TRUE`, `rm_num = TRUE`, `tolower = TRUE`, `rm_punt = TRUE`.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_clean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Limpieza de texto en pipeline — pipe_clean","text":"Objeto `acep_corpus` con el campo `texto_procesado` actualizado   y registro de la transformación en `procesamiento$limpieza`.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_clean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Limpieza de texto en pipeline — pipe_clean","text":"","code":"# Crear corpus y limpiar textos <- c(\"El SUTEBA va al paro!!!\", \"SOIP protesta 123\") corpus <- acep_corpus(textos) corpus_limpio <- pipe_clean(corpus, rm_punt = TRUE, rm_num = TRUE) print(corpus_limpio) #> acep_corpus object #> ================== #> Documentos: 2  #> Procesado: TRUE  #> Pasos aplicados: 1  #> Funciones: limpieza"},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Conteo de menciones en pipeline — pipe_count","title":"Conteo de menciones en pipeline — pipe_count","text":"Cuenta las menciones de palabras de un diccionario dentro de un flujo pipeline. Esta función extrae los textos de un `acep_corpus` (procesados o originales) y aplica `acep_count()` para detectar ocurrencias del diccionario.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conteo de menciones en pipeline — pipe_count","text":"","code":"pipe_count(corpus, dic, ...)"},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conteo de menciones en pipeline — pipe_count","text":"corpus Objeto `acep_corpus`. Debe ser un corpus válido creado con `acep_corpus()` o resultado de `pipe_clean()`. dic Vector de caracteres con las palabras del diccionario buscar. ... Argumentos adicionales (actualmente utilizados, reservado para futuras extensiones).","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conteo de menciones en pipeline — pipe_count","text":"Objeto `acep_result` con tipo `\"frecuencia\"` que contiene un data frame con:   `id`, `texto` y `frecuencia` de menciones por texto.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conteo de menciones en pipeline — pipe_count","text":"","code":"# Contar menciones en corpus textos <- c(\"El SUTEBA va al paro\", \"SOIP en lucha y paro\") corpus <- acep_corpus(textos) diccionario <- c(\"paro\", \"lucha\", \"protesta\") resultado <- pipe_count(corpus, diccionario) print(resultado) #> acep_result object #> ================== #> Tipo: frecuencia  #> Filas: 2  #> Columnas: 3  #> Creado: 2025-11-10 00:42:22  #>  #> Primeras filas: #>   id                texto frecuencia #> 1  1 El SUTEBA va al paro          1 #> 2  2 SOIP en lucha y paro          2"},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_intensity.html","id":null,"dir":"Reference","previous_headings":"","what":"Cálculo de intensidad en pipeline — pipe_intensity","title":"Cálculo de intensidad en pipeline — pipe_intensity","text":"Calcula el índice de intensidad normalizado dentro de un flujo pipeline. La intensidad se define como la proporción de menciones del diccionario respecto al total de palabras: intensidad = frecuencia / n_palabras.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_intensity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cálculo de intensidad en pipeline — pipe_intensity","text":"","code":"pipe_intensity(result, decimales = 4)"},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_intensity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cálculo de intensidad en pipeline — pipe_intensity","text":"result Objeto `acep_result` que debe contener una columna `frecuencia`. Típicamente proviene de `pipe_count()`. decimales Número de decimales para redondear el índice de intensidad. Por defecto: 4.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_intensity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cálculo de intensidad en pipeline — pipe_intensity","text":"Objeto `acep_result` con tipo `\"intensidad\"` que incluye columnas   adicionales: `n_palabras` e `intensidad`.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_intensity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cálculo de intensidad en pipeline — pipe_intensity","text":"","code":"# Calcular intensidad desde resultado de conteo textos <- c(\"El SUTEBA va al paro\", \"SOIP en lucha y paro\") corpus <- acep_corpus(textos) diccionario <- c(\"paro\", \"lucha\") resultado <- pipe_count(corpus, diccionario) resultado_intensidad <- pipe_intensity(resultado, decimales = 4) print(resultado_intensidad) #> acep_result object #> ================== #> Tipo: intensidad  #> Filas: 2  #> Columnas: 5  #> Creado: 2025-11-10 00:42:22  #>  #> Primeras filas: #>   id                texto frecuencia n_palabras intensidad #> 1  1 El SUTEBA va al paro          1          5        0.2 #> 2  2 SOIP en lucha y paro          2          5        0.4"},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_timeseries.html","id":null,"dir":"Reference","previous_headings":"","what":"Generación de series temporales en pipeline — pipe_timeseries","title":"Generación de series temporales en pipeline — pipe_timeseries","text":"Crea agregaciones temporales de índices de conflictividad dentro de un flujo pipeline. Agrupa los resultados por segmentos temporales (día, mes, año) y calcula estadísticas resumidas usando `acep_sst()`.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_timeseries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generación de series temporales en pipeline — pipe_timeseries","text":"","code":"pipe_timeseries(data, st = \"mes\", u = 2, d = 4)"},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_timeseries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generación de series temporales en pipeline — pipe_timeseries","text":"data Data frame o objeto `acep_result` que contenga columnas: `fecha` (o variable temporal), `n_palabras`, `conflictos`, `intensidad`. st Segmento temporal para agrupar. Valores: `\"dia\"`, `\"mes\"`, `\"anio\"`. Por defecto: `\"mes\"`. u Umbral para calcular métricas categóricas. Por defecto: 2. d Número de decimales para redondear. Por defecto: 4.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_timeseries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generación de series temporales en pipeline — pipe_timeseries","text":"Objeto `acep_result` con tipo `\"serie_temporal\"` que contiene   agregaciones por período temporal.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/pipe_timeseries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generación de series temporales en pipeline — pipe_timeseries","text":"","code":"if (FALSE) { # \\dontrun{ # Crear serie temporal desde data frame con fechas data <- data.frame(   fecha = as.Date(c(\"2024-01-15\", \"2024-01-20\", \"2024-02-10\")),   n_palabras = c(100, 150, 120),   conflictos = c(5, 8, 6),   intensidad = c(0.05, 0.053, 0.05) ) serie <- pipe_timeseries(data, st = \"mes\", u = 2) print(serie) } # }"},{"path":"https://agusnieto77.github.io/ACEP/reference/proteger_arrays_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Funcion auxiliar para proteger arrays en esquemas JSON — proteger_arrays_schema","title":"Funcion auxiliar para proteger arrays en esquemas JSON — proteger_arrays_schema","text":"Protege arrays en esquemas JSON para evitar que jsonlite::toJSON los convierta incorrectamente. Aplica () campos 'required' y 'enum' recursivamente. Protege arrays en esquemas JSON para evitar que jsonlite::toJSON los convierta incorrectamente. Aplica () campos 'required' y 'enum' recursivamente.","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/proteger_arrays_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Funcion auxiliar para proteger arrays en esquemas JSON — proteger_arrays_schema","text":"","code":"proteger_arrays_schema(schema)  proteger_arrays_schema(schema)"},{"path":"https://agusnieto77.github.io/ACEP/reference/proteger_arrays_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Funcion auxiliar para proteger arrays en esquemas JSON — proteger_arrays_schema","text":"schema Esquema JSON como lista de R","code":""},{"path":"https://agusnieto77.github.io/ACEP/reference/proteger_arrays_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Funcion auxiliar para proteger arrays en esquemas JSON — proteger_arrays_schema","text":"Esquema con arrays protegidos Esquema con arrays protegidos","code":""},{"path":[]},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"nuevas-funcionalidades-0-1-0-9000","dir":"Changelog","previous_headings":"","what":"Nuevas funcionalidades","title":"ACEP 0.1.0.9000 (versión en desarrollo)","text":"Se agregó acep_corpus(): constructor de objetos corpus para trabajar con pipelines de procesamiento de texto. Se agregó acep_result(): constructor de objetos resultado con métodos de impresión y resumen. Se agregó acep_pipeline(): pipeline completo que integra limpieza, conteo e intensidad. pipe_clean(): limpieza de texto en pipeline pipe_count(): conteo de menciones en pipeline pipe_intensity(): cálculo de intensidad en pipeline pipe_timeseries(): generación de series temporales en pipeline Se agregó acep_postag_hibrido(): etiquetado POS, lematización y extracción de entidades con spacyr. Se agregó acep_process_chunks(): procesamiento de textos en lotes para gestionar grandes volúmenes de datos. Se agregó acep_gpt_schema(): esquemas JSON predefinidos para análisis de texto con GPT. Se agregó acep_ollama(): interacción con modelos de lenguaje de Ollama tanto locales como cloud usando structured outputs. Permite ejecutar análisis sin costos en local y activar modelos gigantes (DeepSeek 671B, Kimi 1T, Qwen3 Coder) con una API key opcional. Se agregó acep_ollama_setup(): guía de instalación y configuración de Ollama. Se agregó acep_together(): integración con TogetherAI para acceder modelos open source (Llama, Qwen, DeepSeek, Moonshot) con JSON mode, esquemas validados y postprocesamiento automático. acep_claude(): interacción con modelos Anthropic Claude (Sonnet 4.5, Claude 3.5, Claude 3) usando tool calling forzado para structured outputs acep_gemini(): interacción con modelos Google Gemini (2.5 y 2.0) usando responseSchema con OpenAPI 3.0. Incluye acceso gratuito limitado acep_openrouter(): gateway unificado para acceder 400+ modelos de 60+ proveedores (OpenAI, Anthropic, Google, Meta, Qwen, DeepSeek) con una sola API y soporte de fallback automático acep_clear_regex_cache(): limpia el caché de expresiones regulares acep_regex_cache_size(): consulta el tamaño del caché","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"mejoras-en-funciones-existentes-0-1-0-9000","dir":"Changelog","previous_headings":"","what":"Mejoras en funciones existentes","title":"ACEP 0.1.0.9000 (versión en desarrollo)","text":"acep_count(): se incorporó sistema de caché de expresiones regulares para mejorar rendimiento. Soporte para modelos GPT-4o, GPT-4.1, GPT-5, o1 y o4 Detección automática de parámetro correcto (max_tokens vs max_completion_tokens) según el modelo Validación flexible con patrones regex para modelos futuros Compatibilidad con todos los modelos que soporten Structured Outputs acep_clean(): renombrada desde acep_cleaning() para mayor consistencia. acep_ollama(): ahora detecta el tipo de endpoint (localhost o cloud), permite fijar max_tokens, usa hosts remotos con autenticación mediante OLLAMA_API_KEY y elimina la dependencia obligatoria de ollamar. acep_openrouter(): agrega listado actualizado de modelos GPT-5, Grok 4, DeepSeek V3/R1, Llama 4 y Mixtral, aplica fallback inteligente entre candidatos, refuerza la validación JSON y reporta el detalle de errores por intento.","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"datos-y-recursos-0-1-0-9000","dir":"Changelog","previous_headings":"","what":"Datos y recursos","title":"ACEP 0.1.0.9000 (versión en desarrollo)","text":"acep_bases: se reorganizó la documentación e incorpora el data frame lc_720 con 720 notas anotadas manualmente para evaluar diccionarios y extracción estructurada de eventos de protesta.","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"documentación-0-1-0-9000","dir":"Changelog","previous_headings":"","what":"Documentación","title":"ACEP 0.1.0.9000 (versión en desarrollo)","text":"Se mejoró la documentación de todas las funciones nuevas y modificadas. Se agregaron ejemplos prácticos todas las funciones operativas. Se actualizó README.Rmd con la lista completa de funciones del paquete, incluyendo las 4 nuevas funciones de IA. Se actualizaron todas las viñetas para usar las nuevas funciones. Se documentó acep_together() y las mejoras de acep_ollama()/acep_openrouter(), con ejemplos para modo cloud, fallback y JSON mode. Guías de uso con ejemplos para cada proveedor (OpenAI, Anthropic, Google, OpenRouter, TogetherAI, Ollama cloud) Tabla comparativa de características entre proveedores Instrucciones para configuración de API keys Ejemplos de uso intercambiable entre diferentes APIs manteniendo la misma interfaz","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"acep-0029005-versión-en-desarrollo","dir":"Changelog","previous_headings":"","what":"ACEP 0.0.2.9005 (versión en desarrollo)","title":"ACEP 0.0.2.9005 (versión en desarrollo)","text":"Se actualizó y mejoró la función para interactuar con los modelos de OpenAI.","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"acep-0039004-versión-en-desarrollo-vigente","dir":"Changelog","previous_headings":"","what":"ACEP 0.0.3.9004 (versión en desarrollo vigente)","title":"ACEP 0.0.3.9004 (versión en desarrollo vigente)","text":"Se mejoraron las funciones existentes y se creó la función acep_upos().","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"acep-0039003-versión-en-desarrollo","dir":"Changelog","previous_headings":"","what":"ACEP 0.0.3.9003 (versión en desarrollo)","title":"ACEP 0.0.3.9003 (versión en desarrollo)","text":"Se crearon nuevas funciones y se mejoraron las existentes.","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"acep-0039002-versión-en-desarrollo","dir":"Changelog","previous_headings":"","what":"ACEP 0.0.3.9002 (versión en desarrollo)","title":"ACEP 0.0.3.9002 (versión en desarrollo)","text":"Incorporamos una función para extraer palabras clave de corpus de texto en base un diccionario. Se creo una nueva función para interactuar con la api de OpenAI.","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"acep-0039001-versión-en-desarrollo","dir":"Changelog","previous_headings":"","what":"ACEP 0.0.3.9001 (versión en desarrollo)","title":"ACEP 0.0.3.9001 (versión en desarrollo)","text":"Se mejoraron las nuevas funciones para contexto de texto y tokenización.","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"acep-0021-versión-cran-vigente","dir":"Changelog","previous_headings":"","what":"ACEP 0.0.21 (versión CRAN vigente)","title":"ACEP 0.0.21 (versión CRAN vigente)","text":"CRAN release: 2022-11-05 Se mejoraron las nuevas funciones para limpieza de texto, tokenización y detección de menciones.","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"acep-0029000-versión-en-desarrollo","dir":"Changelog","previous_headings":"","what":"ACEP 0.0.2.9000 (versión en desarrollo)","title":"ACEP 0.0.2.9000 (versión en desarrollo)","text":"Se mejoraron las nuevas funciones para limpieza de texto, tokenización y detección de menciones.","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"acep-002-versión-cran","dir":"Changelog","previous_headings":"","what":"ACEP 0.0.2 (versión CRAN)","title":"ACEP 0.0.2 (versión CRAN)","text":"CRAN release: 2022-10-30 Se agregaron nuevas funciones para limpieza de texto, tokenizacion y detección de menciones.","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"acep-0019000-versión-en-desarrollo","dir":"Changelog","previous_headings":"","what":"ACEP 0.0.1.9000 (versión en desarrollo)","title":"ACEP 0.0.1.9000 (versión en desarrollo)","text":"se agregaron nuevas funciones. se agregaron nuevas bases de datos. se agregaron nuevas descripciones. se agregaron nuevos ejemplos.","code":""},{"path":"https://agusnieto77.github.io/ACEP/news/index.html","id":"acep-001-versión-cran","dir":"Changelog","previous_headings":"","what":"ACEP 0.0.1 (versión CRAN)","title":"ACEP 0.0.1 (versión CRAN)","text":"CRAN release: 2022-07-18 Se ha añadido un archivo NEWS.md para seguir los cambios en el paquete.","code":""}]
