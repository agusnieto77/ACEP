% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/acep_ollama.R
\name{acep_ollama}
\alias{acep_ollama}
\title{Interaccion con modelos Ollama locales usando Structured Outputs}
\usage{
acep_ollama(
  texto,
  instrucciones,
  modelo = "qwen3:1.7b",
  schema = NULL,
  parse_json = TRUE,
  temperature = 0,
  host = "http://localhost:11434",
  seed = 123456
)
}
\arguments{
\item{texto}{Texto a analizar. Puede ser una noticia, tweet, documento, etc.}

\item{instrucciones}{Instrucciones en lenguaje natural que indican al modelo que hacer
con el texto. Ejemplo: "Extrae todas las entidades nombradas", "Clasifica el sentimiento".}

\item{modelo}{Modelo de Ollama a utilizar. Ejemplos: "qwen2.5, llama3.1", "mistral",
"phi3", "gemma2". Por defecto: "qwen3:1.7b". Debe estar previamente descargado con
`ollama pull nombre_modelo` desde la terminal o desde `ollamar::pull('nombre del modelo')` en consola.}

\item{schema}{Esquema JSON que define la estructura de la respuesta. Puede usar
`acep_gpt_schema()` para obtener esquemas predefinidos o crear uno personalizado.
Si es NULL, usa un esquema simple con campo "respuesta".}

\item{parse_json}{Logico. Si TRUE (por defecto), parsea automaticamente el JSON
a un objeto R (lista o data frame). Si FALSE, devuelve el JSON como string.}

\item{temperature}{Parametro de temperatura (0-2). Valores bajos (0-0.3) generan
respuestas mas deterministas. Valores altos (0.7-1) mas creativas. Por defecto: 0.}

\item{host}{URL del servidor Ollama. Por defecto: "http://localhost:11434"}

\item{seed}{Semilla numerica para reproducibilidad. Por defecto: 123456.}
}
\value{
Si parse_json=TRUE, devuelve una lista o data frame con la respuesta
  estructurada segun el esquema. Si parse_json=FALSE, devuelve un string JSON.
}
\description{
Funcion para interactuar con modelos de lenguaje locales usando Ollama.
Similar a acep_gpt() pero ejecuta modelos en tu computadora sin necesidad
de API keys ni costos. Soporta structured outputs para garantizar respuestas
en formato JSON que cumplen con un esquema predefinido.
}
\examples{
\dontrun{
# Primero, instalar Ollama y descargar un modelo:
# Terminal: ollama pull llama3.1

# Extraer entidades de un texto
texto <- "El SUTEBA convoco a un paro en Buenos Aires el 15 de marzo."
instrucciones <- "Extrae todas las entidades nombradas del texto."
schema <- acep_gpt_schema("extraccion_entidades")
resultado <- acep_ollama(texto, instrucciones, schema = schema)
print(resultado)

# Analisis de sentimiento
texto <- "La protesta fue pacifica y bien organizada."
schema <- acep_gpt_schema("sentimiento")
resultado <- acep_ollama(texto, "Analiza el sentimiento del texto", schema = schema)
print(resultado$sentimiento_general)
}
}
