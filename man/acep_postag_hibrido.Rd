% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/acep_postag_hibrido.R
\name{acep_postag_hibrido}
\alias{acep_postag_hibrido}
\title{Etiquetado POS, lematización y extracción de entidades con spacyr}
\usage{
acep_postag_hibrido(
  texto,
  core = "es_core_news_lg",
  bajar_core = TRUE,
  inst_spacy = FALSE,
  inst_miniconda = FALSE,
  inst_reticulate = FALSE,
  chunk_size = 1000,
  parallel_chunks = FALSE,
  n_cores = NULL,
  geocode_cache_file = "geocode_cache.json",
  use_cache = TRUE,
  show_progress = TRUE
)
}
\arguments{
\item{texto}{Vector de caracteres con los textos a analizar.}

\item{core}{Modelo de lenguaje de spaCy a utilizar. Opciones: `"es_core_news_sm"`,
`"es_core_news_md"`, `"es_core_news_lg"` (español), `"en_core_web_sm"`,
`"en_core_web_md"`, `"en_core_web_lg"` (inglés), `"pt_core_news_sm"`,
`"pt_core_news_md"`, `"pt_core_news_lg"` (portugués). Por defecto: `"es_core_news_lg"`.}

\item{bajar_core}{Lógico. Si `TRUE`, descarga automáticamente el modelo si no está instalado.}

\item{inst_spacy}{Lógico. Si `TRUE`, instala la biblioteca spaCy en el entorno Python.}

\item{inst_miniconda}{Lógico. Si `TRUE`, instala Miniconda (necesario para spaCy).}

\item{inst_reticulate}{Lógico. Si `TRUE`, instala el paquete reticulate de R.}

\item{chunk_size}{Número de textos a procesar por lote. Valores más bajos consumen
menos memoria pero tardan más. Por defecto: 1000.}

\item{parallel_chunks}{Lógico. Si `TRUE`, procesa los lotes en paralelo usando
múltiples núcleos del CPU. Requiere los paquetes `future` y `furrr`. Por defecto: `FALSE`.}

\item{n_cores}{Número de núcleos de CPU a usar en modo paralelo. Si es `NULL`,
detecta automáticamente el número de núcleos disponibles menos uno.}

\item{geocode_cache_file}{Ruta al archivo JSON donde se almacena el caché de
geocodificación para evitar consultas repetidas. Por defecto: `"geocode_cache.json"`.}

\item{use_cache}{Lógico. Si `TRUE`, usa y actualiza el caché de geocodificación.}

\item{show_progress}{Lógico. Si `TRUE`, muestra mensajes de progreso en la consola.}
}
\value{
Lista con 6 data frames que contienen diferentes niveles de análisis:
\itemize{
  \item \code{texto_tag}: Tokenización completa con etiquetas POS, lemas, dependencias
    sintácticas y atributos morfológicos para cada token
  \item \code{texto_tag_entity}: Tokens con entidades nombradas consolidadas
    (ej: "Mar del Plata" como una sola entidad en lugar de 3 tokens separados)
  \item \code{texto_only_entity}: Solo las entidades nombradas extraídas
    (personas, organizaciones, ubicaciones, fechas, etc.)
  \item \code{texto_only_entity_loc}: Entidades de tipo ubicación (LOC)
    con coordenadas geográficas (latitud/longitud) obtenidas mediante geocodificación
  \item \code{texto_nounphrase}: Tokens con frases nominales consolidadas
  \item \code{texto_only_nounphrase}: Solo las frases nominales extraídas
}
}
\description{
Realiza análisis lingüístico completo de textos usando la biblioteca spaCy a través
de spacyr. Incluye: etiquetado POS (Part-of-Speech), lematización, tokenización,
extracción de entidades nombradas, frases nominales y geocodificación de ubicaciones.
La función procesa automáticamente grandes volúmenes de texto dividiéndolos en lotes
(chunks) y soporta procesamiento paralelo para acelerar el análisis
}
\examples{
\dontrun{
# Análisis básico de un texto
texto <- "El SUTEBA convocó a un paro en Mar del Plata el 15 de marzo."
resultado <- acep_postag_hibrido(texto)

# Ver tokens con etiquetas POS
head(resultado$texto_tag)

# Ver entidades nombradas
print(resultado$texto_only_entity)

# Ver ubicaciones geocodificadas
print(resultado$texto_only_entity_loc)

# Procesar múltiples textos con procesamiento paralelo
textos <- c("Primera noticia sobre conflictos.",
            "Segunda noticia sobre protestas.",
            "Tercera noticia sobre reclamos.")
resultado <- acep_postag_hibrido(textos,
                                 parallel_chunks = TRUE,
                                 chunk_size = 100)
}
}
