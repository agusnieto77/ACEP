% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/acep_postag.R
\name{acep_postag}
\alias{acep_postag}
\title{Etiquetado POS adaptativo con optimizaciones avanzadas}
\usage{
acep_postag(
  texto,
  core = "es_core_news_lg",
  bajar_core = TRUE,
  inst_spacy = FALSE,
  inst_miniconda = FALSE,
  inst_reticulate = FALSE,
  chunk_size = 1000,
  geocode_cache_file = "geocode_cache.json",
  use_cache = TRUE,
  show_progress = TRUE
)
}
\arguments{
\item{texto}{Vector de caracteres con los textos a procesar.}

\item{core}{Idioma del modelo de etiquetado POS del paquete \code{spacyr}. Opciones disponibles:
'es_core_news_sm', 'es_core_news_md', 'es_core_news_lg' (español),
'pt_core_news_sm', 'pt_core_news_md', 'pt_core_news_lg' (portugués),
'en_core_web_sm', 'en_core_web_md', 'en_core_web_lg', 'en_core_web_trf' (inglés).
Default: "es_core_news_lg".}

\item{bajar_core}{Parámetro booleano que define si descargar o no el modelo de etiquetado POS.
Default: TRUE.}

\item{inst_spacy}{Parámetro booleano que define si instalar o no spacy (Python).
Default: FALSE.}

\item{inst_miniconda}{Parámetro booleano que define si instalar o no miniconda.
Default: FALSE.}

\item{inst_reticulate}{Parámetro booleano que define si instalar o no el paquete \code{reticulate}.
Default: FALSE.}

\item{chunk_size}{Tamaño de los lotes para procesamiento chunking. Ajustar según RAM disponible:
500 para sistemas con 2-4 GB RAM, 1000 para 8 GB RAM (default), 2000-5000 para 16+ GB RAM.
Default: 1000.}

\item{geocode_cache_file}{Ruta del archivo JSON para guardar caché de geocodificación.
Permite evitar consultas repetidas a la API de Nominatim y compartir caché entre proyectos.
Default: "geocode_cache.json".}

\item{use_cache}{Parámetro booleano que activa/desactiva el sistema de caché de geocodificación.
Desactivar para forzar re-geocodificación de todas las ubicaciones.
Default: TRUE.}

\item{show_progress}{Parámetro booleano que controla la visualización de mensajes de progreso
durante el procesamiento. Útil para operaciones largas.
Default: TRUE.}
}
\value{
Lista con seis elementos en formato tabular:
\itemize{
  \item \code{texto_tag}: Data frame con tokens etiquetados (POS, lemas, dependencias, etc.)
  \item \code{texto_tag_entity}: Data frame con entidades nombradas consolidadas
  \item \code{texto_only_entity}: Data frame con solo las entidades extraídas
  \item \code{texto_only_entity_loc}: Data frame con entidades de tipo LOC geocodificadas (lat/long)
  \item \code{texto_nounphrase}: Data frame con frases nominales consolidadas
  \item \code{texto_only_nounphrase}: Data frame con solo las frases nominales extraídas
}
}
\description{
Versión optimizada de acep_postag que se adapta automáticamente al tamaño del input.
Implementa procesamiento por lotes (chunking) para grandes volúmenes, caché de geocodificación
para evitar consultas repetidas, y estrategias de procesamiento adaptativas según la cantidad
de textos. Puede procesar desde 10 hasta millones de textos de forma eficiente.
}
\details{
La función implementa dos estrategias de procesamiento automáticas:
\itemize{
  \item \strong{Batch Processing} (≤ 100 textos): Procesa todos los textos en una sola llamada
  para máxima velocidad.
  \item \strong{Chunking} (> 100 textos): Divide los textos en lotes del tamaño especificado
  en \code{chunk_size} para controlar el uso de memoria y permitir procesamiento de grandes volúmenes.
}

El sistema de caché de geocodificación guarda las coordenadas de ubicaciones ya consultadas
en formato JSON, evitando consultas repetidas a la API de Nominatim (que tiene límite de 1 req/seg).
Esto puede reducir el tiempo de procesamiento en 50-90% en ejecuciones posteriores con ubicaciones repetidas.

Para datasets muy grandes (>100,000 textos), se recomienda procesar en lotes usando la función
auxiliar proporcionada en los ejemplos y guardar resultados incrementalmente.
}
\examples{
\dontrun{
# Ejemplo básico con pocos textos
textos <- c(
  "En Mar del Plata el SOIP declara la huelga en demanda de aumento salarial.",
  "La manifestación se realizó en Buenos Aires el 15 de marzo.",
  "El presidente visitó Córdoba para inaugurar la nueva planta."
)
resultado <- acep_postag(texto = textos, bajar_core = FALSE)
head(resultado$texto_tag)

# Ejemplo con dataset mediano y configuración personalizada
resultado <- acep_postag(
  texto = mis_1000_textos,
  bajar_core = FALSE,
  chunk_size = 500,
  geocode_cache_file = "cache/ubicaciones_argentina.json",
  use_cache = TRUE
)

# Ver ubicaciones geocodificadas
head(resultado$texto_only_entity_loc)

# Procesamiento incremental para datasets muy grandes
procesar_incremental <- function(textos, batch_size = 10000) {
  dir.create("resultados", showWarnings = FALSE)
  n_batches <- ceiling(length(textos) / batch_size)

  for (i in 1:n_batches) {
    start_idx <- (i - 1) * batch_size + 1
    end_idx <- min(i * batch_size, length(textos))
    batch <- textos[start_idx:end_idx]

    resultado <- acep_postag(
      texto = batch,
      bajar_core = FALSE,
      chunk_size = 2000,
      use_cache = TRUE,
      geocode_cache_file = "cache_global.json"
    )

    saveRDS(resultado, sprintf("resultados/batch_\%04d.rds", i))
    message(sprintf("Batch \%d/\%d completado", i, n_batches))
  }
}

# Usar función incremental
procesar_incremental(mis_millones_de_textos, batch_size = 10000)

# Ver contenido del caché
cache <- jsonlite::read_json("geocode_cache.json", simplifyVector = TRUE)
print(paste("Ubicaciones en caché:", nrow(cache)))
}
}
\keyword{cache}
\keyword{chunking}
\keyword{etiquetado}
\keyword{optimizacion}
